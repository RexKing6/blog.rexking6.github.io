<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.rexking6.top","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#37c6c0","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"YS7HT61SEB","apiKey":"0fd1eba022e7883c76ff4a71aee2acdc","indexName":"blog_NAME","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"找不到关于 ${query} 的文章","hits_stats":"共找到 ${hits} 篇文章，花了 ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="...">
<meta property="og:type" content="article">
<meta property="og:title" content="MobileNet">
<meta property="og:url" content="https://blog.rexking6.top/2019/07/06/MobileNet/">
<meta property="og:site_name" content="RexKing6&#39;s Note">
<meta property="og:description" content="...">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422061.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422190.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422204.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422232.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422288.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422339.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422385.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422406.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422418.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422441.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422461.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422479.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422500.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422529.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422614.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422627.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422674.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422761.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422773.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562422783.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423163.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423186.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423217.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423239.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423290.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423308.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423322.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423416.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423441.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423505.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423541.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423561.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423582.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423595.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423609.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423644.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423696.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423707.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423726.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423739.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423823.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562423835.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424683.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424698.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424879.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424914.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424932.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424963.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562424978.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425011.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425033.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425088.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425107.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425140.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425183.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425224.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425288.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425426.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425467.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425482.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425551.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425566.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425578.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425592.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425631.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425642.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425687.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425704.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425717.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425738.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425758.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425785.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425797.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425833.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425854.png">
<meta property="og:image" content="http://image.rexking6.top/img/v2-6428cf505ac1e9e1cf462e1ec8fe9a68_b.gif">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425901.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425935.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562425967.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428062.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428094.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428126.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428149.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428161.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428172.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1562428187.png">
<meta property="article:published_time" content="2019-07-06T14:05:21.000Z">
<meta property="article:modified_time" content="2021-07-10T11:36:07.349Z">
<meta property="article:author" content="Run-Qing Chen">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://image.rexking6.top/img/clip1562422061.png">

<link rel="canonical" href="https://blog.rexking6.top/2019/07/06/MobileNet/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>MobileNet | RexKing6's Note</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="RexKing6's Note" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RexKing6's Note</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/rexking6" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.rexking6.top/2019/07/06/MobileNet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Run-Qing Chen">
      <meta itemprop="description" content="覆苍天以为衾，卧大地以为庐。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RexKing6's Note">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MobileNet
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-06 22:05:21" itemprop="dateCreated datePublished" datetime="2019-07-06T22:05:21+08:00">2019-07-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-10 19:36:07" itemprop="dateModified" datetime="2021-07-10T19:36:07+08:00">2021-07-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span id="/2019/07/06/MobileNet/" class="post-meta-item leancloud_visitors" data-flag-title="MobileNet" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>转载自：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/70703846">轻量级神经网络“巡礼”（二）—— MobileNet，从V1到V3</a>。</p>
<p>自从2017年由谷歌公司提出，MobileNet可谓是轻量级网络中的Inception，经历了一代又一代的更新。成为了学习轻量级网络的必经之路。</p>
<h1 id="MobileNet-V1"><a href="#MobileNet-V1" class="headerlink" title="MobileNet V1"></a>MobileNet V1</h1><p><img src="http://image.rexking6.top/img/clip1562422061.png" alt=""></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.04861">CVPR2017：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></p>
<p>2017年4月，谷歌提出MobileNetV1，这一专注于在移动设备上的轻量级神经网络。一直都有一个争议，说MobileNetV1怎么和Xception的网络block结构一样，都大量用到了深度可分离？</p>
<p>其实这里有个小插曲： MobileNetV1在<a target="_blank" rel="noopener" href="http://arxiv.org">arxiv</a>上的介绍是：</p>
<p><img src="http://image.rexking6.top/img/clip1562422190.png" alt=""></p>
<p>可以看到MobileNetV1是在2017年4月才提交的v1版本，但是</p>
<p><img src="http://image.rexking6.top/img/clip1562422204.png" alt=""></p>
<p>Xception是早在2016年10月v1版本就提出来了。那么，真的是MobileNet“抄袭”了Xception吗？其实并不是的，在<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1610.02357v1.pdf">Xception v1版本论文</a>当中有这样的一句话：</p>
<p><img src="http://image.rexking6.top/img/clip1562422232.png" alt=""></p>
<p>而这个Andew Howard是谁呢？没错，就是MobileNetV1的作者。而在<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1610.02357.pdf">Xception v3论文版本</a>中，一句话就变成了：</p>
<p><img src="http://image.rexking6.top/img/clip1562422288.png" alt=""></p>
<p>真相只有一个： 2016年6月，谷歌提出了MobileNetV1，由于各种原因当时没有挂上arxiv，一直到2017年4月才提交。好巧不巧，谷歌的另一团队，同时提出了Xception。所有才有了两个结构都是基于深度可分离卷积的相似争论。</p>
<p>其实介绍MobileNetV1（以下简称V1）只有一句话，<strong>MobileNetV1就是把VGG中的标准卷积层换成深度可分离卷积就可以了。</strong></p>
<p>那么，这个<strong>深度可分离卷积是什么</strong>？</p>
<h2 id="深度可分离卷积"><a href="#深度可分离卷积" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h2><p><strong>深度可分离卷积</strong>（<em>depthwise separable convolution</em>），根据史料记载，可追溯到2012年的论文<a href="https://link.zhihu.com/?target=https%3A//www.researchgate.net/profile/Christophe_Garcia2/publication/230867026_Simplifying_ConvNets_for_Fast_Learning/links/54ae96f60cf29661a3d39931.pdf">Simplifying ConvNets for Fast Learning</a>，作者提出了可分离卷积的概念（下图(a)）：</p>
<p><img src="http://image.rexking6.top/img/clip1562422339.png" alt=""></p>
<p>Laurent Sifre博士2013年在谷歌实习期间，将可分离卷积拓展到了深度（depth），并且在他的博士论文<a href="https://link.zhihu.com/?target=http%3A//www.cmapx.polytechnique.fr/~sifre/research/phd_sifre.pdf">Rigid-motion scattering for image classification</a>中有详细的描写，感兴趣的同学可以去看看论文。</p>
<p>可分离卷积主要有两种类型：<strong>空间可分离卷积</strong>和<strong>深度可分离卷积</strong>。</p>
<h2 id="空间可分离"><a href="#空间可分离" class="headerlink" title="空间可分离"></a>空间可分离</h2><p>顾名思义，空间可分离就是将一个大的卷积核变成两个小的卷积核，比如将一个3×3的核分成一个3×1和一个1×3的核：</p>
<p><img src="http://image.rexking6.top/img/clip1562422385.png" alt=""></p>
<p>由于空间可分离卷积不在MobileNet的范围内，就不说了。</p>
<h2 id="深度可分离卷积-1"><a href="#深度可分离卷积-1" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h2><p><img src="http://image.rexking6.top/img/clip1562422406.png" alt=""></p>
<p><strong>深度可分离卷积</strong>就是<strong>将普通卷积拆分成为一个深度卷积和一个逐点卷积</strong>。</p>
<p>我们先来看一下标准的卷积操作：</p>
<p><img src="http://image.rexking6.top/img/clip1562422418.png" alt=""></p>
<p>输入一个12×12×3的一个输入特征图，经过5×5×3的卷积核卷积得到一个8×8×1的输出特征图。如果此时我们有256个特征图，我们将会得到一个8×8×256的输出特征图。</p>
<p>以上就是标准卷积做干的活。那深度卷积和逐点卷积呢？</p>
<h2 id="深度卷积"><a href="#深度卷积" class="headerlink" title="深度卷积"></a>深度卷积</h2><p><img src="http://image.rexking6.top/img/clip1562422441.png" alt=""></p>
<p>与标准卷积网络不一样的是，我们将<strong>卷积核拆分成为但单通道形式</strong>，在<strong>不改变输入特征图像的深度</strong>的情况下，对<strong>每一通道进行卷积操作</strong>，这样就得到了<strong>和输入特征图通道数一致的输出特征图</strong>。如上图：输入12×12×3的特征图，经过5×5×1×3的深度卷积之后，得到了8×8×3的输出特征图。输入个输出的维度是不变的3。这样就会有一个问题，通道数太少，特征图的维度太少，能获取到足够的有效信息吗？</p>
<h2 id="逐点卷积"><a href="#逐点卷积" class="headerlink" title="逐点卷积"></a>逐点卷积</h2><p><strong>逐点卷积就是1×1卷积</strong>。主要作用就是对特征图进行升维和降维，如下图：</p>
<p><img src="http://image.rexking6.top/img/clip1562422461.png" alt=""></p>
<p>在深度卷积的过程中，我们得到了8×8×3的输出特征图，我们用256个1×1×3的卷积核对输入特征图进行卷积操作，输出的特征图和标准的卷积操作一样都是8×8×256了。</p>
<p><strong>标准卷积与深度可分离卷积的过程对比</strong>如下：</p>
<p><img src="http://image.rexking6.top/img/clip1562422479.png" alt=""></p>
<h2 id="为什么要深度可分离卷积？"><a href="#为什么要深度可分离卷积？" class="headerlink" title="为什么要深度可分离卷积？"></a>为什么要深度可分离卷积？</h2><p>这个问题很好回答，<strong>如果有一个方法能让你用更少的参数，更少的运算，但是能达到差的不是很多的结果，你会使用吗？</strong></p>
<p>深度可分离卷积就是这样的一个方法。我们首先来计算一下<strong>标准卷积的参数量与计算量</strong>。</p>
<p><img src="http://image.rexking6.top/img/clip1562422500.png" alt=""></p>
<h3 id="标准卷积的参数量"><a href="#标准卷积的参数量" class="headerlink" title="标准卷积的参数量"></a>标准卷积的参数量</h3><p>卷积核的尺寸是 $D_K×D_K×M$，一共有 $N$ 个，所以标准卷积的参数量是：</p>
<p><img src="http://image.rexking6.top/img/clip1562422529.png" alt=""></p>
<h3 id="标准卷积的计算量"><a href="#标准卷积的计算量" class="headerlink" title="标准卷积的计算量"></a>标准卷积的计算量</h3><p>卷积核的尺寸是 $D_K×D_K×M$，一共有 $N$ 个，每一个都要进行 $D_W×D_H$ 次运算，所以标准卷积的计算量是：</p>
<p><img src="http://image.rexking6.top/img/clip1562422614.png" alt=""></p>
<p>标准卷积算完了，我们接下来计算<strong>深度可分离卷积的参数量和计算量</strong>：</p>
<p><img src="http://image.rexking6.top/img/clip1562422627.png" alt=""></p>
<h3 id="深度可分离卷积的参数量"><a href="#深度可分离卷积的参数量" class="headerlink" title="深度可分离卷积的参数量"></a>深度可分离卷积的参数量</h3><p><strong>深度可分离卷积的参数量</strong>由<strong>深度卷积</strong>和<strong>逐点卷积</strong>两部分组成：</p>
<p><strong>深度卷积</strong>的卷积核尺寸 $D_K×D_K×M$；<strong>逐点卷积</strong>的卷积核尺寸为 $1×1×M$，一共有 $N$ 个，所以<strong>深度可分离卷积的参数量</strong>是：</p>
<p><img src="http://image.rexking6.top/img/clip1562422674.png" alt=""></p>
<h3 id="深度可分离卷积的计算量"><a href="#深度可分离卷积的计算量" class="headerlink" title="深度可分离卷积的计算量"></a>深度可分离卷积的计算量</h3><p><strong>深度可分离卷积的计算量</strong>也是由<strong>深度卷积</strong>和<strong>逐点卷积</strong>两部分组成：</p>
<p><strong>深度卷积</strong>的卷积核尺寸 $D_K×D_K×M$，一共要做 $D_W×D_H$ 次乘加运算；<strong>逐点卷积</strong>的卷积核尺寸为 $1×1×M$，有 $N$ 个，一共要做 $D_W×D_H$ 次乘加运算，所以<strong>深度可分离卷积的计算量</strong>是：</p>
<p><img src="http://image.rexking6.top/img/clip1562422761.png" alt=""></p>
<p><strong>总的来说：</strong></p>
<p><img src="http://image.rexking6.top/img/clip1562422773.png" alt=""></p>
<p>可以参数数量和乘加操作的运算量均下降为原来的</p>
<p><img src="http://image.rexking6.top/img/clip1562422783.png" alt=""></p>
<p>我们通常所使用的是3×3的卷积核，也就是会下降到原来的<strong>九分之一到八分之一</strong>。</p>
<h3 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h3><p>输出为一个224×224×3的图像，VGG网络某层卷积输入的尺寸是112×112×64的特征图，卷积核为3×3×128，<strong>标准卷积的运算量</strong>是：</p>
<script type="math/tex; mode=display">
3×3×128×64×112×112 = 924844032</script><p><strong>深度可分离卷积的运算量</strong>是：</p>
<script type="math/tex; mode=display">
3×3×64×112×112+128×64×112×112 = 109985792</script><p>这一层，MobileNetV1所采用的<strong>深度可分离卷积计算量与标准卷积计算量的比值</strong>为：</p>
<script type="math/tex; mode=display">
109985792/924844032 = 0.1189</script><p>与我们所计算的九分之一到八分之一一致。</p>
<h2 id="V1卷积层"><a href="#V1卷积层" class="headerlink" title="V1卷积层"></a>V1卷积层</h2><p><img src="http://image.rexking6.top/img/clip1562423163.png" alt=""></p>
<p>上图左边是标准卷积层，右边是V1的卷积层，虚线处是不相同点。V1的卷积层，首先使用3×3的深度卷积提取特征，接着是一个BN层，随后是一个ReLU层，在之后就会逐点卷积，最后就是BN和ReLU了。这也很符合深度可分离卷积，<strong>将左边的标准卷积拆分成右边的一个深度卷积和一个逐点卷积</strong>。</p>
<h3 id="ReLU6"><a href="#ReLU6" class="headerlink" title="ReLU6"></a>ReLU6</h3><p><img src="http://image.rexking6.top/img/clip1562423186.png" alt=""></p>
<p>上图左边是普通的ReLU，对于大于0的值不进行处理，右边是ReLU6，当输入的值大于6的时候，返回6，relu6“具有一个边界”。作者认为<strong>ReLU6作为非线性激活函数，在低精度计算下具有更强的鲁棒性</strong>。（这里所说的“低精度”，我看到有人说不是指的float16，而是指的定点运算(fixed-point arithmetic)）</p>
<p>现在就有一个问题，<strong>标准卷积核深度可分离卷积层到底对结果有什么样的影响呢？</strong></p>
<p>上实验。</p>
<p><img src="http://image.rexking6.top/img/clip1562423217.png" alt=""></p>
<p>可以看到使用深度可分离卷积与标准卷积，<strong>参数和计算量能下降为后者的九分之一到八分之一</strong>左右。但是<strong>准确率只有下降极小的1％</strong>。</p>
<h2 id="V1网络结构"><a href="#V1网络结构" class="headerlink" title="V1网络结构"></a>V1网络结构</h2><p><img src="http://image.rexking6.top/img/clip1562423239.png" alt=""></p>
<p>MobileNet的网络结构如上图所示。首先是一个3x3的标准卷积，s2进行下采样。然后就是堆积深度可分离卷积，并且其中的部分深度卷积会利用s2进行下采样。然后采用平均池化层将feature变成1x1，根据预测类别大小加上全连接层，最后是一个softmax层。整个网络有28层，其中深度卷积层有13层。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>V1论文中还有一部分对V1网络再进行调整，在此就不赘述了，感兴趣的同学可以去看看原论文。</p>
<p>V1的效果到底好不好，作者将V1与大型网络GoogleNet和VGG16进行了比较：</p>
<p><img src="http://image.rexking6.top/img/clip1562423290.png" alt=""></p>
<p>可以发现，作为轻量级网络的V1在计算量小于GoogleNet，参数量差不多是在一个数量级的基础上，在分类效果上比GoogleNet还要好，这就是要得益于深度可分离卷积了。VGG16的计算量参数量比V1大了30倍，但是结果也仅仅只高了1%不到。</p>
<p>目标检测，在COCO数据集上的结果：</p>
<p><img src="http://image.rexking6.top/img/clip1562423308.png" alt=""></p>
<p>对了，作者还在论文中分析整个了网络的参数和计算量分布，如下图所示。可以看到整个计算量基本集中在1x1卷积上。对于参数也主要集中在1x1卷积，除此之外还有就是全连接层占了一部分参数。</p>
<p><img src="http://image.rexking6.top/img/clip1562423322.png" alt=""></p>
<h1 id="MobileNet-V2"><a href="#MobileNet-V2" class="headerlink" title="MobileNet V2"></a>MobileNet V2</h1><p> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.04861">CVPR2018：MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p>
<p>MobileNetV1（以下简称：V1）过后，我们就要讨论讨论MobileNetV2（以下简称：V2）了。为了能更好地讨论V2，我们首先再回顾一下V1：</p>
<h2 id="回顾MobileNet-V1"><a href="#回顾MobileNet-V1" class="headerlink" title="回顾MobileNet V1"></a>回顾MobileNet V1</h2><p><strong>V1核心思想</strong>是采用 <strong>深度可分离卷积</strong> 操作。在相同的权值参数数量的情况下，相较标准卷积操作，可以减少数倍的计算量，从而达到提升网络运算速度的目的。</p>
<p>V1的block如下图所示：</p>
<p><img src="http://image.rexking6.top/img/clip1562423416.png" alt=""></p>
<p>首先利用3×3的深度可分离卷积提取特征，然后利用1×1的卷积来扩张通道。用这样的block堆叠起来的MobileNetV1既能较少不小的参数量、计算量，提高网络运算速度，又能的得到一个接近于标准卷积的还不错的结果，看起来是很美好的。</p>
<p>但是有人在实际使用的时候， 发现深度卷积部分的卷积核比较容易训废掉：训完之后发现深度卷积训出来的卷积核有不少是空的：</p>
<p><img src="http://image.rexking6.top/img/clip1562423441.png" alt=""></p>
<p>作者认为这是<strong>ReLU</strong>这个激活函数的锅。</p>
<h2 id="ReLU做了些啥？"><a href="#ReLU做了些啥？" class="headerlink" title="ReLU做了些啥？"></a>ReLU做了些啥？</h2><p>V2的论文中，作者也有这样的一个解释。这是将低维流形的ReLU变换embedded到高维空间中的的例子。</p>
<p><img src="http://image.rexking6.top/img/clip1562423505.png" alt=""></p>
<p>我们在这里抛弃掉流形这个概念，通俗理解一下。</p>
<p>假设在2维空间有一组由 $m$ 个点组成的螺旋线 $X_m$ 数据（如input），利用随机矩阵 $T$ 映射到 $n$ 维空间上并进行ReLU运算，即：</p>
<p><img src="http://image.rexking6.top/img/clip1562423541.png" alt=""></p>
<p>其中，$X_m$ 被随机矩阵 $T$ 映射到了 $n$ 维空间：</p>
<p><img src="http://image.rexking6.top/img/clip1562423561.png" alt=""></p>
<p>再利用随机矩阵 $T$ 的逆矩阵 $T^{-1}$，将 $y$ 映射回2维空间当中：</p>
<p><img src="http://image.rexking6.top/img/clip1562423582.png" alt=""></p>
<p><strong>全过程如下表示</strong>：</p>
<p><img src="http://image.rexking6.top/img/clip1562423595.png" alt=""></p>
<p>换句话说，<strong>就是对一个n维空间中的一个“东西”做ReLU运算，然后（利用T的逆矩阵T-1恢复）对比ReLU之后的结果与Input的结果相差有多大</strong>。</p>
<p>可以看到：</p>
<p><img src="http://image.rexking6.top/img/clip1562423609.png" alt=""></p>
<p>当n = 2, 3时，与Input相比有很大一部分的信息已经丢失了。而当n = 15到30，还是有相当多的地方被保留了下来。</p>
<p>也就是说，<strong>对低维度做ReLU运算，很容易造成信息的丢失。而在高维度进行ReLU运算的话，信息的丢失则会很少。</strong></p>
<p><strong>这就解释了为什么深度卷积的卷积核有不少是空</strong>。发现了问题，我们就能更好地解决问题。针对这个问题，可以这样解决：既然是ReLU导致的信息损耗，<strong>将ReLU替换成线性激活函数</strong>。</p>
<h2 id="Linear-bottleneck"><a href="#Linear-bottleneck" class="headerlink" title="Linear bottleneck"></a>Linear bottleneck</h2><p>我们当然不能把所有的激活层都换成线性的啊，所以我们就悄咪咪的把最后的那个ReLU6换成Linear。（<em>至于为什么换最后一个ReLU6而不换第一个和第二个ReLU6，看到后面就知道了。</em>）</p>
<p><img src="http://image.rexking6.top/img/clip1562423644.png" alt=""></p>
<p>作者将这个部分称之为<strong>linear bottleneck</strong>。对，就是论文名中的那个linear bottleneck。</p>
<h2 id="Expansion-layer"><a href="#Expansion-layer" class="headerlink" title="Expansion layer"></a>Expansion layer</h2><p>现在还有个问题是，<strong>深度卷积本身没有改变通道的能力，来的是多少通道输出就是多少通道</strong>。如果来的通道很少的话，DW深度卷积只能在低维度上工作，这样效果并不会很好，所以<strong>我们要“扩张”通道</strong>。既然我们已经知道<strong>PW逐点卷积也就是1×1卷积可以用来升维和降维</strong>，那就可以<strong>在DW深度卷积之前使用PW卷积进行升维（升维倍数为 $t$，$t=6$），再在一个更高维的空间中进行卷积操作来提取特征</strong>：</p>
<p><img src="http://image.rexking6.top/img/clip1562423696.png" alt=""></p>
<p>也就是说，不管输入通道数是多少，经过第一个PW逐点卷积升维之后，深度卷积都是在相对的更高6倍维度上进行工作。</p>
<p><img src="http://image.rexking6.top/img/clip1562423707.png" alt=""></p>
<h2 id="Inverted-residuals"><a href="#Inverted-residuals" class="headerlink" title="Inverted residuals"></a>Inverted residuals</h2><p>回顾V1的网络结构，我们发现V1很像是一个直筒型的VGG网络。我们想像Resnet一样复用我们的特征，所以我们引入了<strong>shortcut结构</strong>，这样V2的block就是如下图形式：</p>
<p><img src="http://image.rexking6.top/img/clip1562423726.png" alt=""></p>
<p>对比一下V1和V2：</p>
<p><img src="http://image.rexking6.top/img/clip1562423739.png" alt=""></p>
<p>可以发现，都采用了 $1×1\rightarrow 3×3 \rightarrow 1 × 1$ 的模式，以及都使用Shortcut结构。但是不同点呢：</p>
<ul>
<li>ResNet 先降维（0.25倍）、卷积、再升维。</li>
<li>MobileNetV2 则是先升维（6倍）、卷积、再降维。</li>
</ul>
<p>刚好V2的block刚好与Resnet的block相反，作者将其命名为<strong>Inverted residuals</strong>。就是论文名中的<strong>Inverted residuals</strong>。</p>
<h2 id="V2的block"><a href="#V2的block" class="headerlink" title="V2的block"></a>V2的block</h2><p>至此，V2的最大的创新点就结束了，我们再总结一下V2的block：</p>
<p><img src="http://image.rexking6.top/img/clip1562423823.png" alt=""></p>
<p>将V1和V2的block进行一下对比：</p>
<p><img src="http://image.rexking6.top/img/clip1562423835.png" alt=""></p>
<p>左边是v1的block，没有Shortcut并且带最后的ReLU6。</p>
<p>右边是v2的加入了1×1升维，引入Shortcut并且去掉了最后的ReLU，改为Linear。步长为1时，先进行1×1卷积升维，再进行深度卷积提取特征，再通过Linear的逐点卷积降维。将input与output相加，形成残差结构。步长为2时，因为input与output的尺寸不符，因此不添加shortcut结构，其余均一致。</p>
<h2 id="V2的网络结构"><a href="#V2的网络结构" class="headerlink" title="V2的网络结构"></a>V2的网络结构</h2><p><img src="http://image.rexking6.top/img/clip1562424683.png" alt=""></p>
<p>28×28×32那一层的步长为2的话，输出应该是14×14，应该是一处错误。按照作者论文里的说法，自己修改了一下：</p>
<p><img src="http://image.rexking6.top/img/clip1562424698.png" alt=""></p>
<h2 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h3><p><img src="http://image.rexking6.top/img/clip1562424879.png" alt=""></p>
<p>图像分类的实验，主要是在以上的网络上进行的，ShuffleNet是V1的版本使用了分组卷积和shuffling, 也使用了类似的残差结构(c)中的(b)。</p>
<p>结果如下：</p>
<p><img src="http://image.rexking6.top/img/clip1562424914.png" alt=""></p>
<p>详细对比如下：</p>
<p><img src="http://image.rexking6.top/img/clip1562424932.png" alt=""></p>
<h3 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h3><h4 id="SSDLite"><a href="#SSDLite" class="headerlink" title="SSDLite"></a>SSDLite</h4><p>目标检测方面，作者首先提出了SSDLite。就是对SSD结构做了修改，将SSD的预测层中所有标准卷积替换为深度可分离卷积。作者说这样参数量和计算成本大大降低，计算更高效。SSD与SSDLite对比：</p>
<p><img src="http://image.rexking6.top/img/clip1562424963.png" alt=""></p>
<p>应用在物体检测任务上，V1与常用检测网络的对比：</p>
<p><img src="http://image.rexking6.top/img/clip1562424978.png" alt=""></p>
<p>可以看到，基于MobileNetV2的SSDLite在COCO数据集上超过了YOLOv2，并且大小小10倍速度快20倍。</p>
<h3 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h3><p><img src="http://image.rexking6.top/img/clip1562425011.png" alt=""></p>
<p>分割效果如下：</p>
<p><img src="http://image.rexking6.top/img/clip1562425033.png" alt=""></p>
<h2 id="V1-VS-V2"><a href="#V1-VS-V2" class="headerlink" title="V1 VS V2"></a>V1 VS V2</h2><p><img src="http://image.rexking6.top/img/clip1562425088.png" alt=""></p>
<p>可以看到，虽然V2的层数比V1的要多很多，但是FLOPs，参数以及CPU耗时都是比V1要好的。</p>
<p>V1 V2在google Pixel 1手机上在Image Classification任务的对比：</p>
<p><img src="http://image.rexking6.top/img/clip1562425107.png" alt=""></p>
<p>MobileNet V2模型在整体速度范围内可以更快实现相同的准确性。</p>
<p>目标检测和语义分割的结果：</p>
<p><img src="http://image.rexking6.top/img/clip1562425140.png" alt=""></p>
<p>综上，<strong>MobileNetV2 提供了一个非常高效的面向移动设备的模型，可以用作许多视觉识别任务的基础</strong>。</p>
<p>但是在我实际应用V1V2时，V1的效果都要稍微好一点。上一张<a target="_blank" rel="noopener" href="https://gluon-cv.mxnet.io/model_zoo/classification.html">gluonCV</a>的结果图，和我的实现也差不多：</p>
<p><img src="http://image.rexking6.top/img/clip1562425183.png" alt=""></p>
<h1 id="MobileNet-V3"><a href="#MobileNet-V3" class="headerlink" title="MobileNet V3"></a>MobileNet V3</h1><p>V1，V2都看完了，现在就来到了MobileNetV3（以下简称V3）。</p>
<p><img src="http://image.rexking6.top/img/clip1562425224.png" alt=""></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.02244.pdf">Searching for MobileNetV3</a></p>
<p>MobileNetV3，是谷歌在2019年3月21日提出的网络架构。首先，引入眼帘的是这篇文章的标题，“searching”一词就把V3的论文的核心观点展示了出来——用<strong>神经结构搜索（NAS）</strong>来完成V3。</p>
<p>由于真的没有接触过NAS，所以V3就讲讲其他的，除NAS之外的东西吧。</p>
<p>先上结果：</p>
<p><img src="http://image.rexking6.top/img/clip1562425288.png" alt=""></p>
<p>可以看到，在同一大小的计算量下，V3在ImageNet上的结果都是最好的。</p>
<h2 id="相关技术"><a href="#相关技术" class="headerlink" title="相关技术"></a>相关技术</h2><ol>
<li>网络的架构基于NAS实现的MnasNet（效果比MobileNetV2好）；</li>
<li>引入MobileNet V1的深度可分离卷积；</li>
<li>引入MobileNet V2的具有线性瓶颈的倒残差结构；</li>
<li>引入基于squeeze and excitation结构的轻量级注意力模型（SE）；</li>
<li>使用了一种新的激活函数 $h-swish(x)$ ；</li>
<li>网络结构搜索中，结合两种技术：资源受限的NAS（platform-aware NAS）与NetAdapt；</li>
<li>修改了MobileNetV2网络端部最后阶段。</li>
</ol>
<h2 id="激活函数h-swish"><a href="#激活函数h-swish" class="headerlink" title="激活函数h-swish"></a>激活函数h-swish</h2><h3 id="swish"><a href="#swish" class="headerlink" title="swish"></a>swish</h3><p>h-swish是基于swish的改进，swish最早是在谷歌大脑2017的论文<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1710.05941">Searching for Activation functions</a>所提出（又是Searching for）。</p>
<p><img src="http://image.rexking6.top/img/clip1562425426.png" alt=""></p>
<p>swish论文的作者认为，Swish具备无上界有下界、平滑、非单调的特性。并且Swish在深层模型上的效果优于ReLU。仅仅使用Swish单元替换ReLU就能把MobileNet,NASNetA在 ImageNet上的top-1分类准确率提高0.9%，Inception-ResNet-v的分类准确率提高0.6%。</p>
<p>V3也利用swish当作为ReLU的替代时，它可以显著提高神经网络的精度。但是呢，作者认为这种非线性激活函数虽然提高了精度，但在嵌入式环境中，是有不少的成本的。原因就是在移动设备上计算sigmoid函数是非常明智的选择。所以提出了h-swish。</p>
<h3 id="h-swish"><a href="#h-swish" class="headerlink" title="h-swish"></a>h-swish</h3><p>可以用一个近似函数来逼急这个swish，让swish变得硬(hard)。作者选择的是基于ReLU6，作者认为几乎所有的软件和硬件框架上都可以使用ReLU6的优化实现。其次，它能在特定模式下消除了由于近似sigmoid的不同实现而带来的潜在的数值精度损失。</p>
<p><img src="http://image.rexking6.top/img/clip1562425467.png" alt=""></p>
<p>下图是Sigmoid和swish的hard、soft形式：</p>
<p><img src="http://image.rexking6.top/img/clip1562425482.png" alt=""></p>
<p>我们可以简单的认为，hard形式是soft形式的低精度化。作者认为swish的表现和其他非线性相比，能够将过滤器的数量减少到16个的同时保持与使用ReLU或swish的32个过滤器相同的精度，这节省了3毫秒的时间和1000万MAdds的计算量。</p>
<p>并且同时，作者认为<strong>随着网络的深入，应用非线性激活函数的成本会降低，能够更好的减少参数量</strong>。作者发现swish的大多数好处都是通过在更深的层中使用它们实现的。因此，<strong>在V3的架构中，只在模型的后半部分使用h-swish（HS）</strong>。</p>
<h2 id="网络结构搜索NAS"><a href="#网络结构搜索NAS" class="headerlink" title="网络结构搜索NAS"></a>网络结构搜索NAS</h2><p>主要结合两种技术：<strong>资源受限的NAS（platform-aware NAS）</strong>与<strong>NetAdapt</strong>。</p>
<p><strong>资源受限的NAS</strong>，用于在计算和参数量受限的前提下搜索网络来优化各个块（block），所以称之为<strong>模块级搜索（Block-wise Search）</strong> 。</p>
<p><strong>NetAdapt</strong>，用于对各个模块确定之后网络层的微调每一层的卷积核数量，所以称之为<strong>层级搜索（Layer-wise Search）</strong>。</p>
<p>一旦通过体系结构搜索找到模型，我们就会发现<strong>最后一些层以及一些早期层计算代价比较高昂</strong>。于是作者决定对这些架构进行一些修改，以减少这些慢层（slow layers）的延迟，同时保持准确性。这些修改显然超出了当前搜索的范围。</p>
<h2 id="对V2最后阶段的修改"><a href="#对V2最后阶段的修改" class="headerlink" title="对V2最后阶段的修改"></a>对V2最后阶段的修改</h2><p>作者认为，当前模型是基于V2模型中的<strong>倒残差结构</strong>和相应的变体（如下图）。使用<strong>1×1卷积</strong>来构建最后层，这样可以便于拓展到更高维的特征空间。这样做的好处是，在预测时，有更多更丰富的特征来满足预测，但是同时也<strong>引入了额外的计算成本与延时</strong>。</p>
<p><img src="http://image.rexking6.top/img/clip1562425551.png" alt=""></p>
<p>所以，需要改进的地方就是要<strong>保留高维特征的前提下减小延时</strong>。首先，还是将1×1层放在到最终平均池之后。这样的话最后一组特征现在不是7x7（下图V2结构红框），而是以1x1计算（下图V3结构黄框）。</p>
<p><img src="http://image.rexking6.top/img/clip1562425566.png" alt=""></p>
<p><img src="http://image.rexking6.top/img/clip1562425578.png" alt=""></p>
<p>这样的好处是，<strong>在计算和延迟方面，特征的计算几乎是免费的</strong>。最终，重新设计完的结构如下：</p>
<p><img src="http://image.rexking6.top/img/clip1562425592.png" alt=""></p>
<p>在不会造成精度损失的同时，减少10ms耗时，提速15%，减小了30m的MAdd操作。</p>
<h2 id="V3的block"><a href="#V3的block" class="headerlink" title="V3的block"></a>V3的block</h2><p>综合以上，V3的block结构如下所示：</p>
<p><img src="http://image.rexking6.top/img/clip1562425631.png" alt=""></p>
<p>与V2的block相比较：</p>
<p><img src="http://image.rexking6.top/img/clip1562425642.png" alt=""></p>
<h2 id="V3的网络结构"><a href="#V3的网络结构" class="headerlink" title="V3的网络结构"></a>V3的网络结构</h2><p>MobileNet V3定义了两个模型: <strong>MobileNet V3-Large</strong>和<strong>MobileNet V3-Small</strong>。V3-Large是针对<strong>高资源</strong>情况下的使用，相应的，V3-small就是针对<strong>低资源</strong>情况下的使用。两者都是基于之前的简单讨论的NAS。</p>
<h3 id="MobileNet-V3-Large"><a href="#MobileNet-V3-Large" class="headerlink" title="MobileNet V3-Large"></a>MobileNet V3-Large</h3><p><img src="http://image.rexking6.top/img/clip1562425687.png" alt=""></p>
<h3 id="MobileNet-V3-Small"><a href="#MobileNet-V3-Small" class="headerlink" title="MobileNet V3-Small"></a>MobileNet V3-Small</h3><p><img src="http://image.rexking6.top/img/clip1562425704.png" alt=""></p>
<p>就像之前所说的：只有在更深层次使用h-swish才能得到比较大的好处。所以在上面的网络模型中，不论大小，作者只在模型的后半部分使用h-swish。</p>
<p>用谷歌pixel 1/2/3来对大小V3进行测试的结果。</p>
<p><img src="http://image.rexking6.top/img/clip1562425717.png" alt=""></p>
<h2 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="Image-Classification-1"><a href="#Image-Classification-1" class="headerlink" title="Image Classification"></a>Image Classification</h3><p><img src="http://image.rexking6.top/img/clip1562425738.png" alt=""></p>
<h3 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h3><p><img src="http://image.rexking6.top/img/clip1562425758.png" alt=""></p>
<h3 id="Semantic-Segmentation-1"><a href="#Semantic-Segmentation-1" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h3><p><img src="http://image.rexking6.top/img/clip1562425785.png" alt=""></p>
<p><img src="http://image.rexking6.top/img/clip1562425797.png" alt=""></p>
<h1 id="为什么MobileNet会这么快？"><a href="#为什么MobileNet会这么快？" class="headerlink" title="为什么MobileNet会这么快？"></a>为什么MobileNet会这么快？</h1><p>在写这篇文章的时候看到了一篇文章<a href="https://link.zhihu.com/?target=https%3A//medium.com/yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d">Why MobileNet and Its Variants (e.g. ShuffleNet) Are Fast？</a>，这也让我有了一样的一个问题，这篇文章主要是从结构方面进行了讨论，从深度可分离卷积到组卷积的参数计算量等，因为之前的文章都有写过，在这里就不赘述了，感兴趣的同学可以翻阅下之前的文章。</p>
<p>在这里换一个的角度。我们直接从<strong>用时多少的角度</strong>去讨论下这个问题。</p>
<p>下图来自Caffe作者贾扬清的博士论文：</p>
<p><img src="http://image.rexking6.top/img/clip1562425833.png" alt=""></p>
<p>该图是AlexNet网络中不同层的GPU和CPU的时间消耗，我们可以清晰的看到，不管是在GPU还是在CPU运行，<strong>最重要的“耗时杀手”就是conv，卷积层</strong>。也就是说，<strong>想要提高网络的运行速度，就得到提高卷积层的计算效率</strong>。</p>
<p>我们以MobileNet V1为主，看看MobileNet的资源分布情况：</p>
<p><img src="http://image.rexking6.top/img/clip1562425854.png" alt=""></p>
<p>可以看到，<strong>MobileNet的95%的计算都花费在了1×1的卷积上</strong>，那1×1卷积有什么好处吗？</p>
<p>我们都知道，卷积操作就是如下图所示的乘加运算：</p>
<p><img src="http://image.rexking6.top/img/v2-6428cf505ac1e9e1cf462e1ec8fe9a68_b.gif" alt=""></p>
<p>在计算机操作时，需要将其存入内存当中再操作（按照“行先序”）：</p>
<p><img src="http://image.rexking6.top/img/clip1562425901.png" alt=""></p>
<p>这样一来，特征图 $y_{11},y_{12},y_{21},y_{22}$ 的计算如下所示：</p>
<p><img src="http://image.rexking6.top/img/clip1562425935.png" alt=""></p>
<p>按照卷积计算，实线标注出卷积计算中的访存过程（对应数据相乘），我们可以看到这一过程是非常散乱和混乱的。直接用卷积的计算方式是比较愚蠢的。</p>
<p>这时候就要用到im2col操作。</p>
<h2 id="im2col"><a href="#im2col" class="headerlink" title="im2col"></a>im2col</h2><p>一句话来介绍im2col操作的话，就是<strong>通过牺牲空间的手段（约扩增 $K×K$ 倍），将特征图转换成庞大的矩阵来进行卷积计算</strong>。</p>
<p><img src="http://image.rexking6.top/img/clip1562425967.png" alt=""></p>
<p>其实思路非常简单：把每一次循环所需要的数据都排列成列向量，然后逐一堆叠起来形成矩阵（按通道顺序在列方向上拼接矩阵）。比如 $C_i×W_i×H_i$ 大小的输入特征图，$K×K$ 大小的卷积核，输出大小为 $C_o×W_o×H_o$，输入特征图将按需求被转换成$(K\times K)×(C_i\times W_o\times H_o)$ 的矩阵，卷积核将被转换成 $C_o×(K\times K)$ 的矩阵。</p>
<p><img src="http://image.rexking6.top/img/clip1562428062.png" alt=""></p>
<p>然后调用<strong>GEMM（矩阵乘矩阵）库</strong>加速两矩阵相乘也就完成了卷积计算。由于<strong>按照计算需求排布了数据顺序，每次计算过程中总是能够依次访问特征图数据，极大地提高了计算卷积的速度。</strong> <em>（不光有GEMM，还有FFt（快速傅氏变换））</em></p>
<p><img src="http://image.rexking6.top/img/clip1562428094.png" alt=""></p>
<p>换一种表示方法能更好地理解，图片来自<a target="_blank" rel="noopener" href="https://hal.inria.fr/file/index/docid/112631/filename/p1038112283956.pdf">High Performance Convolutional Neural Networks for Document Processing</a>：</p>
<p><img src="http://image.rexking6.top/img/clip1562428126.png" alt=""></p>
<p>这样可以更清楚的看到卷积的定义进行卷积操作（上图上半部分），<strong>内存访问会非常不规律</strong>，以至于性能会非常糟糕。而Im2col()以一种<strong>内存访问规则的方式排列数据</strong>，<strong>虽然Im2col操作增加了很多数据冗余，但使用Gemm的性能优势超过了这个数据冗余的劣势</strong>。</p>
<p>所以标准卷积运算大概就是这样的一个过程：</p>
<p><img src="http://image.rexking6.top/img/clip1562428149.png" alt=""></p>
<p>那我们现在回到1×1的卷积上来，有点特殊。按照我们之前所说的，1×1的卷积的原始储存结构和进行im2col的结构如下图所示：</p>
<p><img src="http://image.rexking6.top/img/clip1562428161.png" alt=""></p>
<p>可以看到矩阵是完全相同的。标准卷积运算和1×1卷积运算对比如下图：</p>
<p><img src="http://image.rexking6.top/img/clip1562428172.png" alt=""></p>
<p>也就是说，<strong>1x1卷积不需要im2col的过程</strong>，所以底层可以有更快的实现，拿起来就能直接算，大大节省了数据重排列的时间和空间。</p>
<p>当然，这些也不是那么绝对的，因为毕竟MobileNet速度快不快，与CONV1x1运算的优化程度密切相关。如果使用了定制化的硬件（比如用FPGA直接实现3x3的卷积运算单元），那么im2col就失去了意义而且反而增加了开销。</p>
<p>回到之前的MobileNet的资源分布，95%的1×1卷积和优化的网络结构就是MobileNet能如此快的原因了。</p>
<p><img src="http://image.rexking6.top/img/clip1562428187.png" alt=""></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.04861.pdf">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.04381.pdf">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.02244.pdf">Searching for MobileNetV3</a></li>
<li><a target="_blank" rel="noopener" href="http://zpascal.net/cvpr2017/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf">Xception: Deep Learning with Depthwise Separable Convolutions</a></li>
<li><a target="_blank" rel="noopener" href="https://www.researchgate.net/profile/Christophe_Garcia2/publication/230867026_Simplifying_ConvNets_for_Fast_Learning/links/54ae96f60cf29661a3d39931.pdf">Simplifying ConvNets for Fast Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728">a-basic-introduction-to-separable-convolution</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31551004">CNN模型之MobileNet</a></li>
<li><a target="_blank" rel="noopener" href="https://cuijiahua.com/blog/2018/02/dl_6.html">网络解析（二）：MoblieNets详解</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011974639/article/details/79199306">轻量级网络—MobileNet论文解读</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/O2Bhn66cWCN_87P52jj8hQ">MobileNetV2：下一代边缘计算视觉网络</a></li>
<li><a target="_blank" rel="noopener" href="http://machinethink.net/blog/mobilenet-v2/">MobileNet version 2</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/287988785/answer/469932620">如何评价 Google 最新的模型 MnasNet？ - 曲晓峰的回答 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.pdf">Learning Semantic Image Representations at a Large Scale 贾扬清博士论文</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/dwyane12138/article/details/78449898">im2col的原理和实现</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/28385679/answer/44297845">在 Caffe 中如何计算卷积？ - 贾扬清的回答 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://hey-yahei.cn/2019/03/28/Conv-Family/index.html">漫谈卷积层</a></li>
<li><a target="_blank" rel="noopener" href="https://hal.inria.fr/file/index/docid/112631/filename/p1038112283956.pdf">High Performance Convolutional Neural Networks for Document Processing</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com//yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d">Why MobileNet and Its Variants (e.g. ShuffleNet) Are Fast</a></li>
</ul>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2019\03\21\Fisher线性判别\" rel="bookmark">Fisher线性判别</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2018\02\13\cs229中文笔记-一二\" rel="bookmark">cs229中文笔记(一二)</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2018\02\18\cs229中文笔记-七\" rel="bookmark">cs229中文笔记(七)</a></div>
    </li>
  </ul>

        <div class="reward-container">
  <div>一分一毛，也是心意。</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Run-Qing Chen 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="Run-Qing Chen 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Run-Qing Chen
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://blog.rexking6.top/2019/07/06/MobileNet/" title="MobileNet">https://blog.rexking6.top/2019/07/06/MobileNet/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/06/26/%E5%87%A0%E7%A7%8DNormalization%E7%AE%97%E6%B3%95/" rel="prev" title="几种Normalization算法">
      <i class="fa fa-chevron-left"></i> 几种Normalization算法
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/08/28/%E4%BD%BF%E7%94%A8-BibTeX-%E7%94%9F%E6%88%90%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E5%88%97%E8%A1%A8/" rel="next" title="使用 BibTeX 生成参考文献列表">
      使用 BibTeX 生成参考文献列表 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

    <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MobileNet-V1"><span class="nav-number">2.</span> <span class="nav-text">MobileNet V1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.1.</span> <span class="nav-text">深度可分离卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A9%BA%E9%97%B4%E5%8F%AF%E5%88%86%E7%A6%BB"><span class="nav-number">2.2.</span> <span class="nav-text">空间可分离</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF-1"><span class="nav-number">2.3.</span> <span class="nav-text">深度可分离卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.4.</span> <span class="nav-text">深度卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%90%E7%82%B9%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.5.</span> <span class="nav-text">逐点卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF%EF%BC%9F"><span class="nav-number">2.6.</span> <span class="nav-text">为什么要深度可分离卷积？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F"><span class="nav-number">2.6.1.</span> <span class="nav-text">标准卷积的参数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%AE%A1%E7%AE%97%E9%87%8F"><span class="nav-number">2.6.2.</span> <span class="nav-text">标准卷积的计算量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F"><span class="nav-number">2.6.3.</span> <span class="nav-text">深度可分离卷积的参数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%AE%A1%E7%AE%97%E9%87%8F"><span class="nav-number">2.6.4.</span> <span class="nav-text">深度可分离卷积的计算量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%81%87%E8%AE%BE"><span class="nav-number">2.6.5.</span> <span class="nav-text">假设</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V1%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">2.7.</span> <span class="nav-text">V1卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ReLU6"><span class="nav-number">2.7.1.</span> <span class="nav-text">ReLU6</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V1%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">2.8.</span> <span class="nav-text">V1网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">2.9.</span> <span class="nav-text">实验结果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MobileNet-V2"><span class="nav-number">3.</span> <span class="nav-text">MobileNet V2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9E%E9%A1%BEMobileNet-V1"><span class="nav-number">3.1.</span> <span class="nav-text">回顾MobileNet V1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ReLU%E5%81%9A%E4%BA%86%E4%BA%9B%E5%95%A5%EF%BC%9F"><span class="nav-number">3.2.</span> <span class="nav-text">ReLU做了些啥？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-bottleneck"><span class="nav-number">3.3.</span> <span class="nav-text">Linear bottleneck</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Expansion-layer"><span class="nav-number">3.4.</span> <span class="nav-text">Expansion layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Inverted-residuals"><span class="nav-number">3.5.</span> <span class="nav-text">Inverted residuals</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V2%E7%9A%84block"><span class="nav-number">3.6.</span> <span class="nav-text">V2的block</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V2%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">3.7.</span> <span class="nav-text">V2的网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-1"><span class="nav-number">3.8.</span> <span class="nav-text">实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-Classification"><span class="nav-number">3.8.1.</span> <span class="nav-text">Image Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Object-Detection"><span class="nav-number">3.8.2.</span> <span class="nav-text">Object Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SSDLite"><span class="nav-number">3.8.2.1.</span> <span class="nav-text">SSDLite</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Semantic-Segmentation"><span class="nav-number">3.8.3.</span> <span class="nav-text">Semantic Segmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V1-VS-V2"><span class="nav-number">3.9.</span> <span class="nav-text">V1 VS V2</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MobileNet-V3"><span class="nav-number">4.</span> <span class="nav-text">MobileNet V3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF"><span class="nav-number">4.1.</span> <span class="nav-text">相关技术</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0h-swish"><span class="nav-number">4.2.</span> <span class="nav-text">激活函数h-swish</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#swish"><span class="nav-number">4.2.1.</span> <span class="nav-text">swish</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#h-swish"><span class="nav-number">4.2.2.</span> <span class="nav-text">h-swish</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2NAS"><span class="nav-number">4.3.</span> <span class="nav-text">网络结构搜索NAS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9V2%E6%9C%80%E5%90%8E%E9%98%B6%E6%AE%B5%E7%9A%84%E4%BF%AE%E6%94%B9"><span class="nav-number">4.4.</span> <span class="nav-text">对V2最后阶段的修改</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V3%E7%9A%84block"><span class="nav-number">4.5.</span> <span class="nav-text">V3的block</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V3%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">4.6.</span> <span class="nav-text">V3的网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileNet-V3-Large"><span class="nav-number">4.6.1.</span> <span class="nav-text">MobileNet V3-Large</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileNet-V3-Small"><span class="nav-number">4.6.2.</span> <span class="nav-text">MobileNet V3-Small</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-2"><span class="nav-number">4.7.</span> <span class="nav-text">实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-Classification-1"><span class="nav-number">4.7.1.</span> <span class="nav-text">Image Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Detection"><span class="nav-number">4.7.2.</span> <span class="nav-text">Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Semantic-Segmentation-1"><span class="nav-number">4.7.3.</span> <span class="nav-text">Semantic Segmentation</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88MobileNet%E4%BC%9A%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="nav-number">5.</span> <span class="nav-text">为什么MobileNet会这么快？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#im2col"><span class="nav-number">5.1.</span> <span class="nav-text">im2col</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Run-Qing Chen"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Run-Qing Chen</p>
  <div class="site-description" itemprop="description">覆苍天以为衾，卧大地以为庐。</div>
</div>


   <div class="feed-link motion-element">
     <a href="/atom.xml" rel="alternate">
       <i class="fa fa-rss"></i>
       RSS
     </a>
   </div>
 
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">174</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/RexKing6" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;RexKing6" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1010026261@qq.com" title="E-Mail → mailto:1010026261@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.zxpblog.cn/" title="https:&#x2F;&#x2F;www.zxpblog.cn&#x2F;" rel="noopener" target="_blank">赵小平</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://whitepuffer.github.io/" title="https:&#x2F;&#x2F;whitepuffer.github.io&#x2F;" rel="noopener" target="_blank">江斓</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://kexue.fm/" title="https:&#x2F;&#x2F;kexue.fm&#x2F;" rel="noopener" target="_blank">科学空间</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yongyuan.name/" title="https:&#x2F;&#x2F;yongyuan.name&#x2F;" rel="noopener" target="_blank">袁勇</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/abcjennifer" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;abcjennifer" rel="noopener" target="_blank">Rachel Zhang</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://dmkf.xyz/" title="http:&#x2F;&#x2F;dmkf.xyz&#x2F;" rel="noopener" target="_blank">代码咖啡</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://wuxiaolong.me/" title="http:&#x2F;&#x2F;wuxiaolong.me&#x2F;" rel="noopener" target="_blank">吴小龙同学</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.tennfy.com/" title="http:&#x2F;&#x2F;www.tennfy.com&#x2F;" rel="noopener" target="_blank">TENNFY WU</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备16049735号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fab fa-accessible-icon"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Run-Qing Chen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">2.2m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">33:38</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"dOMRIGavgWnKuSQ5IqJS3ckT-gzGzoHsz","app_key":"qMh3SHPhOGOhYa5GA251PGcy","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
