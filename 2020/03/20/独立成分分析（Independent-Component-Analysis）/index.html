<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.rexking6.top","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#37c6c0","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"YS7HT61SEB","apiKey":"0fd1eba022e7883c76ff4a71aee2acdc","indexName":"blog_NAME","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"找不到关于 ${query} 的文章","hits_stats":"共找到 ${hits} 篇文章，花了 ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="...">
<meta property="og:type" content="article">
<meta property="og:title" content="独立成分分析（Independent Component Analysis）">
<meta property="og:url" content="https://blog.rexking6.top/2020/03/20/%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Independent-Component-Analysis%EF%BC%89/">
<meta property="og:site_name" content="RexKing6&#39;s Note">
<meta property="og:description" content="...">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://image.rexking6.top/img/201104191610509840.jpg">
<meta property="og:image" content="http://image.rexking6.top/img/20110419161051264.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1589275707.png">
<meta property="og:image" content="http://image.rexking6.top/img/20110419161115263.png">
<meta property="og:image" content="http://image.rexking6.top/img/201104191611205208.jpg">
<meta property="og:image" content="http://image.rexking6.top/img/2011041916112227.jpg">
<meta property="og:image" content="http://image.rexking6.top/img/clip1589365272.png">
<meta property="og:image" content="http://image.rexking6.top/img/201104191632562969.png">
<meta property="og:image" content="http://image.rexking6.top/img/201104191633061498.png">
<meta property="og:image" content="http://image.rexking6.top/img/201104191634444227.png">
<meta property="og:image" content="http://image.rexking6.top/img/201104191634454652.png">
<meta property="og:image" content="http://image.rexking6.top/img/201104191634478390.png">
<meta property="article:published_time" content="2020-03-20T04:21:48.000Z">
<meta property="article:modified_time" content="2021-07-10T11:39:16.997Z">
<meta property="article:author" content="Run-Qing Chen">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://image.rexking6.top/img/201104191610509840.jpg">

<link rel="canonical" href="https://blog.rexking6.top/2020/03/20/%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Independent-Component-Analysis%EF%BC%89/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>独立成分分析（Independent Component Analysis） | RexKing6's Note</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="RexKing6's Note" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RexKing6's Note</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/rexking6" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.rexking6.top/2020/03/20/%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Independent-Component-Analysis%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Run-Qing Chen">
      <meta itemprop="description" content="覆苍天以为衾，卧大地以为庐。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RexKing6's Note">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          独立成分分析（Independent Component Analysis）
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-20 12:21:48" itemprop="dateCreated datePublished" datetime="2020-03-20T12:21:48+08:00">2020-03-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-10 19:39:16" itemprop="dateModified" datetime="2021-07-10T19:39:16+08:00">2021-07-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span id="/2020/03/20/%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Independent-Component-Analysis%EF%BC%89/" class="post-meta-item leancloud_visitors" data-flag-title="独立成分分析（Independent Component Analysis）" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>15k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>综合转载于：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/jerrylead/archive/2011/04/19/2021071.html">独立成分分析（Independent Component Analysis）</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/jerrylead/archive/2011/04/19/2021221.html">ICA扩展描述</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/Tonywu2018/article/details/91490158">详解独立成分分析</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/de396e8cce15">独立成分（ICA）分析</a></li>
<li><a target="_blank" rel="noopener" href="http://www.dataivy.cn/blog/独立成分分析independent-component-analysis_ica/">独立成分分析Independent component analysis(ICA)</a></li>
</ul>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>上节提到的PCA是一种数据降维的方法，但是只对符合高斯分布的样本点比较有效，那么对于其他分布的样本，有没有主元分解的方法呢？</p>
<p>经典的鸡尾酒宴会问题（cocktail party problem）。假设在party中有 $n$ 个人，他们可以同时说话，我们也在房间中一些角落里共放置了 $n$ 个声音接收器（Microphone）用来记录声音。宴会过后，我们从 $n$ 个麦克风中得到了一组数据 $\{x^{(i)}(x_1^{(i)},x_2^{(i)},\dots,x_n^{(i)}),i=1,2,\dots,m\}$ ，$i$ 表示采样的时间顺序，也就是说共得到了 $m$ 组采样，每一组采样都是 $n$ 维的。我们的目标是单单从这 $m$ 组采样数据中分辨出每个人说话的信号。</p>
<p> 将第二个问题细化一下，有 $n$ 个信号源 $\text{s}(s_1,s_2,\dots,s_n)^T$，$s\in \mathbb R^n$，每一维都是一个人的声音信号，每个人发出的声音信号独立。$\rm A$ 是一个未知的混合矩阵（mixing matrix），用来组合叠加信号 $\rm s$，那么</p>
<script type="math/tex; mode=display">
\rm x=As</script><p>$\rm x$ 的意义在上文解释过，这里的 $\rm x$ 不是一个向量，是一个矩阵。其中每个列向量是 $x^{(i)}$，$x^{(i)}=\text{A}s^{(i)}$ 表示成图就是</p>
<p><img src="http://image.rexking6.top/img/201104191610509840.jpg" alt=""></p>
<p><img src="http://image.rexking6.top/img/20110419161051264.png" alt=""></p>
<p>$x^{(i)}$ 的每个分量都由 $s^{(i)}$ 的分量线性表示。$\rm A$ 和 $\rm s$ 都是未知的，$\rm x$ 是已知的，我们要想办法根据 $\rm x$ 来推出 $\rm s$。这个过程也称作为盲信号分离。</p>
<p>令 $\rm W=A^{-1}$，那么 $s^{(i)}=\text A^{-1}x^{(i)}=\rm Wx^{(i)}$，将 $\rm W$ 表示成</p>
<p><img src="http://image.rexking6.top/img/clip1589275707.png" alt=""></p>
<p>其中 $w_i\in\mathbb R^n$，其实就是将 $w_i$ 写成行向量形式。那么得到：</p>
<script type="math/tex; mode=display">
s_j^{(i)}=w_j^Tx^{(i)}</script><h1 id="ICA的不确定性"><a href="#ICA的不确定性" class="headerlink" title="ICA的不确定性"></a>ICA的不确定性</h1><p>由于 $\rm W$ 和 $\rm s$ 都不确定，那么在没有先验知识的情况下，无法同时确定这两个相关参数。比如上面的公式 $\rm s=Wx$。当 $\rm W$ 扩大两倍时，$\rm s$ 只需要同时扩大两倍即可，等式仍然满足，因此无法得到唯一的 $\rm s$。同时如果将人的编号打乱，变成另外一个顺序，如上图的蓝色节点的编号变为3,2,1，那么只需要调换 $\rm A$ 的列向量顺序即可，因此也无法单独确定 $\rm s$。这两种情况称为原信号不确定。</p>
<p>还有一种ICA不适用的情况，那就是信号不能是高斯分布的。假设只有两个人发出的声音信号符合多值正态分布，$\text{s}\sim N(0,1)$，I是2*2的单位矩阵，$\rm s$ 的概率密度函数就不用说了吧，以均值0为中心，投影面是椭圆的山峰状（参见多值高斯分布）。因为$ \rm x = As$，因此，$\rm x$ 也是高斯分布的，均值为0，协方差为 $\rm E[xx^T]=E[Ass^TA^T]=AA^T$。</p>
<p>令 $\rm R$ 是正交阵（$\rm RR^T=R^TR=I$），$\rm A’=AR$。如果将 $\rm A$ 替换成 $\rm A’$ 。那么 $\rm x’ =A’s$。$\rm s$ 分布没变，因此 $\rm x’$ 仍然是均值为0，协方差。因此$\rm E[x’x’^T]=E[A’ss^TA’^T]=E[ARss(AR)^T]=ARR^TA^T=AA^T$，不管混合矩阵是 $\rm A$ 还是 $\rm A’$，$\rm x$ 的分布情况是一样的，那么就无法确定混合矩阵，也就无法确定原信号。</p>
<h1 id="密度函数和线性变换"><a href="#密度函数和线性变换" class="headerlink" title="密度函数和线性变换"></a>密度函数和线性变换</h1><p>在讨论ICA具体算法之前，我们先来回顾一下概率和线性代数里的知识。</p>
<p>假设我们的随机变量 $\rm s$ 有概率密度函数 $p_s(s)$（连续值是概率密度函数，离散值是概率）。为了简单，我们再假设$\rm s$ 是实数，还有一个随机变量 $\rm x=As$，$\rm A$ 和 $\rm x$ 都是实数。令 $p_x$ 是 $\rm x$的概率密度，那么怎么求 $p_x$ ？</p>
<p>令 $\rm W=A^{-1}$，首先将式子变换成 $\rm s = Wx$，然后得到 $p_x(x)=p_s(\text Ws)$，求解完毕。可惜这种方法是错误的。比如 $\rm s$ 符合均匀分布的话（$\rm s\sim Uniform[0,1]$），那么 $\rm s$ 的概率密度是 $p_s(s)=1\{0\le s\le 1\}$，现在令 $\rm A=2$，即 $\rm x=2s$，也就是说 $\rm x$ 在[0,2]上均匀分布，可知 $p_x(x)=0.5$。然而，前面的推导会得到 $p_x(x)=p_s(0.5s)=1$。正确的公式应该是</p>
<script type="math/tex; mode=display">
p_x(x)=p_s(\text Wx)|\text W|</script><p>推导方法：</p>
<script type="math/tex; mode=display">
\text F_{\text X}(\text a)=\text P(\text X\le\text  a)=\text P(\text A\text S\le \text x)=\text P(\text S\le \text W\text x) = \text F_{\text s}(\text W\text x)\\
p_x(x)=\text F'_{\text X}(\text W\text x)=p_s(\text W\text x)|\text W|</script><p>更一般地，如果 $\rm s$ 是向量，$\rm A$ 可逆的方阵，那么上式子仍然成立。</p>
<h1 id="ICA算法"><a href="#ICA算法" class="headerlink" title="ICA算法"></a>ICA算法</h1><p>ICA算法归功于Bell和Sejnowski，这里使用最大似然估计来解释算法，原始的论文中使用的是一个复杂的方法Infomax principal。</p>
<p>我们假定每个 $s_i$ 有概率密度 $p_s$，那么给定时刻原信号的联合分布就是</p>
<script type="math/tex; mode=display">
p(s) = \prod_{i=1}^n p_s(s_i)</script><p>这个公式代表一个假设前提：每个人发出的声音信号各自独立。有了 $p(s)$，我们可以求得 $p(x)$：</p>
<script type="math/tex; mode=display">
p(x)=p_s(\text Wx)|\text W| = |\text W|\prod_{i=1}^np_s(w_i^Tx_i)</script><p>左边是每个采样信号 $x$（$n$ 维向量）的概率，右边是每个原信号概率的乘积的 $|\text W|$ 倍。</p>
<p>前面提到过，如果没有先验知识，我们无法求得 $\rm W$ 和 $\rm s$。因此我们需要知道 $p_s(s_i)$，我们打算选取一个概率密度函数赋给s，但是我们不能选取高斯分布的密度函数。在概率论里我们知道密度函数 $p(x)$ 由累计分布函数（cdf）$F(x)$ 求导得到。$F(x)$ 要满足两个性质是：单调递增和在[0,1]。我们发现sigmoid函数很适合，定义域负无穷到正无穷，值域0到1，缓慢递增。我们假定 $\rm s$ 的累积分布函数符合sigmoid函数。</p>
<script type="math/tex; mode=display">
g(\text s) = \frac{1}{1+e^{-s}}</script><p>求导后：</p>
<script type="math/tex; mode=display">
p_s(s) = g'(s)=\frac{e^s}{(1+e^s)^2}</script><p>这就是 $\rm s$ 的密度函数。这里 $\rm s$ 是实数。</p>
<p>如果我们预先知道 $\rm s$ 的分布函数，那就不用假设了，但是在缺失的情况下，sigmoid函数能够在大多数问题上取得不错的效果。由于上式中 $p_s(s)$ 是个对称函数，因此 $\text E[\rm s]=0$ （$\rm s$ 的均值为0），那么 $\rm E[x]=E[As]=0$，$\rm x$ 的均值也是0。</p>
<p>知道了 $p_s(s)$，就剩下 $\rm W$ 了。给定采样后的训练样本 $\{x^{(i)}(x_1^{(i)},x_2^{(i)},\dots,x_n^{(i)}),i=1,2,\dots,m\}$，样本对数似然估计如下：</p>
<p>使用前面得到的 $\text x$ 的概率密度函数，得</p>
<script type="math/tex; mode=display">
l(\text W)=\sum_{i=1}^m\Big(\sum_{j=1}^n\log g'(w_j^Tx^{(i)})+\log|\text W|\Big)</script><p>大括号里面是 $p(x^{(i)})$。</p>
<p>接下来就是对 $\rm W$ 求导了，这里牵涉一个问题是对行列式 $|\rm W| $ 进行求导的方法，属于矩阵微积分。这里先给出结果，在文章最后再给出推导公式。</p>
<script type="math/tex; mode=display">
\rm \nabla_W|W|=|W|(W^{-1})^T</script><p>最终得到的求导后公式如下，$\log g’(s)$ 的导数为 $1-2g(s)$：</p>
<p><img src="http://image.rexking6.top/img/20110419161115263.png" alt=""></p>
<p>其中 $\alpha$ 是梯度上升速率，人为指定。</p>
<p>当迭代求出 $\rm W$ 后，便可得到 $s^{(i)} = \text Wx^{(i)}$ 来还原出原始信号。</p>
<p><strong>注意：</strong>我们计算最大似然估计时，假设了 $x^{(i)}$ 与 $x^{(j)}$ 之间是独立的，然而对于语音信号或者其他具有时间连续依赖特性（比如温度）上，这个假设不能成立。但是在数据足够多时，假设独立对效果影响不大，同时如果事先打乱样例，并运行随机梯度上升算法，那么能够加快收敛速度。</p>
<p>回顾一下鸡尾酒宴会问题，$\rm s$ 是人发出的信号，是连续值，不同时间点的s不同，每个人发出的信号之间独立（$s_i$ 和 $s_j$ 之间独立）。$\rm s$ 的累计概率分布函数是 sigmoid 函数，但是所有人发出声音信号都符合这个分布。 $\rm A$ 代表了 $\rm s$ 相对于 $\rm x$ 的位置变化，$\rm x$ 是 $\rm s$ 和 $\rm A$ 变化后的结果。</p>
<h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p><img src="http://image.rexking6.top/img/201104191611205208.jpg" alt=""></p>
<p>$\rm s =2$ 时的原始信号</p>
<p><img src="http://image.rexking6.top/img/2011041916112227.jpg" alt=""></p>
<p>观察到的 $\rm x$ 信号</p>
<p><img src="http://image.rexking6.top/img/clip1589365272.png" alt=""></p>
<p>使用ICA还原后的 $\rm s$ 信号</p>
<h1 id="行列式的梯度"><a href="#行列式的梯度" class="headerlink" title="行列式的梯度"></a>行列式的梯度</h1><p>对行列式求导，设矩阵 $\rm A$ 是 $n×n$ 的，我们知道行列式与代数余子式有关，</p>
<script type="math/tex; mode=display">
|\text A| = \sum_{i=1}^n(-1)^{i+j}\text A_{ij}|A_{\backslash i,\backslash,j}|\space (\text{for any }j \in 1,\dots,n)</script><p>$\text A_{\backslash i,\backslash j}$是去掉第 $i$ 行，第 $j$ 列后的余子式，那么对 $a_{k,l}$ 求导得：</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial a_{k,l}}|\text A|=\frac{\partial}{\partial a_{k,l}}\sum_{i=1}^n(-1)^{i+j}a_{ij}|A_{\backslash i, \backslash j}| = (-1)^{k+l}|\text A_{\backslash k, \backslash j}| = (A^\ast)_{lk}</script><p>$\rm A^\ast$ 是伴随矩阵，因此</p>
<script type="math/tex; mode=display">
\rm \nabla_A|A| = (A^\ast)^T = |A|(A^{-1})^T</script><h1 id="ICA算法扩展描述"><a href="#ICA算法扩展描述" class="headerlink" title="ICA算法扩展描述"></a>ICA算法扩展描述</h1><p>上面介绍的内容基本上是讲义上的，与我看的另一篇《Independent Component Analysis: Algorithms and Applications》（Aapo Hyvärinen and Erkki Oja）有点出入。下面总结一下这篇文章里提到的一些内容（有些我也没看明白）。</p>
<p>首先里面提到了一个与“独立”相似的概念“不相关（uncorrelated）”。Uncorrelated属于部分独立，而不是完全独立，怎么刻画呢？</p>
<p>如果随机变量 $y_1$ 和 $y_2$ 是独立的，当且仅当 $p(y_1,y_2)=p(y_1)p(y_2)$。</p>
<p>如果随机变量 $y_1$ 和 $y_2$ 是不相关的，当且仅当 $\text E(y_1, y_2) = E(y_1)E(y_2)$</p>
<p>第二个不相关的条件要比第一个独立的条件“松”一些。因为独立能推出不相关，不相关推不出独立。</p>
<p>证明如下：</p>
<script type="math/tex; mode=display">
p_1(y_1) = \int p(y_1, y_2)dy_2,\\
p(y_1, y_2) = p_1(y_1)p_2(y_2).</script><script type="math/tex; mode=display">
\begin{aligned}
&E\left\{h_{1}\left(y_{1}\right) h_{2}\left(y_{2}\right)\right\}\\
=& \iint h_{1}\left(y_{1}\right) h_{2}\left(y_{2}\right) p\left(y_{1}, y_{2}\right) d y_{1} d y_{2}\\
=&\iint h_{1}\left(y_{1}\right)p_{1}\left(y_{1}\right) h_{2}\left(y_{2}\right) p_{2}\left(y_{2}\right) d y_{1} d y_{2}\\
=&\int h_{1}\left(y_{1}\right) p_{1}\left(y_{1}\right) d y_{1} \int h_{2}\left(y_{2}\right) p_{2}\left(y_{2}\right) d y_{2}\\ 
=&E\left\{h_{1}\left(y_{1}\right)\right\} E\left\{h_{2}\left(y_{2}\right)\right\}
\end{aligned}</script><p>反过来不能推出。</p>
<p>比如，$y_1$ 和 $y_2$ 的联合分布如下(0,1)，(0, -1)，(1,0)，(-1,0)。</p>
<script type="math/tex; mode=display">
E(y_1,y_2) = E(y_1)E(y_2)=0</script><p>因此 $y_1$ 和 $y_2$ 不相关，但是</p>
<script type="math/tex; mode=display">
E(y_1^2y_2^2)=0\neq \frac{1}{4}=E(y_1^2)E(y_2^2)</script><p>因此 $y_1$ 和 $y_2$ 不满足上面的积分公式，$y_1$ 和 $y_2$ 不是独立的。</p>
<p>上面提到过，如果 $s^{(i)}$ 是高斯分布的，$\rm A$ 是正交的，那么 $x^{(i)}$ 也是高斯分布的，且 $x^{(i)}$ 与 $x^{(j)}$ 之间是独立的。那么无法确定 $\rm A$，因为任何正交变换都可以让 $x^{(i)}$ 达到同分布的效果。但是如果 $s^{(i)}$ 中只有一个分量是高斯分布的，仍然可以使用ICA。</p>
<p>那么ICA要解决的问题变为：如何从 $\rm x$ 中推出 $\rm s$ ，使得 $\rm s$ 最不可能满足高斯分布？中心极限定理告诉我们：大量独立同分布随机变量之和满足高斯分布。</p>
<p><img src="http://image.rexking6.top/img/201104191632562969.png" alt=""></p>
<p>我们一直假设的是 $x^{(i)}$ 是由独立同分布的主元 $s^{(i)}$ 经过混合矩阵 $\rm A$ 生成。那么为了求 $s^{(i)}$，我们需要计算 $s^{(i)}$ 的每个分量 $y_j^{(i)}=w_j^Tx^{(i)}$。定义 $z_j=A^Tw_j$，那么 $y_j^{(i)}=w_j^Tx^{(i)}=w_j^T\text A s^{(i)}=z_j^Ts^{(i)}$，之所以这么麻烦再定义 $\rm z$ 是想说明一个关系，我们想通过整出一个 $w_j$ 来对 $x^{(i)}$ 进行线性组合，得出 $\rm y$ 。而我们不知道得出的 $\rm y$ 是否是真正的 $\rm s$ 的分量，但我们知道 $\rm y$ 是 $\rm s$ 的真正分量的线性组合。由于我们不能使 $\rm s$ 的分量成为高斯分布，因此我们的目标求是让 $\rm y$（也就是 $w_j^Tx^{(i)}$）最不可能是高斯分布时的 $\rm w$。那么问题递归到如何度量 $\rm y$ 是否是高斯分布的了。</p>
<p>一种度量方法是kurtosis方法，公式如下：</p>
<script type="math/tex; mode=display">
\text{kurt}(y)=E\{y^4\}-3(E\{y^2\})^2</script><p>如果 $y$ 是高斯分布，那么该函数值为0，否则绝大多数情况下值不为0。但这种度量方法不怎么好，有很多问题。看下一种方法：</p>
<p>负熵（Negentropy）度量方法。我们在信息论里面知道对于离散的随机变量 $Y$，其熵是</p>
<script type="math/tex; mode=display">
H(Y)=-\sum_i P(Y=a_i)\log P(Y=a_i)</script><p>连续值是：</p>
<script type="math/tex; mode=display">
H(y)=-\int f(y)\log f(y)dy</script><p>在信息论里有一个强有力的结论是：高斯分布的随机变量是同方差分布中熵最大的。也就是说对于一个随机变量来说，满足高斯分布时，最随机。定义负熵的计算公式如下：</p>
<script type="math/tex; mode=display">
J(y)=H(y_{\text{gauss}})-H(y)</script><p>也就是随机变量 $\rm y$ 相对于高斯分布时的熵差，这个公式的问题就是直接计算时较为复杂，一般采用逼近策略。</p>
<script type="math/tex; mode=display">
J(y) \approx \frac{1}{12}E\{y^3\}^2+\frac{1}{48}\text{kurt}(y)^2</script><p>这种逼近策略不够好，作者提出了基于最大熵的更优的公式：</p>
<script type="math/tex; mode=display">
J(y)\approx \sum_{i=1}^p k_i[E\{G_i(y)\}-E\{G_i(v)\}]^2</script><p>之后的FastICA就基于这个公式。另外一种度量方法是最小互信息方法：</p>
<script type="math/tex; mode=display">
I(y_1,y_2,\dots,y_m)=\sum_{i=1}^mH(y_i)-H(\rm y)</script><p>这个公式可以这样解释，前一个 $H$ 是 $y_i$ 的编码长度（以信息编码的方式理解），第二个 $H$ 是 $\rm y$ 成为随机变量时的平均编码长度。之后的内容包括FastICA就不再介绍了，我也没看懂。</p>
<h1 id="ICA的投影追踪解释"><a href="#ICA的投影追踪解释" class="headerlink" title="ICA的投影追踪解释"></a>ICA的投影追踪解释</h1><p>投影追踪在统计学中的意思是去寻找多维数据的“interesting”投影。这些投影可用在数据可视化、密度估计和回归中。比如在一维的投影追踪中，我们寻找一条直线，使得所有的数据点投影到直线上后，能够反映出数据的分布。然而我们最不想要的是高斯分布，最不像高斯分布的数据点最interesting。这个与我们的ICA思想是一致的，寻找独立的最不可能是高斯分布的 $\rm s$。</p>
<p>在下图中，主元是纵轴，拥有最大的方差，但最interesting的是横轴，因为它可以将两个类分开（信号分离）。</p>
<p><img src="http://image.rexking6.top/img/201104191633061498.png" alt=""></p>
<h1 id="ICA算法的前处理步骤"><a href="#ICA算法的前处理步骤" class="headerlink" title="ICA算法的前处理步骤"></a>ICA算法的前处理步骤</h1><ol>
<li><p><strong>中心化：</strong>也就是求 $\rm x$ 均值，然后让所有 $\rm x$ 减去均值，这一步与PCA一致。</p>
</li>
<li><p><strong>白化：</strong>目的是将 $\rm x$ 乘以一个矩阵变成 $\tilde{\text x}$，使得 $\tilde {\text x}$ 的协方差矩阵是 $I$。原始的向量是 $\rm x$ 。转换后的是 $\tilde {\text x}$。$\tilde {\text x}$ 的协方差矩阵是 $I$，即</p>
<script type="math/tex; mode=display">
E\{\tilde {\text x}\tilde {\text x}^T\}=I</script><p>我们只需用下面的变换，就可以从 $\rm x$ 得到想要的 $\tilde {\text x}$。</p>
<script type="math/tex; mode=display">
\tilde {\text x}=\text E\text D^{-1/2}\text E^T\text x</script><p>其中使用特征值分解来得到 $\rm E$（特征向量矩阵）和$ \rm D$（特征值对角矩阵），计算公式为</p>
<script type="math/tex; mode=display">
E\{\text x\text x^T\}=\text E\text D\text E^T</script><p>下面用个图来直观描述一下：</p>
<p>假设信号源 $s_1$ 和 $s_2$ 是独立的，比如下图横轴是 $s_1$，纵轴是 $s_2$，根据 $s_1$ 得不到 $s_2$。</p>
<p><img src="http://image.rexking6.top/img/201104191634444227.png" alt=""></p>
<p>我们只知道他们合成后的信号 $\rm x$，如下</p>
<p><img src="http://image.rexking6.top/img/201104191634454652.png" alt=""></p>
<p>此时 $x_1$ 和 $x_2$ 不是独立的（比如看最上面的尖角，知道了 $x_1$ 就知道了 $x_2$ ）。那么直接代入我们之前的极大似然概率估计会有问题，因为我们假定 $\rm x$ 是独立的。</p>
<p>因此，漂白这一步为了让 $\rm x$ 独立。漂白结果如下：</p>
<p><img src="http://image.rexking6.top/img/201104191634478390.png" alt=""></p>
<p>可以看到数据变成了方阵，在 $\tilde {\text x}$ 的维度上已经达到了独立。</p>
<p>然而这时 $\text x$ 分布很好的情况下能够这样转换，当有噪音时怎么办呢？可以先使用前面提到的PCA方法来对数据进行降维，滤去噪声信号，得到k维的正交向量，然后再使用ICA。</p>
</li>
<li><p><strong>进一步的预处理：</strong>给定数据集的ICA成功与否可能会跟特定应用的预处理步骤有关。比如数据中包含时间信号，那么带通滤波也将会是很有用的。如果我们对观测信号 $x_i(t)$ 进行线性滤波得到新的信号 $x_i^\ast(t)$，具有相同混合矩阵的ICA模型仍然适用于 $x_i^\ast(t)$。观测 $\text x(1),\dots,\text x(T)$ 是矩阵 $\rm X$ 的列，对于 $\rm S$ 也是如此，那么ICA模型可被表示为：</p>
<script type="math/tex; mode=display">
\rm X=AS</script><p>现在，$\rm X$ 的时间滤波相当于 $\rm X$ 从右边乘以一个矩阵 $\rm M$，如下：</p>
<script type="math/tex; mode=display">
\rm X^\ast = XM = ASM = AS^\ast</script><p>这表明ICA模型依然有效。</p>
</li>
</ol>
<h1 id="FastICA算法"><a href="#FastICA算法" class="headerlink" title="FastICA算法"></a>FastICA算法</h1><p>在前面的小节中，介绍了非高斯性的不同度量方式，也就是ICA估计的目标函数。在实际中，还需要一种最大化对比函数的算法。这一小节介绍一种非常有效的最大化方法，这里假设数据都是经过预处理的。</p>
<h2 id="单元FastICA"><a href="#单元FastICA" class="headerlink" title="单元FastICA"></a>单元FastICA</h2><p>首先来看单元FastICA，通过“单元”，我们指的是计算单元，最终是人工神经元，具有神经元能够通过学习规则更新的权值向量 $\rm w$。FastICA学习规则寻找方向，也就是使投影 $\rm w^Tx$ 最大化非高斯性的单位向量 $\rm w$，非高斯性通过负熵 $J(\rm w^Tx)$ 的近似度量。回想一下 $\rm w^Tx$ 的方差必须是统一的，对于白化的数据，这相当于将 $\rm w$ 的范数统一。FastICA是基于定点迭代的方案的寻找 $\rm w^Tx$ 非高斯性的最大值。这也可以用近似牛顿迭代法推导出来。</p>
<p>FastICA算法的基本形式如下：</p>
<ol>
<li>选择初始的权值向量 $\rm w$ （随机选择）</li>
<li>令 $\mathbf{w}^{+}=E\left\{\mathbf{x} g\left(\mathbf{w}^{T} \mathbf{x}\right)\right\}-E\left\{g^{\prime}\left(\mathbf{w}^{T} \mathbf{x}\right)\right\} \mathbf{w}$</li>
<li>令 $\mathbf{w}=\mathbf{w}^{+} /\left|\mathbf{w}^{+}\right|$</li>
<li>如果不收敛，就返回步骤2</li>
</ol>
<p>收敛是指 $\rm w$ 的新旧值指向同一个方向，也就是，它们的点积等于1，向量不一定收敛到同一个点，因为 $\rm w$ 和 $\rm -w$ 定义的方向是相同的，这也是因为独立分量只能定义为乘法符号。</p>
<p>FastICA推导如下，首先 $\rm w^Tx$ 的负熵的近似的最大值是从 $E\left\{G\left(\mathbf{w}^{T} \mathbf{x}\right)\right\}$ 获得的，在约束 $E\left\{\left(\mathbf{w}^{T} \mathbf{x}\right)^{2}\right\}=|\mathbf{w}|^{2}=1$ 下的 $E\left\{G\left(\mathbf{w}^{T} \mathbf{x}\right)\right\}$的最优值是从下式中获得的：</p>
<script type="math/tex; mode=display">
E\left\{\mathbf{x} g\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\}-\beta \mathbf{w}=0</script><p>用牛顿法来解上面的等式，令等式左边为 $F$，然后可以获得雅可比矩阵 $J F(\mathbf{w})$：</p>
<script type="math/tex; mode=display">
J F(\mathbf{w})=E\left\{\mathbf{x} \mathbf{x}^{\mathrm{T}} g^{\prime}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\}-\beta \mathbf{I}</script><p>为了简化矩阵，我们对上式中的第一部分取近似，由于数据是球形的，一个合理的近似是 $E\left\{\mathbf{x} \mathbf{x}^{\mathrm{T}} g^{\prime}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\} \approx E\left\{\mathbf{x} \mathbf{x}^{\mathrm{T}}\right\} E\left\{g^{\prime}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\}=E\left\{g^{\prime}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\} \mathbf{I}$  因此雅可比矩阵变成了对角矩阵，并且很容易求其逆，从而得到下面的近似牛顿迭代：</p>
<script type="math/tex; mode=display">
\mathbf{w}^{+}=\mathbf{w}-\left[E\left\{\mathbf{x} g\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\}-\beta \mathbf{w}\right] /\left[E\left\{g^{\prime}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\}-\beta\right]</script><p>通过对上式两边同时乘以 $\beta-E\left\{g^{\prime}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)\right\}$ 可以进一步简化。实际上，FastICA的期望必须由他们的估计来代替。 自然估计当然是相应的样本均值。 理想情况下，应该使用所有可用数据，但这通常不是一个好主意，因为计算可能变得过于苛刻。 然后可以使用较小的样本估计平均值，其大小可能对最终估计的准确性具有相当大的影响。 应在每次迭代时单独选择样本点。 如果收敛不令人满意，则可以增加样本量。</p>
<h2 id="多元FastICA"><a href="#多元FastICA" class="headerlink" title="多元FastICA"></a>多元FastICA</h2><p>前面讲的单单元算法只是估计一个独立成分或者一个投影追踪的方向，为了估计几个独立成分，我们需要使用具有权重向量 $\mathbf{w}$ 的若干单元（例如，神经元）来运行单单元FastICA算法。为了防止不同的向量收敛到相同的最大值，需要在每次迭代后对输出 $\mathbf{w}_{1}^{T} \mathbf{x}, \ldots, \mathbf{w}_{n}^{T} \mathbf{x}$ 去相关，有3种方法可以做到这一点，对于白化的 $\mathbf x$ 这种去相关相当于正交化。</p>
<p>实现去相关的简单方法是基于类似Gram-Schmidt的去相关的放缩方案。这意味着需要一个个的估计独立成分，当我们已经估计了 $p$  个独立成分或者 $p$ 个向量 $\mathbf{w}_{1}, \dots, \mathbf{w}_{p}$，对 $\mathbf{w}_{p+1}$ 运行单元定点算法，在每一次迭代之后，从  $\mathbf{w}_{p+1}$ 中减去投影 $\mathbf{w}_{p+1}^{T} \mathbf{w}_{j} \mathbf{w}_{j}$ ，其中 $j=1, \dots, p$，最后重新标准化 $\mathbf{w}_{p+1}$：</p>
<ol>
<li>$\mathbf{w}_{p+1}=\mathbf{w}_{p+1}-\sum_{j=1}^{r} \mathbf{w}_{p+1}^{\mathrm{T}} \mathbf{w}_{j} \mathbf{w}_{j}$</li>
<li>$\mathbf{w}_{p+1}=\mathbf{w}_{p+1} / \sqrt{\mathbf{w}_{p+1}^{\mathrm{T}} \mathbf{w}_{p+1}}$</li>
</ol>
<p>然而，在某些应用程序中，可能需要使用对称的去相关，其中没有向量比其他向量具有“特权”，这可以通过矩阵平方根法做到，令：</p>
<script type="math/tex; mode=display">
\mathbf{W}=\left(\mathbf{W} \mathbf{W}^{T}\right)^{-\frac{1}{2}} \mathbf{W}</script><p>其中 $\mathbf{W}$ 是向量 $\left(\mathbf{w}_{1}, \dots, \mathbf{w}_{n}\right)^{T}$ 组成的矩阵，平方根的倒数 $\left(\mathbf{W} \mathbf{W}^{T}\right)^{-\frac{1}{2}}$ 可以从 $\mathbf{W} \mathbf{W}^{T}=\mathbf{F} \Lambda \mathbf{F}^{T}$ 特征值分解得到，$\left(\mathbf{W} \mathbf{W}^{T}\right)^{-\frac{1}{2}}=\mathbf{F} \Lambda^{\frac{1}{2}} \mathbf{F}^{T}$，一个更简单的迭代方法如下：</p>
<ol>
<li>$\mathbf{W}=\mathbf{W} / \sqrt{\left|\mathbf{W} \mathbf{W}^{\mathrm{T}}\right|}$</li>
<li>重复：$\mathbf{W}=\frac{3}{2} \mathbf{W}-\frac{1}{2} \mathbf{W} \mathbf{W}^{\mathrm{T}} \mathbf{W}$，直至收敛</li>
</ol>
<p>步骤1中的范数可以使用矩阵的任意范数，比如2-范数。</p>
<h2 id="FastICA-和最大似然"><a href="#FastICA-和最大似然" class="headerlink" title="FastICA 和最大似然"></a>FastICA 和最大似然</h2><p>最后，给出FastICA和最大似然估计的联系。以矩阵形式写，看到FastICA采用以下形式：</p>
<script type="math/tex; mode=display">
\mathbf{W}^{+}=\mathbf{W}+\operatorname{diag}\left(\alpha_{i}\right)\left[\operatorname{diag}\left(\beta_{i}\right)+E\left\{g(\mathbf{y}) \mathbf{y}^{\mathrm{T}}\right\}\right] \mathbf{W}</script><p>其中 $\mathbf{y}=\mathbf{W} \mathbf{x}$，$\beta_{i}=-E\left\{y_{i} g\left(y_{i}\right)\right\}$，$\alpha_{i}=-\frac{1}{\beta_{i}+E\left\{g^{\prime}\left(y_{i}\right)\right\}}$，矩阵 $\mathbf{W}$ 在每一步后都需要正交化。上述版本的FastICA可以与随机梯度法的最大似然比较：</p>
<script type="math/tex; mode=display">
\mathbf{W}^{+}=\mathbf{W}+\mu\left[\mathbf{I}+g(\mathbf{y}) \mathbf{y}^{\mathrm{T}}\right] \mathbf{W}</script><p>其中 $\mu$ 是学习速率。$g$是独立成分的概率密度函数的函数：$g=\frac{f_{i}^{\prime}}{f_{i}}$，其中 $f_{i}$ 是独立成分的概率密度函数。FastICA可以作为ICA数据模型最大似然估计的定点算法。在FastICA中，通过选择矩阵 $\operatorname{diag}\left(\alpha_{i}\right)$ 和 $\operatorname{diag}\left(\beta_{i}\right)$ 来优化收敛速度。 FastICA的另一个优点是它可以估计子和超高斯独立分量，这与普通ML算法形成对比，普通ML算法仅适用于给定的分布类别。</p>
<h2 id="FastICA的属性"><a href="#FastICA的属性" class="headerlink" title="FastICA的属性"></a>FastICA的属性</h2><p>与现有的ICA方法相比，FastICA算法和底层对比度函数具有许多所需的特性。</p>
<ol>
<li>在ICA数据模型的假设下，收敛是立方的（或至少是二次的）。 这与基于（随机）梯度下降方法的普通ICA算法形成对比，其中收敛仅是线性的。 这意味着非常快速的收敛，正如通过对真实数据的模拟和实验所证实的那样。</li>
<li>与基于梯度的算法相反，没有选择步长参数。这意味着该算法易于使用。</li>
<li>该算法使用任何非线性 $g$ 直接找到（实际上）任何非高斯分布的独立分量。 这与许多算法形成对比，其中必须首先获得概率分布函数的一些估计，并且必须相应地选择非线性。</li>
<li>可以通过选择合适的非线性 $g$ 来优化该方法的性能。 特别地，可以获得稳健和/或最小方差的算法。 实际上，两个非线性具有一些最佳性质。</li>
<li>可以逐个估计独立分量，这大致相当于进行投影追踪。 这在探索性数据分析中很有用，并且在仅需要估计某些独立组件的情况下减少了该方法的计算负荷。</li>
<li>FastICA具有神经算法的大部分优点：它是并行的，分布式的，计算简单的，并且需要很少的存储空间。 只有在不断变化的环境中需要快速适应性时，随机梯度法似乎才是优选的。</li>
</ol>
<p>原论文中还涉及到了ICA算法的应用：在脑磁图去除数据伪迹中的应用；在金融数据中发现隐藏因子；为自然图像去噪。有兴趣的可以去阅读原文。</p>
<h1 id="MATLAB实践"><a href="#MATLAB实践" class="headerlink" title="MATLAB实践"></a>MATLAB实践</h1><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%FastICA的matlab代码</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Z</span> = <span class="title">ICA</span><span class="params">( X )</span></span></span><br><span class="line"> </span><br><span class="line"><span class="comment">%去均值</span></span><br><span class="line">[M,T]=<span class="built_in">size</span>(X);   <span class="comment">%获取输入矩阵的行列数，行数为观测数据的数目，列数为采样点数</span></span><br><span class="line">average=<span class="built_in">mean</span>(X&#x27;)&#x27;;  <span class="comment">%均值</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:M</span><br><span class="line">    X(<span class="built_in">i</span>,:)=X(<span class="built_in">i</span>,:)-average(<span class="built_in">i</span>)*<span class="built_in">ones</span>(<span class="number">1</span>,T);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">%白化/球化</span></span><br><span class="line">Cx=cov(X&#x27;,<span class="number">1</span>);  <span class="comment">%计算协方差矩阵Cx</span></span><br><span class="line">[eigvector,eigvalue]=eig(Cx);   <span class="comment">%计算Cx的特征值和特征向量</span></span><br><span class="line">W=eigvalue^(<span class="number">-1</span>/<span class="number">2</span>)*eigvector&#x27;;   <span class="comment">%白化矩阵</span></span><br><span class="line">Z=W*X;    <span class="comment">%正交矩阵</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">%迭代</span></span><br><span class="line">Maxcount=<span class="number">10000</span>;  <span class="comment">%最大迭代次数</span></span><br><span class="line">Critical=<span class="number">0.00001</span>;  <span class="comment">%判断是否收敛</span></span><br><span class="line">m=M;</span><br><span class="line">W=<span class="built_in">rand</span>(m);</span><br><span class="line"><span class="keyword">for</span> n=<span class="number">1</span>:m</span><br><span class="line">    WP=W(:,n);  <span class="comment">%初始权矢量（任意）</span></span><br><span class="line">    <span class="comment">%Y=WP&#x27;*Z;</span></span><br><span class="line">    <span class="comment">%G=Y.^3;%G为非线性函数，可取y^3等</span></span><br><span class="line">    <span class="comment">%GG=3*Y.^2；   %G的导数</span></span><br><span class="line">    count=<span class="number">0</span>;</span><br><span class="line">    LastWP=<span class="built_in">zeros</span>(m,<span class="number">1</span>);</span><br><span class="line">    W(:,n)=W(:,n)/norm(W(:,n));</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">abs</span>(WP-LastWP)&amp;<span class="built_in">abs</span>(WP+LastWP)&gt;Critical</span><br><span class="line">        count=count+<span class="number">1</span>;  <span class="comment">%迭代次数</span></span><br><span class="line">        LastWP=WP;      <span class="comment">%上次迭代的值</span></span><br><span class="line">        <span class="comment">%WP=1/T*Z*((LastWP&#x27;*Z).^3)&#x27;-3*LastWP;</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</span><br><span class="line">            WP(<span class="built_in">i</span>)=<span class="built_in">mean</span>(Z(<span class="built_in">i</span>,:).*(<span class="built_in">tanh</span>((LastWP)&#x27;*Z)))-(<span class="built_in">mean</span>(<span class="number">1</span>-(<span class="built_in">tanh</span>((LastWP))&#x27;*Z).^<span class="number">2</span>)).*LastWP(<span class="built_in">i</span>);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        WPP=<span class="built_in">zeros</span>(m,<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:n<span class="number">-1</span></span><br><span class="line">            WPP=WPP+(WP&#x27;*W(:,<span class="built_in">j</span>))*W(:,<span class="built_in">j</span>);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        WP=WP-WPP;</span><br><span class="line">        WP=WP/(norm(WP));</span><br><span class="line">        <span class="keyword">if</span> count==Maxcount</span><br><span class="line">            fprintf(<span class="string">&#x27;未找到相应的信号&#x27;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    W(:,n)=WP;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">Z=W&#x27;*Z;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h1 id="Python实践"><a href="#Python实践" class="headerlink" title="Python实践"></a>Python实践</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> FastICA, PCA</span><br><span class="line"><span class="comment"># 生成观测模拟数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">n_samples = <span class="number">2000</span></span><br><span class="line">time = np.linspace(<span class="number">0</span>, <span class="number">8</span>, n_samples)</span><br><span class="line">s1 = np.sin(<span class="number">2</span> * time)  <span class="comment"># 信号源 1 : 正弦信号</span></span><br><span class="line">s2 = np.sign(np.sin(<span class="number">3</span> * time))  <span class="comment"># 信号源 2 : 方形信号</span></span><br><span class="line">s3 = signal.sawtooth(<span class="number">2</span> * np.pi * time)  <span class="comment"># 信号源 3: 锯齿波信号</span></span><br><span class="line">S = np.c_[s1, s2, s3]</span><br><span class="line">S += <span class="number">0.2</span> * np.random.normal(size=S.shape)  <span class="comment"># 增加噪音数据</span></span><br><span class="line">S /= S.std(axis=<span class="number">0</span>)  <span class="comment"># 标准化</span></span><br><span class="line"><span class="comment"># 混合数据</span></span><br><span class="line">A = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">0.5</span>, <span class="number">2</span>, <span class="number">1.0</span>], [<span class="number">1.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>]])  <span class="comment"># 混合矩阵</span></span><br><span class="line">X = np.dot(S, A.T)  <span class="comment"># 生成观测信号源</span></span><br><span class="line"><span class="comment"># ICA模型</span></span><br><span class="line">ica = FastICA(n_components=<span class="number">3</span>)</span><br><span class="line">S_ = ica.fit_transform(X)  <span class="comment"># 重构信号</span></span><br><span class="line">A_ = ica.mixing_  <span class="comment"># 获得估计混合后的矩阵</span></span><br><span class="line"><span class="comment"># PCA模型</span></span><br><span class="line">pca = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">H = pca.fit_transform(X)  <span class="comment"># 基于PCA的成分正交重构信号源</span></span><br><span class="line"><span class="comment"># 图形展示</span></span><br><span class="line">plt.figure()</span><br><span class="line">models = [X, S, S_, H]</span><br><span class="line">names = [<span class="string">&#x27;Observations (mixed signal)&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;True Sources&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;ICA recovered signals&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;PCA recovered signals&#x27;</span>]</span><br><span class="line">colors = [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;steelblue&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> ii, (model, name) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(models, names), <span class="number">1</span>):</span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">1</span>, ii)</span><br><span class="line">    plt.title(name)</span><br><span class="line">    <span class="keyword">for</span> sig, color <span class="keyword">in</span> <span class="built_in">zip</span>(model.T, colors):</span><br><span class="line">        plt.plot(sig, color=color)</span><br><span class="line">plt.subplots_adjust(<span class="number">0.09</span>, <span class="number">0.04</span>, <span class="number">0.94</span>, <span class="number">0.94</span>, <span class="number">0.26</span>, <span class="number">0.46</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>ICA的盲信号分析领域的一个强有力方法，也是求非高斯分布数据隐含因子的方法。从之前我们熟悉的样本-特征角度看，我们使用ICA的前提条件是，认为样本数据由独立非高斯分布的隐含因子产生，隐含因子个数等于特征数，我们要求的是隐含因子。</p>
<p>而PCA认为特征是由k个正交的特征（也可看作是隐含因子）生成的，我们要求的是数据在新特征上的投影。同是因子分析，一个用来更适合用来还原信号（因为信号比较有规律，经常不是高斯分布的），一个更适合用来降维（用那么多特征干嘛，k个正交的即可）。有时候也需要组合两者一起使用。这段是我的个人理解，仅供参考。</p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2019\03\21\Fisher线性判别\" rel="bookmark">Fisher线性判别</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2018\02\13\cs229中文笔记-一二\" rel="bookmark">cs229中文笔记(一二)</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2018\02\18\cs229中文笔记-七\" rel="bookmark">cs229中文笔记(七)</a></div>
    </li>
  </ul>

        <div class="reward-container">
  <div>一分一毛，也是心意。</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Run-Qing Chen 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="Run-Qing Chen 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Run-Qing Chen
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://blog.rexking6.top/2020/03/20/%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Independent-Component-Analysis%EF%BC%89/" title="独立成分分析（Independent Component Analysis）">https://blog.rexking6.top/2020/03/20/独立成分分析（Independent-Component-Analysis）/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/13/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD%EF%BC%88Variational-Inference%EF%BC%89%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%AE%80%E8%BF%B0/" rel="prev" title="变分推断（Variational Inference）最新进展简述">
      <i class="fa fa-chevron-left"></i> 变分推断（Variational Inference）最新进展简述
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/09/23/%E5%BF%AB%E9%80%9F%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A1%A50/" rel="next" title="快速傅立叶变换补0">
      快速傅立叶变换补0 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

    <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%97%AE%E9%A2%98"><span class="nav-number">2.</span> <span class="nav-text">问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ICA%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="nav-number">3.</span> <span class="nav-text">ICA的不确定性</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2"><span class="nav-number">4.</span> <span class="nav-text">密度函数和线性变换</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ICA%E7%AE%97%E6%B3%95"><span class="nav-number">5.</span> <span class="nav-text">ICA算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B"><span class="nav-number">6.</span> <span class="nav-text">实例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F%E7%9A%84%E6%A2%AF%E5%BA%A6"><span class="nav-number">7.</span> <span class="nav-text">行列式的梯度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ICA%E7%AE%97%E6%B3%95%E6%89%A9%E5%B1%95%E6%8F%8F%E8%BF%B0"><span class="nav-number">8.</span> <span class="nav-text">ICA算法扩展描述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ICA%E7%9A%84%E6%8A%95%E5%BD%B1%E8%BF%BD%E8%B8%AA%E8%A7%A3%E9%87%8A"><span class="nav-number">9.</span> <span class="nav-text">ICA的投影追踪解释</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ICA%E7%AE%97%E6%B3%95%E7%9A%84%E5%89%8D%E5%A4%84%E7%90%86%E6%AD%A5%E9%AA%A4"><span class="nav-number">10.</span> <span class="nav-text">ICA算法的前处理步骤</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#FastICA%E7%AE%97%E6%B3%95"><span class="nav-number">11.</span> <span class="nav-text">FastICA算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E5%85%83FastICA"><span class="nav-number">11.1.</span> <span class="nav-text">单元FastICA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%85%83FastICA"><span class="nav-number">11.2.</span> <span class="nav-text">多元FastICA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FastICA-%E5%92%8C%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6"><span class="nav-number">11.3.</span> <span class="nav-text">FastICA 和最大似然</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FastICA%E7%9A%84%E5%B1%9E%E6%80%A7"><span class="nav-number">11.4.</span> <span class="nav-text">FastICA的属性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MATLAB%E5%AE%9E%E8%B7%B5"><span class="nav-number">12.</span> <span class="nav-text">MATLAB实践</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Python%E5%AE%9E%E8%B7%B5"><span class="nav-number">13.</span> <span class="nav-text">Python实践</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">14.</span> <span class="nav-text">小结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Run-Qing Chen"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Run-Qing Chen</p>
  <div class="site-description" itemprop="description">覆苍天以为衾，卧大地以为庐。</div>
</div>


   <div class="feed-link motion-element">
     <a href="/atom.xml" rel="alternate">
       <i class="fa fa-rss"></i>
       RSS
     </a>
   </div>
 
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">176</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/RexKing6" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;RexKing6" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1010026261@qq.com" title="E-Mail → mailto:1010026261@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.zxpblog.cn/" title="https:&#x2F;&#x2F;www.zxpblog.cn&#x2F;" rel="noopener" target="_blank">赵小平</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://whitepuffer.github.io/" title="https:&#x2F;&#x2F;whitepuffer.github.io&#x2F;" rel="noopener" target="_blank">江斓</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://kexue.fm/" title="https:&#x2F;&#x2F;kexue.fm&#x2F;" rel="noopener" target="_blank">科学空间</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yongyuan.name/" title="https:&#x2F;&#x2F;yongyuan.name&#x2F;" rel="noopener" target="_blank">袁勇</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/abcjennifer" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;abcjennifer" rel="noopener" target="_blank">Rachel Zhang</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://dmkf.xyz/" title="http:&#x2F;&#x2F;dmkf.xyz&#x2F;" rel="noopener" target="_blank">代码咖啡</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://wuxiaolong.me/" title="http:&#x2F;&#x2F;wuxiaolong.me&#x2F;" rel="noopener" target="_blank">吴小龙同学</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.tennfy.com/" title="http:&#x2F;&#x2F;www.tennfy.com&#x2F;" rel="noopener" target="_blank">TENNFY WU</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备16049735号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fab fa-accessible-icon"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Run-Qing Chen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">2m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">30:41</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"dOMRIGavgWnKuSQ5IqJS3ckT-gzGzoHsz","app_key":"qMh3SHPhOGOhYa5GA251PGcy","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
