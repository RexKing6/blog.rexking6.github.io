<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.rexking6.top","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#37c6c0","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"YS7HT61SEB","apiKey":"0fd1eba022e7883c76ff4a71aee2acdc","indexName":"blog_NAME","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"找不到关于 ${query} 的文章","hits_stats":"共找到 ${hits} 篇文章，花了 ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="...">
<meta property="og:type" content="article">
<meta property="og:title" content="《视频分析前沿》一">
<meta property="og:url" content="https://blog.rexking6.top/2018/09/27/%E3%80%8A%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E5%89%8D%E6%B2%BF%E3%80%8B%E4%B8%80/">
<meta property="og:site_name" content="RexKing6&#39;s Note">
<meta property="og:description" content="...">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538018731.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538018837.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538018975.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538019054.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538019408.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538019535.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538021451.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538021702.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538028200.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538028344.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538028481.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538028542.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538029328.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538029537.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538031325.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538032901.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538033072.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538033135.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538033584.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538034219.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538035732.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538036105.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1538036132.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539233749.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539233791.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539233834.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539233884.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539234098.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539242401.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539243137.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539243430.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539243550.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539243851.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539243987.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539847902.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539849431.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539849970.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539850347.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539850408.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539850601.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539851803.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539851847.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539851879.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539860648.png">
<meta property="og:image" content="http://image.rexking6.top/img/clip1539865773.png">
<meta property="article:published_time" content="2018-09-27T03:14:33.000Z">
<meta property="article:modified_time" content="2021-07-10T11:31:16.658Z">
<meta property="article:author" content="Run-Qing Chen">
<meta property="article:tag" content="硕士课程">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://image.rexking6.top/img/clip1538018731.png">

<link rel="canonical" href="https://blog.rexking6.top/2018/09/27/%E3%80%8A%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E5%89%8D%E6%B2%BF%E3%80%8B%E4%B8%80/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>《视频分析前沿》一 | RexKing6's Note</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="RexKing6's Note" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RexKing6's Note</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/rexking6" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.rexking6.top/2018/09/27/%E3%80%8A%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E5%89%8D%E6%B2%BF%E3%80%8B%E4%B8%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Run-Qing Chen">
      <meta itemprop="description" content="覆苍天以为衾，卧大地以为庐。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RexKing6's Note">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《视频分析前沿》一
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-09-27 11:14:33" itemprop="dateCreated datePublished" datetime="2018-09-27T11:14:33+08:00">2018-09-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-10 19:31:16" itemprop="dateModified" datetime="2021-07-10T19:31:16+08:00">2021-07-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A1%95%E5%A3%AB%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">硕士课程</span></a>
                </span>
            </span>

          
            <span id="/2018/09/27/%E3%80%8A%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E5%89%8D%E6%B2%BF%E3%80%8B%E4%B8%80/" class="post-meta-item leancloud_visitors" data-flag-title="《视频分析前沿》一" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>15k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这学期选了王菡子老师的《视频分析前沿》，作一下记录。</p>
<h1 id="一：对象表示"><a href="#一：对象表示" class="headerlink" title="一：对象表示"></a>一：对象表示</h1><h2 id="假设-amp-限制"><a href="#假设-amp-限制" class="headerlink" title="假设&amp;限制"></a>假设&amp;限制</h2><p>对物体的运动和/或外观施加限制:</p>
<ul>
<li>假设对象运动是平滑的,没有突然的运动</li>
<li>假设对象的运动速度或加速度是恒定的，基于先验信息</li>
<li>假设对象的数量和大小,或者是对象的外观和形状在追踪过程没有改变</li>
</ul>
<h2 id="难题-amp-挑战"><a href="#难题-amp-挑战" class="headerlink" title="难题&amp;挑战"></a>难题&amp;挑战</h2><ul>
<li>由3d世界投影到2d图像，引起的信息丢失</li>
<li>完全阻挡或部分阻挡</li>
<li>场景光照变化</li>
<li>车辆在同一方向穿过另一辆车</li>
<li>跟踪小成像对象(包括4像素)</li>
<li>阴影</li>
<li>跟踪许多车辆（例如，一个城市的数千辆车辆）</li>
<li>背景杂乱干扰</li>
<li>物体的非刚性</li>
<li>复杂的物体运动</li>
<li>复杂的物体形状</li>
<li>二次出现</li>
<li>基于多摄像机的跟踪（例如，城市监控网络）</li>
<li>实时处理要求</li>
</ul>
<h2 id="对象形状表示"><a href="#对象形状表示" class="headerlink" title="对象形状表示"></a>对象形状表示</h2><p><img src="http://image.rexking6.top/img/clip1538018731.png" alt=""></p>
<h3 id="点"><a href="#点" class="headerlink" title="点"></a>点</h3><p><img src="http://image.rexking6.top/img/clip1538018837.png" alt=""></p>
<p>物体的质心(a)或者是一组特征点(b)，适合于跟踪在图像中占据小区域的对象。</p>
<h3 id="原始几何形状"><a href="#原始几何形状" class="headerlink" title="原始几何形状"></a>原始几何形状</h3><p><img src="http://image.rexking6.top/img/clip1538018975.png" alt=""></p>
<ul>
<li>对象形状是由一个矩形,椭圆等。</li>
<li>对象运动等表征建模通常是通过变换,仿射或投影转换。</li>
<li>原始几何形状更适合代表简单的刚性物体。</li>
<li>它们也用于跟踪非刚性的对象。</li>
</ul>
<h3 id="物体轮廓与剪影轮廓"><a href="#物体轮廓与剪影轮廓" class="headerlink" title="物体轮廓与剪影轮廓"></a>物体轮廓与剪影轮廓</h3><p><img src="http://image.rexking6.top/img/clip1538019054.png" alt=""></p>
<ul>
<li>轮廓表示定义了一个对象的边界(g)(h)</li>
<li>轮廓内的区域被称为物体的剪影（见(i)）</li>
<li>轮廓和剪影轮廓表示适合跟踪复杂的非刚性的形状</li>
</ul>
<h3 id="关节形状"><a href="#关节形状" class="headerlink" title="关节形状"></a>关节形状</h3><p><img src="http://image.rexking6.top/img/clip1538019408.png" alt=""></p>
<ul>
<li>关节对象是组合在一起的身体部位和关节，如躯干，腿，手，头，脚通过关节连接</li>
<li>部分由运动学运动之间的关系模型，例如，关节角等</li>
<li>模型组成部分使用柱面或椭圆所示(e)</li>
</ul>
<h3 id="骨架"><a href="#骨架" class="headerlink" title="骨架"></a>骨架</h3><p><img src="http://image.rexking6.top/img/clip1538019535.png" alt=""></p>
<ul>
<li>对象可以通过应用中轴变换提取骨架对象轮廓</li>
<li>这个模型是作为认识对象的常用形状表示</li>
<li>骨架表示可用于模型表达和刚性物体（见(f)）。</li>
</ul>
<h2 id="对象外观表示"><a href="#对象外观表示" class="headerlink" title="对象外观表示"></a>对象外观表示</h2><h3 id="物体出现的概率密度"><a href="#物体出现的概率密度" class="headerlink" title="物体出现的概率密度"></a>物体出现的概率密度</h3><p><img src="http://image.rexking6.top/img/clip1538021451.png" alt=""></p>
<ul>
<li>对象外观的概率密度估计可以是参数化的，如高斯和混合高斯模型的；或非参数的，如直方图和内核密度</li>
<li>对象出现的概率密度特征（颜色、纹理）可以从指定的图像区域形状模型（内部区域的一个椭圆或轮廓）计算</li>
</ul>
<h3 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h3><ul>
<li>模板形成使用简单的几何形状或轮廓</li>
<li>模板的一个优势是,它带有两个空间和外观信息</li>
<li>模板只从单一视图生成的编码对象的外观。因此，它们只适用于在跟踪过程中姿态变化不大的对象。</li>
</ul>
<h3 id="主动外观模型"><a href="#主动外观模型" class="headerlink" title="主动外观模型"></a>主动外观模型</h3><p><img src="http://image.rexking6.top/img/clip1538021702.png" alt=""></p>
<ul>
<li>主动外观模型是同时生成的建模对象的形状和外观</li>
<li>对象形状由一组标志定义。地标可以位于对象边界或对象区域内</li>
<li>对于每一个标志,一个外观向量以颜色、纹理或梯度大小的形式存储</li>
<li>主动外观模型需要一个训练阶段，在这个阶段中，形状及其相关外观都是从一组样本中学习到的</li>
</ul>
<h3 id="多视图外观模型"><a href="#多视图外观模型" class="headerlink" title="多视图外观模型"></a>多视图外观模型</h3><ul>
<li>该模型对对象的不同视图进行编码</li>
<li>表示不同对象视图的一种方法是从给定的视图生成子空间</li>
<li>子空间方法，例如主成分分析(PCA)和独立成分分析(ICA)，被用于形状和外观表示。</li>
<li>学习对象的不同视图的另一种方法是通过训练一组分类器，例如支持向量机和贝叶斯网络</li>
<li>多视图的外观模型的一个限制是，所有视图的外观都需要及时完成</li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li>Yilmaz, A., Javed, O., Shah, M., “Object Tracking: A survey”, Acm Computing Surveys, Vol 38, No. 4, 1-45, 2006;</li>
<li>Kevin Cannons, “A Review of Visual Tracking”, Technical Report CSE-2008-07, York University</li>
<li>侯志强等, “视觉跟踪技术综述”, 自动化学报, Vol 32, No. 4, 603-617, 2006 </li>
</ul>
<h1 id="二：特征-amp-目标跟踪"><a href="#二：特征-amp-目标跟踪" class="headerlink" title="二：特征&amp;目标跟踪"></a>二：特征&amp;目标跟踪</h1><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="颜色特征"><a href="#颜色特征" class="headerlink" title="颜色特征"></a>颜色特征</h3><h4 id="RGB"><a href="#RGB" class="headerlink" title="RGB"></a>RGB</h4><p>RGB空间中颜色的差异并不对应于人类感知到的颜色差异。</p>
<h4 id="YIQ"><a href="#YIQ" class="headerlink" title="YIQ"></a>YIQ</h4><p>YIQ，是NTSC（National Television Standards Committee）电视系统标准。Y是提供黑白电视及彩色电视的亮度信号（Luminance），即亮度（Brightness），I代表In-phase，色彩从橙色到青色，Q代表Quadrature-phase，色彩从紫色到黄绿色。</p>
<script type="math/tex; mode=display">
{\left[ \begin{array}{ccc}
Y\\
I\\
Q
\end{array} 
\right ]}=
{\left[ \begin{array}{ccc}
0.299 & 0.587 & 0.114\\
0.596 & -0.274 & -0.322\\
0.211 & -0.253 & -0.312
\end{array} 
\right ]}
{\left[ \begin{array}{ccc}
R\\
G\\
B
\end{array} 
\right ]}</script><h4 id="YUV"><a href="#YUV" class="headerlink" title="YUV"></a>YUV</h4><p>YUV是编译true-color颜色空间（colorspace）的种类，Y’UV，YUV，YCbCr和YPbPr等专有名词都可以称为YUV，彼此有重叠。“Y”表示明亮度（Luminance、Luma），“U”和“V”则是色度、浓度（Chrominance、Chroma）。</p>
<script type="math/tex; mode=display">
{\left[ \begin{array}{ccc}
Y\\
U\\
V
\end{array} 
\right ]}=
{\left[ \begin{array}{ccc}
0.299 & 0.587 & 0.114\\
-0.147 & -0.289 & 0.437\\
0.615 & -0.515 & -0.100
\end{array} 
\right ]}
{\left[ \begin{array}{ccc}
R\\
G\\
B
\end{array} 
\right ]}</script><h4 id="Nrgb"><a href="#Nrgb" class="headerlink" title="Nrgb"></a>Nrgb</h4><p>使颜色不依赖于光照强度的变化。</p>
<script type="math/tex; mode=display">
r = R/(R+G+B) \\
g = G/(R+G+B) \\
b = B/(R+G+B)</script><h4 id="HSI"><a href="#HSI" class="headerlink" title="HSI"></a>HSI</h4><p>分别代表色相、饱和度、强度。HSI系统将颜色信息与强度信息分离。颜色信息是由色相和饱和度值表示的，而强度是由光的量决定的。</p>
<script type="math/tex; mode=display">
H=arctan(\frac{\sqrt{3}(G_B)}{(R-G)+(R-B)})\\
Sat = 1-\frac{min(R,G,B)}{I} \\
Int = \frac{(R+G+B)}{3}</script><p>HSI的一些变体有HSL、HSV、HSB等。</p>
<h4 id="CIE"><a href="#CIE" class="headerlink" title="CIE"></a>CIE</h4><p>CIE(国际ecllairage委员会)的颜色系统被开发用来表示感知的一致性。</p>
<ul>
<li>$L^\star a^\star b^\star$<script type="math/tex; mode=display">
{\left[ \begin{array}{ccc}
X\\
Y\\
Z
\end{array} 
\right ]}=
{\left[ \begin{array}{ccc}
0.607 & 0.174 & 0.200\\
0.299 & 0.587 & 0.114\\
0.000 & 0.066 & 1.116
\end{array} 
\right ]}
{\left[ \begin{array}{ccc}
R\\
G\\
B
\end{array} 
\right ]} \\
L^\star =116(\sqrt[3]{\frac{Y}{Y_0}})-16\\
a^\star = 500[\sqrt[3]{\frac{X}{X_0}}-\sqrt[3]{\frac{Y}{Y_0}}] \\
b^\star = 200[\sqrt[3]{\frac{Y}{Y_0}}-\sqrt[3]{\frac{Z}{Z_0}}]</script>其中，$\frac{Y}{Y_0}&gt;0.01, \frac{X}{X_0}&gt;0.01 \frac{Z}{Z_0}&gt;0.01$，$(X_0,Y_0,Z_0)$是标准白色的$(X,Y,Z)$的值。</li>
</ul>
<p>与HIS空间的转换：</p>
<script type="math/tex; mode=display">
I=L^\star\\
H=arctan(\frac{a^\star}{b^\star})\\
S=\sqrt{(a^\star)^2+(b^\star)^2}</script><ul>
<li>$L^\star u^\star v^\star$<script type="math/tex; mode=display">
u'=\frac{4X}{X+15Y+3Z} \\
v'=\frac{6Y}{X+15Y+3Z} \\
L^\star =116(\sqrt[3]{\frac{Y}{Y_0}})-16\\
u^\star = 13L^\star (u'-u_0)\\
v^\star = 13L^\star (v'-v_0)</script>其中，$\frac{Y}{Y_0}&gt;0.01, $Y_0,u_0,v_0)$是标准白色值。</li>
</ul>
<p>与HIS空间的转换：</p>
<script type="math/tex; mode=display">
I=L^\star\\
H=arctan(\frac{u^\star}{v^\star})\\
S=\sqrt{(u^\star)^2+(v^\star)^2}</script><p>$L^\star u^\star v^\star$和$L^\star a^\star b^\star$是感知均匀颜色空间，而HSV(色相，饱和度，强度)是一个近似均匀的颜色空间。这些颜色空间对噪音很敏感。</p>
<p><img src="http://image.rexking6.top/img/clip1538028200.png" alt=""></p>
<h3 id="边缘特征"><a href="#边缘特征" class="headerlink" title="边缘特征"></a>边缘特征</h3><p>边缘特征的一个重要属性是与颜色特征相比，它们对光照变化不敏感。对于基于轮廓的表示，对象边缘通常用作特征（例如Canny边缘检测器）。</p>
<p><img src="http://image.rexking6.top/img/clip1538028344.png" alt=""></p>
<h3 id="光流特征"><a href="#光流特征" class="headerlink" title="光流特征"></a>光流特征</h3><p>光流在基于运动的分割和跟踪应用中是一种常用的特征，采用亮度约束进行计算，该约束假设在连续帧中对应像素的亮度恒定。</p>
<p><img src="http://image.rexking6.top/img/clip1538028481.png" alt=""></p>
<h3 id="纹理特征"><a href="#纹理特征" class="headerlink" title="纹理特征"></a>纹理特征</h3><p>纹理是测量表面强度变化的一种方法，它具有量化平滑和规律性等特点。有各种各样的纹理描述符。与颜色相比，纹理特征对光照变化的敏感度较低。</p>
<p><img src="http://image.rexking6.top/img/clip1538028542.png" alt=""></p>
<h2 id="对象跟踪方法"><a href="#对象跟踪方法" class="headerlink" title="对象跟踪方法"></a>对象跟踪方法</h2><h3 id="点跟踪"><a href="#点跟踪" class="headerlink" title="点跟踪"></a>点跟踪</h3><p>在连续帧中检测到的对象用点表示。点的关联是基于之前的对象状态，可以包括对象的位置和运动。</p>
<p>点跟踪可以表示为检测对象的对应关系,这是由点在帧之间表示。</p>
<p>点对应关系是复杂的,尤其是在存在遮挡，错误检测，对象的进入和退出。</p>
<p>确定性点对应的方法，通过使用一组运动约束来定义将$t-1$帧中的每个对象与$t$帧中的单个对象相关联的成本。</p>
<p>关联成本通常通过使用以下约束的组合来定义。</p>
<p><img src="http://image.rexking6.top/img/clip1538029328.png" alt=""><br><img src="http://image.rexking6.top/img/clip1538029537.png" alt=""></p>
<ul>
<li>接近度：假设对象的位置不会从一帧到另一帧显着变化（见(a)）</li>
<li>最大速度：定义对象速度的上限（见(b)）</li>
<li>小速度变化：假设物体的方向和速度不会发生剧烈变化（见(c)）</li>
<li>共同运动：约束小邻域中物体的速度是相似的，适用于由多个点表示的对象（见(d)）</li>
<li>刚性：假设3D世界中的物体是刚性的，因此，实际物体上任意两点之间的距离将保持不变（见(e)）</li>
</ul>
<p>对应的统计方法：它使用状态空间方法来模拟对象属性，例如位置，速度和加速度。</p>
<h4 id="单目标状态估计"><a href="#单目标状态估计" class="headerlink" title="单目标状态估计"></a>单目标状态估计</h4><p><strong>卡尔曼滤波器</strong><br>卡尔曼滤波器用于估计线性系统的状态，其中假设状态是服从高斯分布的。</p>
<p>卡尔曼滤波由预测和校正两个步骤组成。预测步骤使用状态模型来预测变量的新状态。它使用状态转移矩阵来定义时间$t$和$t-1$之间状态变量之间的关系。校正步骤使用当前观察值来更新对象的状态。扩展卡尔曼滤波器假设状态由高斯分布。 它使用泰勒级数展开来线性化非线性函数。</p>
<p>卡尔曼滤波器的一个限制是假设状态变量是正态分布的（高斯分布）。 它给出了不遵循高斯分布的状态变量的较差估计。</p>
<p><strong>粒子滤波</strong><br>时间$t$处的条件状态密度由具有权重的一组样本（粒子）表示。权重定义样本的重要性。根据不同的采样方案，在$t-1$步骤中从样本中抽取新样本。最常见的抽样方案是重要性抽样。</p>
<p><img src="http://image.rexking6.top/img/clip1538031325.png" alt=""></p>
<h4 id="多目标状态估计"><a href="#多目标状态估计" class="headerlink" title="多目标状态估计"></a>多目标状态估计</h4><p>跟踪多个对象需要联合解决数据关联和状态估计问题。在应用这些过滤器之前，需要解决关联问题，执行关联的最简单方法是使用最近邻方法，但是在物体彼此靠近的情况下难以处理。</p>
<p><strong>联合概率数据关联滤波器（JPDAF）</strong><br>它假设轨迹数量随时间保持不变。主要限制是无法处理进入视野（FOV）的新物体或已离开FOV的已跟踪物体。</p>
<p><strong>多假设跟踪（MHT）</strong><br>MHT算法在每个时间帧为每个对象维护几个对应假设。对象的最终轨迹是其观察时间段内最可能的对应关系。该算法能够为进入FOV的对象创建新轨迹，并终止离开FOV的对象的轨迹。即使缺少某个对象的某些测量值，它也可以处理遮挡。</p>
<p>MHT是一种迭代算法，从一组当前的跟踪假设开始。每个假设都是一系列不相交的轨迹。对于每个假设，进行下一帧中每个对象位置的预测。通过评估距离函数将预测与实际测量进行比较。基于距离函数为每个假设建立一组关联关系，引入新的假设。每个新假设代表一组新的轨迹。每个测量都可以属于进入FOV的新对象，先前跟踪的对象或虚假测量。可能未将测量分配给对象，因为该对象可能已退出FOV。可能无法获得对应于对象的测量。</p>
<p>MHT以确定性的意义建立联想，并详尽地列举所有可能的关联。MHT算法在存储器和时间上都是计算指数的。</p>
<h4 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h4><p>精确率：</p>
<script type="math/tex; mode=display">precision = \frac{nums \space of \space correct \space correspondences}{nums \space of \space established \space correspondences}</script><p>召回率：</p>
<script type="math/tex; mode=display">recall = \frac{nums \space of \space correct \space correspondences}{nums \space of \space actual \space correspondences}</script><p>点跟踪器适用于跟踪可由单个点表示的非常小的对象。需要多个点来跟踪较大的物体。属于同一对象的点的自动聚类很重要。 它需要区分多个对象，以及对象和背景之间。</p>
<h3 id="核跟踪"><a href="#核跟踪" class="headerlink" title="核跟踪"></a>核跟踪</h3><p>核跟踪是通过计算从一个帧到下一个帧的由原始对象区域表示的对象的运动来执行的。物体运动通常采用参数运动（平移，仿射等）或密集流场的形式。基于所使用的外观表示的方法，包括模板，基于密度的外观模型和多视图外观模型。</p>
<p><strong>模板和基于密度的外观模型：</strong><br>优点：简单，计算成本低。<br>模板匹配：在图像中搜索与对象模板类似的区域。通过相似性度量计算当前图像中模板的位置。通常使用图像强度或颜色特征来形成模板。</p>
<p>模板匹配的局限性在于由于暴力搜索而导致的高计算成本。为了降低计算成本，研究人员通常将对象搜索限制在其先前位置附近。颜色直方图或混合模型可以通过使用矩形或椭圆形区域内的像素外观来计算。</p>
<ol>
<li><p>Fieguth等[1997]通过找到矩形对象区域内的像素的平均颜色来生成对象模型。<br>为了降低计算复杂性，他们在八个相邻位置搜索对象。通过评估从两个区域计算的颜色平均值之间的比率来计算对象模型和假设位置之间的相似性。选择提供最高比率的位置作为当前对象位置。</p>
</li>
<li><p>Comaniciu和Meer [2003]使用从圆形区域计算的加权直方图来表示对象。<br>他们使用均值漂移过程来搜索对象的定位。均值漂移跟踪器通过比较对象的直方图和假设对象位置周围的窗口，迭代地最大化外观相似性。在每次迭代时，计算均值漂移矢量，使得直方图相似度增加。 重复这一过程直到收敛。作者使用由空间内核定义的加权方案，该方案为靠近对象中心的像素提供更高的权重。平移跟踪器优于标准模板匹配的一个优点是消除了暴力搜索。<br>缺点：均值漂移跟踪要求初始化时对象的一部分位于圆形区域内。</p>
</li>
</ol>
<p><img src="http://image.rexking6.top/img/clip1538032901.png" alt=""></p>
<p><img src="http://image.rexking6.top/img/clip1538033072.png" alt=""></p>
<ol>
<li>Jepson等人 [2003]提出了一种物体跟踪器，它将物体跟踪为三分量混合物，包括稳定的外观特征，瞬态特征和噪声过程。<br>稳定分量确定运动估计的最可靠外观。瞬态分量识别快速变化的像素。 噪声分量处理对象外观中的异常值。在线版的EM算法用于学习这三种分量混合物的参数。根据跟踪区域从一帧到下一帧的变形来计算对象的运动。变形变换包括平移$(t_x,t_y)$，旋转$(a,b)$和尺度$s$，参数：</li>
</ol>
<script type="math/tex; mode=display">
{\left( \begin{array}{ccc}
x'\\
y'\\
\end{array} 
\right )}=
s{\left( \begin{array}{ccc}
a & b\\
-b & a
\end{array} 
\right )}
{\left( \begin{array}{ccc}
x\\
y
\end{array} 
\right )}+
{\left( \begin{array}{ccc}
t_x\\
t_y
\end{array} 
\right )}</script><p>稳定和瞬态分量的加权组合用于确定变形参数。</p>
<p><img src="http://image.rexking6.top/img/clip1538033135.png" alt=""></p>
<ol>
<li>1994年，Shi和Tomasi提出了KLT跟踪器，它迭代地计算以兴趣点为中心的区域（例如，25×25补丁）的平移。<br>KLT跟踪器通过计算连续帧中相应补丁之间的仿射变换来评估跟踪补丁的质量。</li>
</ol>
<script type="math/tex; mode=display">
{\left( \begin{array}{ccc}
x'\\
y'\\
\end{array} 
\right )}=
{\left( \begin{array}{ccc}
a & b\\
c & d
\end{array} 
\right )}
{\left( \begin{array}{ccc}
x\\
y
\end{array} 
\right )}+
{\left( \begin{array}{ccc}
t_x\\
t_y
\end{array} 
\right )}</script><p><img src="http://image.rexking6.top/img/clip1538033584.png" alt=""></p>
<h4 id="多目标跟踪模型"><a href="#多目标跟踪模型" class="headerlink" title="多目标跟踪模型"></a>多目标跟踪模型</h4><p>使用多视图外观模型跟踪：</p>
<ul>
<li>对象可能与不同的视图不同。</li>
<li>如果在跟踪期间对象视图发生显着变化，则外观模型可能不再有效。为了克服这个问题，可以离线学习对象的不同视图并用于跟踪。无法实时性。</li>
</ul>
<p>可以基于以下方式定性评估内核跟踪器：</p>
<ul>
<li>跟踪单个或多个对象</li>
<li>处理遮挡的能力</li>
<li>训练要求</li>
<li>运动模型的类型</li>
<li>要求手动初始化</li>
</ul>
<p>由于最先进方法的实时适用性，使用原始几何形状来表示对象非常常见。此类别中的跟踪方法计算对象的参数运动。</p>
<p>此动作通常采用变换，仿射或投射等形式。可以通过最大化前一帧和当前帧之间的对象外观相似性来估计对象的运动。估算过程可以采用暴力搜索的形式，也可以采用基于梯度上升（下降）的最大化（最小化）过程。基于渐变上升（下降）方法的对象跟踪器要求对象的某些部分至少在所选形状内可见，其位置由前一个对象位置定义。</p>
<p>为了消除这些要求，可能的方法是使用卡尔曼滤波或粒子滤波。对象表示的原始几何形状的一个限制是对象的一些部分可以留在定义的形状之外，而背景的一部分可以驻留在其中。在这种情况下，通过最大化模型相似性估计的对象运动可能不正确。要克服此限制，一种方法是强制内核驻留在对象内，而不是封装整个形状。</p>
<h3 id="剪影轮廓跟踪"><a href="#剪影轮廓跟踪" class="headerlink" title="剪影轮廓跟踪"></a>剪影轮廓跟踪</h3><p><img src="http://image.rexking6.top/img/clip1538034219.png" alt=""></p>
<p>剪影轮廓跟踪：基于轮廓的方法为具有复杂形状的对象（如手，头和肩）提供准确的形状描述。</p>
<p>基于轮廓的对象跟踪器的目标是通过使用先前帧生成的对象模型在每个帧中找到对象区域。模型可以是颜色直方图，物体边缘或物体轮廓。</p>
<p>最常见的轮廓表示形式为二进制指示器功能，它用一个标记对象区域，用零标记非对象区域。我们将轮廓跟踪器分为两类：形状匹配和轮廓跟踪。</p>
<p><strong>形状匹配</strong><br>形状匹配方法在当前帧中搜索对象轮廓。与基于模板匹配的跟踪类似，在当前帧中搜索对象轮廓及其关联模型。通过计算对象与从前一帧的假设对象轮廓生成的模型的相似性来执行搜索。假设轮廓仅从当前帧转换到下一帧。因此，不能够明确处理非刚性物体运动。对象模型通常采用边缘图的形式。重新初始化以处理每帧中的外观变化。</p>
<p>一个例子：<br>匹配形状是为了找到在两个连续帧中检测到的相应轮廓。轮廓匹配和点匹配之间的主要区别是对象表示和使用的对象模型。</p>
<ul>
<li>与使用点相比，轮廓匹配使用完整的对象区域。</li>
<li>轮廓匹配使用对象外观特征，而点匹配仅使用基于运动和位置的特征。</li>
<li>剪影检测通常通过背景减法进行。</li>
</ul>
<p>一旦提取了对象轮廓，就通过计算与每个轮廓相关联的对象模型之间的一些距离来执行匹配。对象模型可以是密度函数（颜色或边缘直方图），轮廓边界（闭合或开放对象轮廓），对象边缘或这些模型的组合。</p>
<p>匹配分数可以使用距离测量来计算，包括互相关，Bhattacharya距离和Kullback Leibler散度。Bhattacharya距离和Kullback Leibler散度的表现相似，两者都比基于相关性的测量表现更好。Haritaoglu等人[2000]通过在对象轮廓内获得的边缘信息对对象外观进行建模。</p>
<p><strong>轮廓跟踪</strong><br>在不连续帧中搜索可能的轮廓匹配的情况下，可以通过计算轮廓内的每个像素的流向量来执行跟踪轮廓，使得在整个轮廓上占优势的流用于生成轮廓轨迹。通过使用状态空间模型或直接最小化某些能量函数，跟踪方法迭代地将前一帧中的初始轮廓演变为当前帧中的新位置。此轮廓演变要求当前帧中对象的某些部分与前一帧中的对象区域重叠。</p>
<ul>
<li>使用状态空间模型跟踪轮廓<br>对象的状态是根据轮廓的形状和运动参数定义的。每次更新状态，以使轮廓的后验概率最大化。后验概率取决于先验状态和当前可能性，其通常由轮廓与观察边缘的距离来定义。</li>
</ul>
<p>一个例子：Isard和Blake（1998）根据样条形状参数和仿射运动参数定义了对象状态。</p>
<ol>
<li>测量值包括在轮廓法线方向计算的图像边缘。</li>
<li>使用粒子滤波器更新状态。</li>
</ol>
<p><img src="http://image.rexking6.top/img/clip1538035732.png" alt=""></p>
<ul>
<li>通过直接最小化轮廓能量函数进行跟踪<br>轮廓能量是根据时间梯度（光流）或从物体和背景区域产生的外观统计的形式的时间信息来定义的。使用时间图像梯度的轮廓跟踪是由计算光流的工作推动的。</li>
</ul>
<p>第一个例子：Bertalmio等人[2000]使用亮度恒定约束来演化连续帧中的轮廓。作者使用两个能量函数，一个用于轮廓跟踪，另一个用于强度变形。两种功能同时最小化。</p>
<p>第二个例子：Yilmaz和Shah[2004]使用围绕物体边界的带中生成的颜色和纹理模型演化物体轮廓（见图(a)）。</p>
<p><img src="http://image.rexking6.top/img/clip1538036105.png" alt=""></p>
<p>第三个例子：Yilmaz等人[2004]通过基于水平集的形状模型对物体形状及其变化进行建模。基于水平集的形状模型在跟踪过程中解析对象遮挡（参见图(b)）</p>
<p>跟踪轮廓的优势：灵活处理各种各样的物体形状。然而，通常基于轮廓边界的方法对噪声的抵抗力低于基于区域的方法。表示可以采用运动模型，外观模型或形状模型或其组合的形式。对象外观通常由参数或非参数密度函数建模，例如高斯混合或直方图。对于遮挡处理，常见的方法是假设恒定运动或恒定加速度，其中在遮挡期间，来自前一帧的对象轮廓被转换为其假设的新位置。对于处理对象拆分和合并，隐式轮廓表示处理得很好。</p>
<p><img src="http://image.rexking6.top/img/clip1538036132.png" alt=""></p>
<h2 id="遮挡处理"><a href="#遮挡处理" class="headerlink" title="遮挡处理"></a>遮挡处理</h2><p>遮挡可分为三类：自遮挡，对象间遮挡和背景场景结构遮挡。</p>
<ul>
<li>当对象的一部分遮挡另一部分时，会发生自我遮挡。在跟踪关节状物体时最常出现这种情况。</li>
<li>当跟踪的两个对象相互遮挡时，会发生对象间遮挡。</li>
<li>当背景中的结构遮挡被跟踪对象时，会发生背景遮挡。</li>
</ul>
<p>对于对象间遮挡，多对象跟踪器可以利用遮挡物和遮挡物的位置和外观的知识来检测和解决遮挡。</p>
<p>场景结构对对象的部分遮挡很难检测，因为难以区分改变其形状的对象和被遮挡的对象。问题：如何区分？</p>
<p>在跟踪过程中处理完全遮挡的常用方法是通过线性动态模型或非线性动力学对对象运动建模，并且在遮挡的情况下，继续预测对象位置，直到对象重新出现。</p>
<p>研究人员还利用其他功能来解决遮挡问题：</p>
<ul>
<li>Haritaoglu等人[2000]在部分遮挡期间定位人的头部</li>
<li>Dockstader和Tekalp [2001b]假设两个物体向相反方向移动</li>
<li>Cremers等人 [2002]从可能的物体形状的子空间分析（PCA）建立了一个形状模型，以填补缺失的轮廓部分</li>
<li>Yilmaz等人 [2004]使用基于水平集轮廓表示的混合模型构建在线形状先验。</li>
</ul>
<p>通过适当选择摄像机位置可以减少遮挡的可能性：</p>
<ul>
<li>摄像机安装在空中交通工具上;</li>
<li>观察相同场景的多个摄像机也可用于在跟踪过程中解决对象遮挡;</li>
<li>多镜头跟踪：使用多个摄像机进行跟踪的需要是使用深度信息进行跟踪和遮挡分辨率；使用多个摄像头是为了增加视野区域，因为单个摄像机无法观察大面积区域。</li>
</ul>
<h2 id="多镜头跟踪"><a href="#多镜头跟踪" class="headerlink" title="多镜头跟踪"></a>多镜头跟踪</h2><p>为了减少计算量，Mittal和Davis [2003]不进行密集深度估计，而是使用基于区域的立体方法计算稀疏深度图，即每个对象的单个深度估计。该方法假设固定摄像机。</p>
<p>Kang等人 [2003]使用固定和平移-倾斜-变焦相机的组合，具有重叠的视图用于跟踪。</p>
<p>平移变焦摄像机（PTZ摄像机）是一种通常用于安全摄像机的名称，可以进行远程方向和变焦控制。</p>
<p>为了获得摄像机之间的对应关系，必须对物体速度和路径做出一些假设。但是，这些方法假设</p>
<ol>
<li>摄像机是静止的</li>
<li>每个摄像机内的物体轨道都可用</li>
</ol>
<p>这些算法的性能在很大程度上取决于对象遵循已建立路径的程度以及跨摄像机的预期时间间隔。</p>
<p>问题：当物体在非重叠区域任意移动时如何处理问题？<br>可以采用跟踪识别方法，它使用对象的外观和形状在摄像机视图中重新出现时识别它。</p>
<h1 id="三：目标检测"><a href="#三：目标检测" class="headerlink" title="三：目标检测"></a>三：目标检测</h1><p>目标检测的一种常用方法是在单个帧中使用信息。</p>
<p>一些对象检测方法利用时间信息从一个帧序列计算减少错误的检测。这种时间信息通常以帧差的形式出现。帧差法的研究自70年代末以来。而之后开始采用背景减除。目标检测可以通过构建一个场景的表示来实现，称为背景模型，然后为每个进入的帧寻找模型的偏差。任何显著的变化在一个图像区域从背景模型表示一个移动的对象。</p>
<p>通常，<strong>连接组件算法</strong>用来连接区域对应的对象。大致的思想是，当对图像的各个像素分出前景盒背景后，有些地方会出现噪声，有的只是少数像素与周围的不同，那么就设置一个阈值，清除少数像素的噪声差异。</p>
<h2 id="背景减除"><a href="#背景减除" class="headerlink" title="背景减除"></a>背景减除</h2><p>对每个像素的颜色(Y、U和V的颜色空间)建模，用一个高斯模型模拟静止背景$(x,y)∼N(μ(x,y),∑(x,y))$，模型参数均值$μ(x,y)$和$协方差∑(x,y)$，在连续几帧之间观察颜色像素值的变化。输入一帧，计算其每个像素的颜色来自模型$N(μ(x,y),∑(x,y))$的可能性。偏离背景模型的像素被标记为前景像素。</p>
<p>单一的高斯函数的缺点：</p>
<ul>
<li>在一个特定的位置由于重复性运动对象可以观察到多种颜色。</li>
</ul>
<p>通过使用多元统计模型来描述单像素的背景颜色来克服该缺点。</p>
<p>混合高斯模型:<br>当前帧的像素检查通过比较它与MOG的每一个高斯模型，如果找到一个匹配，匹配的高斯分布的均值和方差进行更新；否则建立新的高斯模型，其均值等于当前像素的颜色和初始化的方差</p>
<p>除此之外，有人提出采用（空间）场景信息，而不是只使用基于像素颜色的信息。使用非参数核密度估计模型逐像素的背景。当前像素匹配不仅跟对应的背景像素模型匹配，而且还跟附近的像素匹配。</p>
<p>有人提出，提取5×5像素块的纹理特征和颜色特征。该方法对光照不敏感。</p>
<p>有人提出三层算法（three-tiered algorithm）：在像素级别，利用维纳滤波概率预测背景颜色。在区域界别，由均匀颜色组成的前景区域被填充。在帧级别，如果大部分的像素在一个帧突然变化，则假设基于像素颜色背景模型不再有效。在这一点上,一个先前存储的像素级背景模型应该被替换，或者应该被重新初始化。</p>
<p>汽车跟踪问题中，Rittscher等人使用隐马尔科夫模型(HMM)将图像中的小块分类为属于这三种状态之一，前景，背景，阴影。</p>
<p>总结：</p>
<ul>
<li>最近背景减除方法可以改变光照、噪声和周期运动的背景区域。</li>
<li>一些方法计算效率很高。</li>
<li>然而背景减除提供了不完整的对象区域在许多情况下（例如会出现对象的分裂或洞）。</li>
<li>许多最先进的背景减除方法都是采用固定的摄像机。</li>
<li>移动摄像机的解决方案可能是通过补偿传感器运动但需要假设在连续帧中，具备平面场景和小运动的条件。</li>
</ul>
<h2 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h2><p><img src="http://image.rexking6.top/img/clip1539233749.png" alt=""></p>
<p>图像分割算法的目的是将图像分割成感知相似的区域。分割两个问题：一个好的分割标准；实现有效的分割的方法。</p>
<h2 id="基于均值漂移聚类的分割"><a href="#基于均值漂移聚类的分割" class="headerlink" title="基于均值漂移聚类的分割"></a>基于均值漂移聚类的分割</h2><p>Comaniciu和Meer提出means hift方法找到在联合立体空间+颜色空间进行聚类。给定的图像，该算法从数据中随机选择初始化大量的虚拟聚类中心；每个聚类中心根据均值移位向量迭代移动，直到聚类中心不再改变位置。在均值漂移迭代中，一些聚类可能会合并。</p>
<p><img src="http://image.rexking6.top/img/clip1539233791.png" alt=""></p>
<p>限制：基于均值漂移聚类的分割需要对各种参数进行微调，以获得更好的分割效果，如颜色和空间核带宽的选择，以及区域大小的最小阈值对分割效果有很大的影响。均值漂移方法已被用于对象跟踪。</p>
<h2 id="基于Graph-Cut分割"><a href="#基于Graph-Cut分割" class="headerlink" title="基于Graph-Cut分割"></a>基于Graph-Cut分割</h2><p>图像分割也可以制定图划分问题，其中顶点就是图像的像素点。通过剪枝图的加权边，将图(图像)的像素划分为N个不相交的子图(区域)。修剪边的总权重在两个子图称为cut。权重通常是计算颜色、亮度、或纹理节点之间的相似性。</p>
<p><img src="http://image.rexking6.top/img/clip1539233834.png" alt=""></p>
<p>Wu和Leahy使用最小割，目标是找到最小割的分区。权重定义基于颜色相似性。最小割的一个限制是它倾向过度分割图像。</p>
<p>Shi和Malik提出了normalized cut来克服过度分割问题。在他们的方法中，将不仅取决于切割边的权值之和，也取决于总连接节点的权重与在每个区域的所有图的节点和之比。节点之间的权值定义为对象颜色相似度和空间距离。此方法与mean shift相比，需要手动选择的参数较少。然而,它可以计算效率低。normalize cut也被用于上下文跟踪对象轮廓。</p>
<h2 id="主动轮廓"><a href="#主动轮廓" class="headerlink" title="主动轮廓"></a>主动轮廓</h2><p><img src="http://image.rexking6.top/img/clip1539233884.png" alt=""></p>
<p>对象分割是通过扩展的一个封闭的轮廓对象的边界，这样轮廓会紧紧包含对象区域。扩展的轮廓是由一个能量函数定义了轮廓与假设物体区域的适应性。不同的研究人员使用不同的能量项，有关图像表观的能量、正则化约束和一些额外的约束。基于图像的能量计算局部或全局特征。</p>
<p>局部信息的形式通常是一个图像梯度和评估轮廓。全局特征计算对象的内部和外部区域，使用颜色特征或纹理特征。一些只使用图像梯度作为图像的能量。然而，图像梯度对局部极小值是敏感的。Zhu和Yuille提出使用区域信息替代图像的梯度信息，但并没有取得好的效果。</p>
<p>Paragios和Deriche提出使用联合梯度和基于区域的能量。他们通过混合高斯模型对外观建模。轮廓扩展收敛首先在全局执行，然后在每次迭代中局部执行。</p>
<p>基于轮廓的方法的一个重要问题是轮廓初始化。在基于图像梯度的方法中，轮廓通常被放置在物体区域之外并缩小，直到遇到物体边界。这种约束在基于区域的方法中被放宽，以便轮廓可以在对象内部或外部初始化。</p>
<p>Paragios和Deriche使用背景减除来初始化轮廓，没有用到构建的先验区域。</p>
<h2 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h2><h3 id="cotraining"><a href="#cotraining" class="headerlink" title="cotraining"></a>cotraining</h3><p>对象检测可以通过学习一组不同的对象视图样本，这属于监督学习机制。它不需要存储一组完整的模板。给定一组学习的例子，有监督学习方法生成一个函数映射输入所期望的输出。训练样本是一对对象特征和一个关联的对象类。这两个量都是手动定义的。</p>
<p>特征选择在分类性能中发挥着重要作用。重要的是使用一组特征，它能够区分一个类和另一个类。可以选择不同的特征，如对象区域，对象方向和对象外观等。一旦选择了特征，可以通过选择有监督学习的方法，如神经网络、自适应增强、决策树、支持向量机进行学习。</p>
<p>有监督学习方法通常需要大量的手工标记样本每个对象类。一个可能的方法来减少手工标记的数据量是cotraining监督学习。训练的主要想法是两个分类器利用少量的标记数据学习，其中标记的数据先用于其中一个分类器进行学习，之后用其预测未标记的数据，再将该粗标记数据给第二个分类器进行学习。</p>
<p>cotraining可以提供非常准确的分类规则。它已成功用于减少手动交互所需的训练。</p>
<h3 id="boosting"><a href="#boosting" class="headerlink" title="boosting"></a>boosting</h3><p>boosting是一个迭代的方法，找到一个非常准确的分类器，通过结合许多基本分类器，每个可能只是一定程度上的准确。在训练阶段，第一步是建立一个初始分布权重的训练集。boosting机制选择一个基分类器，它有最少的错误。如果选择的基分类器分类错误增加的话，这部分错误的数据的权重增加。上下文中的对象检测，弱分类器可以是简单的运算，例如一组阈值等，应用于从图像中提取对象特征。</p>
<p>Viola等人使用Adaboost算法框架用来检测行人。在他们的方法中，图像特征提取用的是时域运算符和空域运算符的组合。特征提取的操作符是简单的矩形滤波器。</p>
<p>时域中的运算符采用帧差的形式，它对某种形式的运动信息编码。帧差法通过在发生运动的区域中强制执行对象检测来减少错误检测的数量。</p>
<p><img src="http://image.rexking6.top/img/clip1539234098.png" alt=""></p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>SVM通过找到将一个类与另一个类分离的最大间隔超平面来将数据聚类成两个类。最大化超平面的间隔，被定义为超平面和两个类中最近的数据点之间的距离。位于超平面边缘边界上的数据点称为支持向量。在目标检测的背景下,这些类对应于对象类(正样本)和非对象类(负样本)。尽管SVM是一个原本的线性分类器，也可以使用核把支持向量机应用于非线性分类器。内核的应用是对于线性不可分的一组数据，将数据变换到一个高维空间，可能变成了可分的。对核的选择并不容易。它可以是高斯核，多项式核等。</p>
<h2 id="滑动窗口机制"><a href="#滑动窗口机制" class="headerlink" title="滑动窗口机制"></a>滑动窗口机制</h2><p>主要思想是将对象检测问题转换成一个二进制分类问题。滑动窗口在图像寻找对象。换句话说，就是在不同的尺度下对图像进行穷尽的搜索。</p>
<p><strong>训练</strong></p>
<ol>
<li>准备大量的训练例子(图片)。其中一些必须包含感兴趣的对象，称为正样本，而另一些则不包含，称为负样本。</li>
<li>提取某种全局特征来表示每个直方图/向量训练的样本。</li>
<li>将所有特征向量训练算法获得一个分类器，它可以告诉某个向量是否属于某个对象。</li>
</ol>
<p><strong>测试</strong></p>
<ol>
<li>从一个测试图像裁剪出子窗口。</li>
<li>同训练阶段一样，从这子窗口中以同样的方式提取特征向量。</li>
<li>将向量分类器做判断这个向量是否代表一个对象。</li>
<li>对下一个子窗口重复以上步骤，检查了所有子窗口找到图像中所有对象的位置。</li>
<li>第一次遍历后，扩大或者缩小尺度对图像再遍历一遍。一般处理3~5个尺度。</li>
</ol>
<p><img src="http://image.rexking6.top/img/clip1539242401.png" alt=""></p>
<h2 id="经典方法"><a href="#经典方法" class="headerlink" title="经典方法"></a>经典方法</h2><h3 id="Haar特征-Adaboost分类器"><a href="#Haar特征-Adaboost分类器" class="headerlink" title="Haar特征+Adaboost分类器"></a>Haar特征+Adaboost分类器</h3><p><img src="http://image.rexking6.top/img/clip1539243137.png" alt=""></p>
<p>Haar特征简单有效。区域的特征值是白色块所有像素的灰度值的总和减去黑色块的总和。由于区域的大小、位置和长宽比都没有限制，所以在一幅图像中有上万个区域可供选择，哪一个是最具有鉴别性的？</p>
<p>采用AdaBoost算法选择最具鉴别性的区域(Haar特征)来训练大量的弱分类器，所有弱分类器的加权和就是最终的强分类器。</p>
<h3 id="Hog特征-SVM分类器"><a href="#Hog特征-SVM分类器" class="headerlink" title="Hog特征+SVM分类器"></a>Hog特征+SVM分类器</h3><p><img src="http://image.rexking6.top/img/clip1539243430.png" alt=""></p>
<p>HOG：梯度方向的直方图，计算训练图像中每个像素的梯度，包括方向。连接4个单元格的HOG，形成一个更大的HOG。将训练图像中所有块的HOG连接起来，形成该图像的最终HOG或特征向量。</p>
<p><img src="http://image.rexking6.top/img/clip1539243550.png" alt=""></p>
<p>在测试阶段，从每个子窗口提取特征向量，并由训练后的支持向量机进行分类。</p>
<h3 id="基于部分分块的方法"><a href="#基于部分分块的方法" class="headerlink" title="基于部分分块的方法"></a>基于部分分块的方法</h3><p>在通过考虑对象的整体外观来提取全局特征的情况中，当测试图像中存在遮挡时，全局特征通常会失败。基于部分分块的方法人为地分割把对象分成几部分，独立地检测每个部分，然后搜索对象的各部分之间的内在关系。</p>
<p><img src="http://image.rexking6.top/img/clip1539243851.png" alt=""></p>
<h3 id="视觉单词词袋"><a href="#视觉单词词袋" class="headerlink" title="视觉单词词袋"></a>视觉单词词袋</h3><p><a href="http://blog.rexking6.top/2018/09/24/Bag-of-visual-word%E8%A7%86%E8%A7%89%E8%AF%8D%E8%A2%8B/">Bag-of-visual word视觉词袋</a></p>
<h3 id="基于轮廓的方法"><a href="#基于轮廓的方法" class="headerlink" title="基于轮廓的方法"></a>基于轮廓的方法</h3><p><img src="http://image.rexking6.top/img/clip1539243987.png" alt=""></p>
<p>物体的轮廓被分割成几个线段，每个线段独立建模。测试图像的轮廓以某种方式与建模对象轮廓匹配，例如控制点对应、倒角距离等等。</p>
<p>缺点：依赖的全局特征，在遇到遮挡情况下会失败。</p>
<h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><p>在实际场景中，可能违反诸如运动的平滑性，最小遮挡量，照明恒定性，相对于背景的高对比度等假设。这些限制应用程序，如自动监视，人机交互，视频检索，交通监控和车辆导航。特征选择，对象表示，动态形状和运动估计非常热门。</p>
<p>对于从广播新闻网络或家庭视频获得的视频，它们是嘈杂的，压缩的，非结构化的，并且通常包含通过从多个视图移动相机而获得的编辑剪辑。</p>
<p>对于正式和非正式会议的视频，它们通常在一个小的视场中包含多人。因此，有严重的遮挡。一个可能的解决方案是采用音频（例如，演讲者的音频定位）。</p>
<p>另一个解决方案是上下文信息的集成。</p>
<ul>
<li>例如，车辆跟踪，应该限制车辆的位置路径在路上。</li>
<li>一个跟踪器如果能够约束物体的形状和运动通常会表现的更好。</li>
</ul>
<p>使用特定的特征集进行跟踪也会极大地影响性能。特征最好的是能够区分多个对象，对象和背景。一些跟踪算法使用多个特征的加权组合。在机器学习和模式识别的社区，特征选择算法被广泛地研究。然而，这些算法需要关于目标和背景的离线训练信息。</p>
<p>当物体的外观或背景发生变化时，鉴别性地特征也会发生变化。因此，有必要对鉴别性特征进行在线选择。实现这一目标的一个有前景的方向是使用在线boosting选择特征选择。</p>
<p>大多数跟踪算法使用指定对象表示的模型。提高在线学习对象模型的能力将大大提高跟踪器的适用性。</p>
<p>基于运动的分割和多体分解方法已经被用来学习多物体运动的模型。然而,这些方法假设的是刚体运动。从单一相机中无监督学习对象模型的多个非刚性的移动对象仍然是一个尚未解决的问题。一个有趣的方向是使用semi-supervised学习建模对象的方法。应利用额外的信息来源，例如先前和上下文信息。有方法来集成这些不同的信息来源将生成一个通用跟踪器，可以成功地应用于各种应用程序。</p>
<h2 id="References-1"><a href="#References-1" class="headerlink" title="References"></a>References</h2><ul>
<li>PAUL VIOLA, etc, “Robust Real-Time Face Detection”, International Journal of Computer Vision, 57(2), 137–154, 2004.</li>
<li>N. Dalal and B. Triggs, “Histograms of Oriented Gradients for Human Detection” , CVPR 2006.</li>
<li>Bastian Leibe, etc, “Robust Object Detection with Interleaved Categorization and Segmentation”, International Journal of Computer Vision (2008) 77: 259–289. </li>
<li>D. Comaniciu, V. Ramesh, and P. Meer. “Mean shift: A robust approach towards feature space analysis”, IEEE Trans. on Pattern Analysis and Machine Intelligence, 24(5):603–619, 2002. </li>
<li>Dorin Comaniciu, Visvanathan Ramesh, Peter Meer, “Kernel-Based Object Tracking”, IEEE Trans. Pattern Anal. Mach. Intell. 25(5): 564-575 (2003) </li>
<li>Michael Isard and Andrew Blake, “CONDENSATION — conditional density propagation for visual tracking”, Int. J. Computer Vision, 29, 1, 5—28, (1998) </li>
</ul>
<h1 id="四、密度估计理论和基于像素的背景分割"><a href="#四、密度估计理论和基于像素的背景分割" class="headerlink" title="四、密度估计理论和基于像素的背景分割"></a>四、密度估计理论和基于像素的背景分割</h1><h2 id="密度估计"><a href="#密度估计" class="headerlink" title="密度估计"></a>密度估计</h2><p>考虑任意具有概率密度函数$f$的随机数量$X$，我们有:</p>
<script type="math/tex; mode=display">P(a<X<b)=\int_a^b f(x)dx,for \space all \space a<b.</script><p>假设我们有一组观察到的数据点假设是来自未知密度函数的样本。我们的目标是根据观测数据估计密度函数。</p>
<p>密度估计有两种方法，参数估计和非参数估计：</p>
<ul>
<li>参数方法假定数据是从一个已知的分布（例如，正态分布中的均值和方差）。</li>
<li>非参数方法假设$f$分布的概率密度,然后是用来估计$\hat f$的数据。</li>
</ul>
<h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><p>它是最古老和使用最广泛的密度估计。</p>
<p>直方图的区间被定义为$[x_0+mh,x_0+(m+1)h)$，对于$m$个正整数和负整数，$x_0$是原点，$h$是区间宽度。</p>
<p>直方图定义如下：</p>
<script type="math/tex; mode=display">\hat f(x)=\frac{(number\space of \space X_i \space in \space the \space same \space bin \space as \space x)}{nh}</script><h4 id="推广"><a href="#推广" class="headerlink" title="推广"></a>推广</h4><p>直方图可以通过允许区间宽度变化来推广，新的估计为：</p>
<script type="math/tex; mode=display">\hat f(x)=\frac{(number\space of \space X_i \space in \space the \space same \space bin \space as \space x)}{n(width \space of \space bin \space containing \space x)}</script><p><img src="http://image.rexking6.top/img/clip1539847902.png" alt=""></p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>在聚类分析和非参数判别分析等过程，使用直方图导致低效地使用数据；</li>
<li>直方图不是连续的，当需要求导时就会出现问题；</li>
<li>初始点的选择可能会有影响的解释；</li>
<li>用直方图表示二元或三元变量数据是很困难的。</li>
</ul>
<h3 id="朴素估计"><a href="#朴素估计" class="headerlink" title="朴素估计"></a>朴素估计</h3><p>如果随机变量$X$的密度为$f$，则：</p>
<script type="math/tex; mode=display">
f(x)=lim_{h\rightarrow 0}\frac{1}{2h}P(x-h<X<x+h)</script><p>因此，朴素估计量为：</p>
<script type="math/tex; mode=display">
\hat f(x)=\frac{[number \space of \space X_i's \space in \space (x-h,x+h)]}{2hn}</script><p>我们将权重函数定义如下:</p>
<script type="math/tex; mode=display">
w(x)=\left\{
\begin{aligned}
\frac{1}{2} \space&\space if \space -1<x<1\\
0 \space&\space if \space otherwise
\end{aligned}
\right.</script><p>然后$\hat f(x)$变成：</p>
<script type="math/tex; mode=display">
\frac{1}{nh}\sum_{i=1}^n w(\frac{x-x_i}{h})</script><p>与直方图的关系：</p>
<script type="math/tex; mode=display">
\hat f(x)=\frac{number \space of \space X_i \space in \space the \space same \space bin \space as \space x}{nh}</script><p>我们可以认为，估计是通过在每个观测点上放置一个宽度$2h$，高度为$(2nh)^{-1}$的“盒子”，然后将所有这些盒子相加得到估算。</p>
<p>如果$x$恰好位于某个直方图箱的中心，那么朴素估计就是$x$处直方图的纵坐标。</p>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><p>$\hat f$不是连续的，而是在$X_i \pm h$的跳跃点，而其他地方导数为0。下面的例子可以看到：</p>
<p><img src="http://image.rexking6.top/img/clip1539849431.png" alt=""></p>
<h3 id="核估计"><a href="#核估计" class="headerlink" title="核估计"></a>核估计</h3><p>核估计是一个泛化的朴素估计量。</p>
<p>用$K$取代之前的权函数，其中$\int_{-\infty}^{\infty}K(x)dx=1$，且对于所有的$u$，都有$K(-u)=K(u)$。然后核估计表示为：</p>
<script type="math/tex; mode=display">
\hat f(x) = \frac{1}{nh} \sum_{i=1}^{n}K(\frac{x-X_i}{nh})</script><p>$h$被称为带宽，它是平滑参数，K是核函数。</p>
<p><img src="http://image.rexking6.top/img/clip1539849970.png" alt=""></p>
<p>带宽$h$的值对密度估计有显著影响：</p>
<ul>
<li>$h$趋于0时，密度估计像是狄拉克$δ$函数的和；</li>
<li>$h$的值比较大时，密度估计会比较模糊和虚假的，图中为$h=0.2,0.4,0.8$</li>
</ul>
<p><img src="http://image.rexking6.top/img/clip1539850347.png" alt=""></p>
<p><img src="http://image.rexking6.top/img/clip1539850408.png" alt=""></p>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>窗口宽度是固定的，在估计的尾部出现假噪声的趋势；</li>
<li>如果估计为了要处理这个问题而变得平滑，那么主要部分分布的基本特征可能就会被掩盖了。</li>
</ul>
<p><img src="http://image.rexking6.top/img/clip1539850601.png" alt=""></p>
<h3 id="最近邻方法"><a href="#最近邻方法" class="headerlink" title="最近邻方法"></a>最近邻方法</h3><p>这是一种使平滑适应“局部”数据密度的方法。</p>
<p>平滑度由整数$k$控制，通常$k \approx n^{1/2}$。</p>
<p>我们定义两点之间的距离：$d(x,y)$。</p>
<p>对于每个$t$，我们定义$d_1(t) \le d_2(t) \le … \le d_n(t)$，这是$t$到样本点的距离。</p>
<p>然后第$k$个近邻密度估计量是：</p>
<script type="math/tex; mode=display">
\hat f(t)=\frac{k}{2nd_k(t)}</script><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>在估计分布的尾部，距离$d_k(t)$将大于主要部分，因此尾部欠平滑的问题将减少。</p>
<h4 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>该估计并不是一个平滑的曲线；</li>
<li>$d_k(t)$是连续但不可导；</li>
<li>如果整个密度的估计是必需的，该估计会是不合适的。</li>
</ul>
<h3 id="广义-k-近邻估计"><a href="#广义-k-近邻估计" class="headerlink" title="广义$k$近邻估计"></a>广义$k$近邻估计</h3><script type="math/tex; mode=display">
\hat f(x)=\frac{1}{nd_k(t)}\sum_{i=1}^nK(\frac{t-X_i}{d_k(t)})</script><h3 id="可变核估计"><a href="#可变核估计" class="headerlink" title="可变核估计"></a>可变核估计</h3><p>$K$是核函数，$k$是正整数。$d_{j,k}$是从$X_j$到其他$(n-1)$个数据点的集合中的第$k$个最近点的距离。 那么可变核估计是：</p>
<script type="math/tex; mode=display">
\hat f(t) = \frac{1}{n}\sum_{j=1}^n\frac{1}{hd_{j,k}}K(\frac{t-X_j}{hd_{j,k}})</script><p>窗口宽度与$d_{j,k}$成比例。 因此，数据很少的区域中的数据点将具有更平坦的内核。</p>
<p><img src="http://image.rexking6.top/img/clip1539851803.png" alt=""></p>
<h5 id="常用的核函数"><a href="#常用的核函数" class="headerlink" title="常用的核函数"></a>常用的核函数</h5><p><img src="http://image.rexking6.top/img/clip1539851847.png" alt=""></p>
<p><img src="http://image.rexking6.top/img/clip1539851879.png" alt=""></p>
<h4 id="多维数据的核方法"><a href="#多维数据的核方法" class="headerlink" title="多维数据的核方法"></a>多维数据的核方法</h4><p>多变量核密度估计的定义：</p>
<script type="math/tex; mode=display">
\hat f(x)=\frac{1}{nh^d}\sum_{i=1}^nK\{\frac{1}{h}(x-X_i)\}</script><p>核函数$K(x)$是一个函数，用$d$维的$x$，满足：</p>
<script type="math/tex; mode=display">
\int_{R^d}K(x)dx=1</script><p>通常，$K$将是径向对称的单峰概率密度函数，例如标准的多元正态密度函数：</p>
<script type="math/tex; mode=display">
K(x)=(2\pi)^{-d/2}exp(-\frac{1}{2}x^Tx)</script><p>另一个可能的核是多变量Epanechnikov核：</p>
<script type="math/tex; mode=display">
K_e(x)=\left\{\begin{aligned}&\frac{1}{2}c_d^{-1}(d+2)(1-x^tx)\space\space &if \space x^Tx<1\\&0 \space\space &if \space otherwise\end{aligned}\right.</script><p>其中$c_d$是单位$d$维球体的体积：$c_1 = 2$，$c_2 = \pi$，$c_3 = 4\pi/3$等。</p>
<p>对于$d=2$：</p>
<script type="math/tex; mode=display">
K_2(x)=\left\{\begin{aligned}&3\pi^{-1}(1-x^Tx)^2\space\space &if \space x^Tx<1\\&0 \space\space &if \space otherwise\end{aligned}\right.</script><p>对于$d=3$：</p>
<script type="math/tex; mode=display">
K_3(x)=\left\{\begin{aligned}&4\pi^{-1}(1-x^Tx)^3\space\space &if \space x^Tx<1\\&0 \space\space &if \space otherwise\end{aligned}\right.</script><h2 id="基于像素的背景分割"><a href="#基于像素的背景分割" class="headerlink" title="基于像素的背景分割"></a>基于像素的背景分割</h2><p>背景减除法是一种广泛使用的概念，用于检测从静态摄像机拍摄的视频中的运动物体。</p>
<p>摄像机静止时，移动物体的检测可以通过用场景背景的表示来比较每一个新的帧来实现。这一过程称为背景减除法，场景表示称为背景模型。</p>
<p>背景减除法过程形成的第一步是自动视觉监视系统和动作捕捉应用程序。背景减除法的结果用于进一步的处理。</p>
<p>基于像素的检测使用背景减除法的一个主要优点是，结果是一个准确地从背景分割的前景区域。</p>
<p>对人类，这个过程给了准确的人体轮廓，可以进一步用于跟踪、姿势和姿态估计等。</p>
<p>这是更可取的基于分类器和基于对象的探测器，主要决定图像中是否是一个边界框或一个区域。</p>
<h3 id="背景模型的挑战"><a href="#背景模型的挑战" class="headerlink" title="背景模型的挑战"></a>背景模型的挑战</h3><p>Toyama等人确定了背景模型必须克服的十个挑战的列表，并通过移动的物体，一天的时间，灯光的开关，树木的摆动，伪装，bootstrapping，前景光圈，睡觉的人，行走的人，阴影来表示它们。</p>
<h4 id="光照变化挑战"><a href="#光照变化挑战" class="headerlink" title="光照变化挑战"></a>光照变化挑战</h4><ul>
<li>因为白天太阳的相对位置，照明的渐变可能发生在户外场景。</li>
<li>突变可能发生在一个室内环境中，因为灯的打开或关闭；或在室外环境中，例如多云，阳光明媚的条件之间的变化。</li>
<li>由背景中的对象（例如，建筑物和树木）或通过移动前景对象在背景上投射的阴影。</li>
</ul>
<h4 id="运动变化挑战"><a href="#运动变化挑战" class="headerlink" title="运动变化挑战"></a>运动变化挑战</h4><ul>
<li>由于小相机位移产生的全局图像运动。在室外环境中，由于风荷载或其他运动源引起的小型摄像机位移是常见的，这导致了图像的整体运动。</li>
<li>部分背景的运动。例如，树枝随风飘动，或流水荡漾。</li>
</ul>
<h4 id="结构变化挑战"><a href="#结构变化挑战" class="headerlink" title="结构变化挑战"></a>结构变化挑战</h4><p>这些变化引入到背景中，包括任何几何上的变化或由目标引入的场景背景的外观。这种变化通常发生在场景背景中引入一些相对不变的东西（BK对象移除或停车场）时。</p>
<h4 id="其他挑战"><a href="#其他挑战" class="headerlink" title="其他挑战"></a>其他挑战</h4><p>另一个基本问题是统计模型的选择。选择合适的模型取决于场景背景中预期的变化类型。这种选择极大地影响了检测的准确性。</p>
<p>在选择特征和统计模型之外，保持背景表示是另一个具有挑战性的问题。</p>
<p>如果之前的观察不是完全来自于背景，即前景对象出现在背景中，问题变得更具挑战性（Bootstrapping）。</p>
<p>均匀彩色物体移动时，内部像素的改变不能被检测到。因此，整个对象可能不会显示为前景（前景光圈）。</p>
<h3 id="统计场景建模"><a href="#统计场景建模" class="headerlink" title="统计场景建模"></a>统计场景建模</h3><h4 id="参数背景模型"><a href="#参数背景模型" class="headerlink" title="参数背景模型"></a>参数背景模型</h4><p>根据单个高斯模型，噪声分布在给定像素上是一个零均值高斯分布，它遵循$N(\mu, \sigma^2)$。</p>
<p>估计模型的参数变为从历史像素观察中，估计均值和方差。</p>
<p>为了检测前景，这相当于用一个阈值在高斯的尾部截断：</p>
<script type="math/tex; mode=display">
||x_t-\hat \mu||>k\hat \sigma</script><p>其中，$\hat \mu$和$\hat \sigma$是估计的均值和标准差，$k$是阈值。</p>
<h5 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h5><p>这种基本的单高斯模型可以通过递归更新每一帧的均值来保持背景图像，从而适应场景中缓慢的变化（例如渐变的光照变化）：</p>
<script type="math/tex; mode=display">
B_t=\frac{t-1}{t}B_{t-1}+\frac{1}{t}I_t</script><p>但是，这种更新机制不会遗忘历史，因此，新图像对模型的影响趋于零。</p>
<p>一个更实用、更有效的解决方案是通过指数遗忘递归地更新模型，即</p>
<script type="math/tex; mode=display">
B_t=\alpha I_t + (1-\alpha)B_{t-1}</script><p>参数$α$控制遗忘旧的背景信息的速度。更新方程是一个有增益系数$α$的低通滤波器，有效地分离了缓慢的时间过程（背景）和快速过程（移动的对象）。</p>
<h4 id="处理动态背景：混合高斯模型GMM"><a href="#处理动态背景：混合高斯模型GMM" class="headerlink" title="处理动态背景：混合高斯模型GMM"></a>处理动态背景：混合高斯模型GMM</h4><p>在户外环境中移动的树木和灌木，场景背景并非完全静态的。</p>
<p>单高斯模型假设像素强度的概率密度函数不会发生变化。</p>
<p>基于混合高斯模型的泛化被用于这样的变化。</p>
<p>像素的强度由$K$个高斯分布的混合建模（K是从3到5的小数字）。</p>
<p>加权混合，某个像素在时间$t$具有强度$x_t$的概率估计为：</p>
<script type="math/tex; mode=display">
Pr(x_t)=\sum_{i=1}^Kw_{i,t}G(x_t,\mu_{i,t},\Sigma_{i,t})</script><p>其中，$w_{i,t}$，$\mu_{i,t}$，和$\sum_{i,t}=\sigma_{i,t}I$分别是$t$时刻第$i$个高斯混合成分权重，均值和协方差。</p>
<script type="math/tex; mode=display">\eta(X_t,\mu,\Sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}e^{-\frac{1}{2}}(X_t-\mu_t)^T\Sigma^{-1}(X_t-\mu_t)</script><p>且</p>
<script type="math/tex; mode=display">
\Sigma_{k,t}=\sigma_k^2I</script><p>分布的参数是递归更新的。</p>
<p>根据现有的$K$个高斯模型检查新的像素值，当找到匹配时，该分布的权重更新如下：</p>
<script type="math/tex; mode=display">
w_{i,t}=(1-\alpha)w_{i,t-1}+\alpha M(i,t)</script><p>其中$M(i,t)$是指标变量，如果第$i$个成分匹配则为1，否则为0。 匹配分布的参数更新为：</p>
<script type="math/tex; mode=display">
\mu_t=(1-\rho)\mu_{t-1}+\rho x_t,\\
\sigma_t^2 = (1-\rho)\sigma_{t-1}^2+\rho(x_t-\mu_t)^T(x_t-\mu_t)</script><p>参数$\alpha$和$\rho$是两个学习率。$K$个分布基于$w_j/\sigma_j^2$排序，前B个分布被用作场景背景的模型，其中$B$被估计为</p>
<script type="math/tex; mode=display">
B=argmin_b(\sum_{j=1}^bw_j>T)</script><p>阈值$T$是赋给背景模型的总权重的分数。通过将距离任何$B$个分布多2.5个标准偏差的任何像素标记为前景像素来执行背景减除法。</p>
<h4 id="非参数化背景模型"><a href="#非参数化背景模型" class="headerlink" title="非参数化背景模型"></a>非参数化背景模型</h4><p>给定密度分布函数$p(x)$的一些样本$S=\{x_i\}_{i=1,…,N}$，关于$p(x)$的密度估计：</p>
<script type="math/tex; mode=display">
\hat p(x)=\frac{1}{N}\sum_{i=1}^NK_\sigma(x-x_i)</script><p>其中$K_\sigma$是核函数，有时也称为窗口函数，其带宽（尺度）为$\sigma$，且有$K_\sigma(t)=\frac{1}{\sigma}K(\frac{t}{\sigma})$。核函数$K$应该满足$K(t) \ge 0$且$\int K(t)dt=1$。</p>
<p>为避免必须通过加权样本的子集来存储完整的数据集，如下所示：</p>
<script type="math/tex; mode=display">
\hat p(x)=\sum_{x_i\in B}\alpha_iK_\sigma(x-x_i)</script><p>其中，$\alpha_i$是总计为1的加权系数，而$B$是一个采样子集。</p>
<p>这个估计可以推广到使用高维特征通过使用核乘积为：</p>
<script type="math/tex; mode=display">
Pr(x_t)=\frac{1}{N}\sum_{i=1}^N\prod_{j=1}^d K_{\sigma_j}(x_{t_j}-x_{i_j})</script><p>其中，$x_t$是$t$时刻的$d$维的颜色特征，$K_{\sigma_j}$是带宽为$\sigma_j$在第$j$个颜色空间维数的核函数。</p>
<p><strong>怎么检测前景像素？</strong></p>
<p>利用这种概率估计，如果$$，该像素被认为是前景像素，其中阈值$th$是一个所有的图像的全局阈值，可以调整达到预期的false positives百分比。</p>
<p><strong>缺点：速度慢</strong></p>
<p>在给定强度值差$(x_t-x_i)$和核函数带宽的情况下，可以使用预先计算的核函数值的查找表以非常快的方式计算概率估计。</p>
<p>对等式中的和的部分评估通常足以超过大多数图像像素的阈值。</p>
<p><strong>改进</strong></p>
<p>由于随机噪声和小的运动背景，需要抑制一些虚假检测。</p>
<p>$x$的附近我们可以考虑消除许多虚假检测：</p>
<script type="math/tex; mode=display">
P_N(x_t)=max_{y \in N(x)}Pr(x_t|B_y)</script><p>为了避免丢失可能意外与背景相似的真实检测，添加了一个约束，即使用整个被检测到的前景对象和被检测到的连接组件的概率:</p>
<script type="math/tex; mode=display">
P_C=\prod_{x\in C}P_N(x)</script><p>只有在以下情况下，检测到的像素才会被认为是背景的一部分：</p>
<script type="math/tex; mode=display">
(P_N(x)>th_1)\wedge(P_C(x)>th_2)</script><p><img src="http://image.rexking6.top/img/clip1539860648.png" alt=""></p>
<p><strong>更新模型</strong></p>
<p>模型的自适应可以通过添加新样本和忽略旧样本来实现。</p>
<p>使用核密度估计方法时需要解决的一个主要问题是选择合适的核带宽（尺度）。（当样本数量趋向无穷大时，对带宽的选择是不重要的；当数据量小时，带宽的选择非常重要。）</p>
<p><strong>改进</strong></p>
<p>KDE背景模型的缺点之一是要求为每个像素存储大量的历史样本：</p>
<ul>
<li>Piccardi和Jan提出一个高效的均值漂移方法均值漂移估计一个像素的模式的历史PDF的高斯函数用于PDF模型。</li>
<li>Han等人提出了一个连续核密度估计方法，其中可变带宽mean shift被用来检测密度模式。</li>
</ul>
<p>一些方法可以自适应地估计大量的模式来表示密度，因此保持了非参数模型的灵活性，实现了参数化模型的效率：</p>
<ul>
<li>快速高斯变换提出了KDE的有效计算。然而，快速高斯变换仅适用于密度估计所需的大量样本。KDE用于像素级别以及区域级别或域范围表示中以模拟场景背景。</li>
</ul>
<h4 id="移动的阴影抑制"><a href="#移动的阴影抑制" class="headerlink" title="移动的阴影抑制"></a>移动的阴影抑制</h4><p><img src="http://image.rexking6.top/img/clip1539865773.png" alt=""></p>
<ul>
<li>静态对象的阴影通常可以在背景进程中进行调整。</li>
<li>移动物体的动态阴影构成前景分割的挑战。</li>
<li>附在轮廓上的阴影会在贴合肢体和估计身体姿势时出现问题。</li>
<li>半影阴影可以通过较低的强度值来表征，同时保留背景的色度，即消色差阴影。</li>
<li>关于检测阴影的大多数研究都集中在消色差阴影上。</li>
</ul>
<p>一个像素的亮度是RGB通道的线性组合，这里记为$I$：</p>
<script type="math/tex; mode=display">
I=w_rR+w_gG+w_bB</script><p>当物体在像素上投射阴影时：</p>
<script type="math/tex; mode=display">
\widetilde I = \alpha I</script><p>$α<1$是影子，$α>1$是高亮。</p>
<p>我们假设由阴影引起的像素亮度变化对三个通道的影响是相同的。因此,观察到的颜色是$αR$，$αG$，$αB$。</p>
<p>我们的目标是消除$α$因子,这样颜色空间有阴影不变性和高亮不变性。</p>
<p>归一化rgb：只有两个坐标足以表示色度，因为$r + g + b = 1$，$α$因子对它们没有影响。</p>
<script type="math/tex; mode=display">
r=\frac{R}{R+G+B}，g=\frac{G}{R+G+B}，b=\frac{B}{R+G+B}</script><p>色度变量$r$、$g$在阴影下不会发生变化，$s$在一定范围内变化，与场景中预期的阴影和亮点相对应。</p>
<script type="math/tex; mode=display">
B=\{x_i|x_i \in A \wedge \alpha \le \frac{s_t}{s_i} \le \beta\}</script><p>另一类阴影抑制算法是依赖图像梯度来模拟场景背景的方法。想法是背景中的纹理信息在阴影下是一致的，因此使用图像梯度作为特征，这样除阴影边界外，投射阴影将不变。除色度模型外，它们还使用背景边缘或梯度模型来检测阴影。</p>
<h4 id="移动摄像头的背景减除法"><a href="#移动摄像头的背景减除法" class="headerlink" title="移动摄像头的背景减除法"></a>移动摄像头的背景减除法</h4><p>场景背景采用基于区域的表示可以适用于某种程度的相机运动，而不是像素级表示。</p>
<p>Sheikh等人使用仿射分解来开发移动相机背景减除法的框架：</p>
<ol>
<li>使用仿射因子分解对稀疏图像特征的轨迹进行分割。</li>
<li>通过估计轨迹基础来维持背景的稀疏表示。</li>
<li>然后使用KDE从稀疏特征模拟背景和前景的外观。</li>
<li>最终用马尔可夫随机场（MRF）用于分配标签。</li>
</ol>
<p>如果相机运动是没有平移的旋转（或接近零基线），则可以通过单应性来建模相机运动，并且可以使用图像镶嵌方法来构建背景模型。</p>
<h2 id="References-2"><a href="#References-2" class="headerlink" title="References"></a>References</h2><ul>
<li>“Density estimation for statistics and data analysis”, B.W. Silverman, 1998, London: Chapman &amp; Hall/CRC. </li>
</ul>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2018\10\29\《多媒体技术》\" rel="bookmark">《多媒体技术》</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2019\01\06\《计算智能》（二）概率\" rel="bookmark">《计算智能》（二）概率</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2018\09\22\《计算机视觉》\" rel="bookmark">《计算机视觉》</a></div>
    </li>
  </ul>

        <div class="reward-container">
  <div>一分一毛，也是心意。</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Run-Qing Chen 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="Run-Qing Chen 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Run-Qing Chen
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://blog.rexking6.top/2018/09/27/%E3%80%8A%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E5%89%8D%E6%B2%BF%E3%80%8B%E4%B8%80/" title="《视频分析前沿》一">https://blog.rexking6.top/2018/09/27/《视频分析前沿》一/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A1%95%E5%A3%AB%E8%AF%BE%E7%A8%8B/" rel="tag"># 硕士课程</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/09/26/K-D-TREE%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/" rel="prev" title="K-D TREE算法原理及实现">
      <i class="fa fa-chevron-left"></i> K-D TREE算法原理及实现
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/09/27/Hamming-Embedding%E6%B1%89%E6%98%8E%E5%B5%8C%E5%85%A5/" rel="next" title="Hamming Embedding汉明嵌入">
      Hamming Embedding汉明嵌入 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

    <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%EF%BC%9A%E5%AF%B9%E8%B1%A1%E8%A1%A8%E7%A4%BA"><span class="nav-number">2.</span> <span class="nav-text">一：对象表示</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%81%87%E8%AE%BE-amp-%E9%99%90%E5%88%B6"><span class="nav-number">2.1.</span> <span class="nav-text">假设&amp;限制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%BE%E9%A2%98-amp-%E6%8C%91%E6%88%98"><span class="nav-number">2.2.</span> <span class="nav-text">难题&amp;挑战</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E8%B1%A1%E5%BD%A2%E7%8A%B6%E8%A1%A8%E7%A4%BA"><span class="nav-number">2.3.</span> <span class="nav-text">对象形状表示</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%82%B9"><span class="nav-number">2.3.1.</span> <span class="nav-text">点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%A7%8B%E5%87%A0%E4%BD%95%E5%BD%A2%E7%8A%B6"><span class="nav-number">2.3.2.</span> <span class="nav-text">原始几何形状</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%A9%E4%BD%93%E8%BD%AE%E5%BB%93%E4%B8%8E%E5%89%AA%E5%BD%B1%E8%BD%AE%E5%BB%93"><span class="nav-number">2.3.3.</span> <span class="nav-text">物体轮廓与剪影轮廓</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E8%8A%82%E5%BD%A2%E7%8A%B6"><span class="nav-number">2.3.4.</span> <span class="nav-text">关节形状</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AA%A8%E6%9E%B6"><span class="nav-number">2.3.5.</span> <span class="nav-text">骨架</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E8%B1%A1%E5%A4%96%E8%A7%82%E8%A1%A8%E7%A4%BA"><span class="nav-number">2.4.</span> <span class="nav-text">对象外观表示</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%A9%E4%BD%93%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6"><span class="nav-number">2.4.1.</span> <span class="nav-text">物体出现的概率密度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E6%9D%BF"><span class="nav-number">2.4.2.</span> <span class="nav-text">模板</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E5%8A%A8%E5%A4%96%E8%A7%82%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.3.</span> <span class="nav-text">主动外观模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%A4%96%E8%A7%82%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.4.</span> <span class="nav-text">多视图外观模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">2.5.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%EF%BC%9A%E7%89%B9%E5%BE%81-amp-%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.</span> <span class="nav-text">二：特征&amp;目标跟踪</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="nav-number">3.1.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%9C%E8%89%B2%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.1.</span> <span class="nav-text">颜色特征</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RGB"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">RGB</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YIQ"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">YIQ</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YUV"><span class="nav-number">3.1.1.3.</span> <span class="nav-text">YUV</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Nrgb"><span class="nav-number">3.1.1.4.</span> <span class="nav-text">Nrgb</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HSI"><span class="nav-number">3.1.1.5.</span> <span class="nav-text">HSI</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CIE"><span class="nav-number">3.1.1.6.</span> <span class="nav-text">CIE</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%B9%E7%BC%98%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.2.</span> <span class="nav-text">边缘特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%89%E6%B5%81%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.3.</span> <span class="nav-text">光流特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.4.</span> <span class="nav-text">纹理特征</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E8%B1%A1%E8%B7%9F%E8%B8%AA%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">对象跟踪方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%82%B9%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.2.1.</span> <span class="nav-text">点跟踪</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%95%E7%9B%AE%E6%A0%87%E7%8A%B6%E6%80%81%E4%BC%B0%E8%AE%A1"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">单目标状态估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E7%9B%AE%E6%A0%87%E7%8A%B6%E6%80%81%E4%BC%B0%E8%AE%A1"><span class="nav-number">3.2.1.2.</span> <span class="nav-text">多目标状态估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="nav-number">3.2.1.3.</span> <span class="nav-text">评价指标</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.2.2.</span> <span class="nav-text">核跟踪</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">多目标跟踪模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%AA%E5%BD%B1%E8%BD%AE%E5%BB%93%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.2.3.</span> <span class="nav-text">剪影轮廓跟踪</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%81%AE%E6%8C%A1%E5%A4%84%E7%90%86"><span class="nav-number">3.3.</span> <span class="nav-text">遮挡处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E9%95%9C%E5%A4%B4%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.4.</span> <span class="nav-text">多镜头跟踪</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">4.</span> <span class="nav-text">三：目标检测</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E5%87%8F%E9%99%A4"><span class="nav-number">4.1.</span> <span class="nav-text">背景减除</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%89%B2"><span class="nav-number">4.2.</span> <span class="nav-text">分割</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%9D%87%E5%80%BC%E6%BC%82%E7%A7%BB%E8%81%9A%E7%B1%BB%E7%9A%84%E5%88%86%E5%89%B2"><span class="nav-number">4.3.</span> <span class="nav-text">基于均值漂移聚类的分割</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8EGraph-Cut%E5%88%86%E5%89%B2"><span class="nav-number">4.4.</span> <span class="nav-text">基于Graph-Cut分割</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E5%8A%A8%E8%BD%AE%E5%BB%93"><span class="nav-number">4.5.</span> <span class="nav-text">主动轮廓</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">4.6.</span> <span class="nav-text">有监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cotraining"><span class="nav-number">4.6.1.</span> <span class="nav-text">cotraining</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#boosting"><span class="nav-number">4.6.2.</span> <span class="nav-text">boosting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">4.6.3.</span> <span class="nav-text">支持向量机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%9C%BA%E5%88%B6"><span class="nav-number">4.7.</span> <span class="nav-text">滑动窗口机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E6%96%B9%E6%B3%95"><span class="nav-number">4.8.</span> <span class="nav-text">经典方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Haar%E7%89%B9%E5%BE%81-Adaboost%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">4.8.1.</span> <span class="nav-text">Haar特征+Adaboost分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hog%E7%89%B9%E5%BE%81-SVM%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">4.8.2.</span> <span class="nav-text">Hog特征+SVM分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E9%83%A8%E5%88%86%E5%88%86%E5%9D%97%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">4.8.3.</span> <span class="nav-text">基于部分分块的方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E8%A7%89%E5%8D%95%E8%AF%8D%E8%AF%8D%E8%A2%8B"><span class="nav-number">4.8.4.</span> <span class="nav-text">视觉单词词袋</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E8%BD%AE%E5%BB%93%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">4.8.5.</span> <span class="nav-text">基于轮廓的方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="nav-number">4.9.</span> <span class="nav-text">未来方向</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-1"><span class="nav-number">4.10.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1%E7%90%86%E8%AE%BA%E5%92%8C%E5%9F%BA%E4%BA%8E%E5%83%8F%E7%B4%A0%E7%9A%84%E8%83%8C%E6%99%AF%E5%88%86%E5%89%B2"><span class="nav-number">5.</span> <span class="nav-text">四、密度估计理论和基于像素的背景分割</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.1.</span> <span class="nav-text">密度估计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="nav-number">5.1.1.</span> <span class="nav-text">直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A8%E5%B9%BF"><span class="nav-number">5.1.1.1.</span> <span class="nav-text">推广</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">5.1.1.2.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.1.2.</span> <span class="nav-text">朴素估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9-1"><span class="nav-number">5.1.2.1.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.1.3.</span> <span class="nav-text">核估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9-2"><span class="nav-number">5.1.3.1.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%80%E8%BF%91%E9%82%BB%E6%96%B9%E6%B3%95"><span class="nav-number">5.1.4.</span> <span class="nav-text">最近邻方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-number">5.1.4.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9-3"><span class="nav-number">5.1.4.2.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%BF%E4%B9%89-k-%E8%BF%91%E9%82%BB%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.1.5.</span> <span class="nav-text">广义$k$近邻估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%AF%E5%8F%98%E6%A0%B8%E4%BC%B0%E8%AE%A1"><span class="nav-number">5.1.6.</span> <span class="nav-text">可变核估计</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.6.0.1.</span> <span class="nav-text">常用的核函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E6%A0%B8%E6%96%B9%E6%B3%95"><span class="nav-number">5.1.6.1.</span> <span class="nav-text">多维数据的核方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%83%8F%E7%B4%A0%E7%9A%84%E8%83%8C%E6%99%AF%E5%88%86%E5%89%B2"><span class="nav-number">5.2.</span> <span class="nav-text">基于像素的背景分割</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8C%91%E6%88%98"><span class="nav-number">5.2.1.</span> <span class="nav-text">背景模型的挑战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%89%E7%85%A7%E5%8F%98%E5%8C%96%E6%8C%91%E6%88%98"><span class="nav-number">5.2.1.1.</span> <span class="nav-text">光照变化挑战</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E5%8A%A8%E5%8F%98%E5%8C%96%E6%8C%91%E6%88%98"><span class="nav-number">5.2.1.2.</span> <span class="nav-text">运动变化挑战</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%93%E6%9E%84%E5%8F%98%E5%8C%96%E6%8C%91%E6%88%98"><span class="nav-number">5.2.1.3.</span> <span class="nav-text">结构变化挑战</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%8C%91%E6%88%98"><span class="nav-number">5.2.1.4.</span> <span class="nav-text">其他挑战</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%9F%E8%AE%A1%E5%9C%BA%E6%99%AF%E5%BB%BA%E6%A8%A1"><span class="nav-number">5.2.2.</span> <span class="nav-text">统计场景建模</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%83%8C%E6%99%AF%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.2.2.1.</span> <span class="nav-text">参数背景模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0"><span class="nav-number">5.2.2.1.1.</span> <span class="nav-text">更新</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%84%E7%90%86%E5%8A%A8%E6%80%81%E8%83%8C%E6%99%AF%EF%BC%9A%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8BGMM"><span class="nav-number">5.2.2.2.</span> <span class="nav-text">处理动态背景：混合高斯模型GMM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%9E%E5%8F%82%E6%95%B0%E5%8C%96%E8%83%8C%E6%99%AF%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.2.2.3.</span> <span class="nav-text">非参数化背景模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A7%BB%E5%8A%A8%E7%9A%84%E9%98%B4%E5%BD%B1%E6%8A%91%E5%88%B6"><span class="nav-number">5.2.2.4.</span> <span class="nav-text">移动的阴影抑制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A7%BB%E5%8A%A8%E6%91%84%E5%83%8F%E5%A4%B4%E7%9A%84%E8%83%8C%E6%99%AF%E5%87%8F%E9%99%A4%E6%B3%95"><span class="nav-number">5.2.2.5.</span> <span class="nav-text">移动摄像头的背景减除法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-2"><span class="nav-number">5.3.</span> <span class="nav-text">References</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Run-Qing Chen"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Run-Qing Chen</p>
  <div class="site-description" itemprop="description">覆苍天以为衾，卧大地以为庐。</div>
</div>


   <div class="feed-link motion-element">
     <a href="/atom.xml" rel="alternate">
       <i class="fa fa-rss"></i>
       RSS
     </a>
   </div>
 
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">181</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/RexKing6" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;RexKing6" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1010026261@qq.com" title="E-Mail → mailto:1010026261@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.zxpblog.cn/" title="https:&#x2F;&#x2F;www.zxpblog.cn&#x2F;" rel="noopener" target="_blank">赵小平</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://whitepuffer.github.io/" title="https:&#x2F;&#x2F;whitepuffer.github.io&#x2F;" rel="noopener" target="_blank">江斓</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://kexue.fm/" title="https:&#x2F;&#x2F;kexue.fm&#x2F;" rel="noopener" target="_blank">科学空间</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yongyuan.name/" title="https:&#x2F;&#x2F;yongyuan.name&#x2F;" rel="noopener" target="_blank">袁勇</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/abcjennifer" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;abcjennifer" rel="noopener" target="_blank">Rachel Zhang</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://dmkf.xyz/" title="http:&#x2F;&#x2F;dmkf.xyz&#x2F;" rel="noopener" target="_blank">代码咖啡</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://wuxiaolong.me/" title="http:&#x2F;&#x2F;wuxiaolong.me&#x2F;" rel="noopener" target="_blank">吴小龙同学</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.tennfy.com/" title="http:&#x2F;&#x2F;www.tennfy.com&#x2F;" rel="noopener" target="_blank">TENNFY WU</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fab fa-accessible-icon"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Run-Qing Chen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">2.8m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">43:01</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"6XDsO3aHIjDk3nV6eLJCufbl-MdYXbMMI","app_key":"YK4qOc0TpkazN6exhuqsnwmB","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
