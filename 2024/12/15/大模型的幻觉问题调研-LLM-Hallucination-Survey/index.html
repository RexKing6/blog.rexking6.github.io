<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.rexking6.top","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#37c6c0","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"YS7HT61SEB","apiKey":"0fd1eba022e7883c76ff4a71aee2acdc","indexName":"blog_NAME","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"找不到关于 ${query} 的文章","hits_stats":"共找到 ${hits} 篇文章，花了 ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="...">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型的幻觉问题调研: LLM Hallucination Survey">
<meta property="og:url" content="https://blog.rexking6.top/2024/12/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98%E8%B0%83%E7%A0%94-LLM-Hallucination-Survey/">
<meta property="og:site_name" content="RexKing6&#39;s Note">
<meta property="og:description" content="...">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://image.rexking6.top/img/v2-3eb192e4990f42b5522425ed5ddfe2cf_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-13f96fdc567007624d3a87f16426aeff_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-ff0c8292c8c5ce7f00c7cd2727d068eb_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-14c63a9889074680dbaeaedbefaba292_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-8ad95c909805fd32f51e509f95e8ebb3_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-f5fc0ce70b63a167fd8d97a4b8199b5c_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-bb1701600ee6498e2916f5ccad808546_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-43dc369115a46e487b6d621e6638c9ac_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-0f34e6f0cae7821ac1a7239014f7637f_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-efc1795288c922a06821fcbecd7e1fed_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-e34655e569508abce7489e042a831e2a_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-2fed05cab24e4c188a90b23f235f80f9_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-40cf1022364e571693210d4a654147c4_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-21f6ae2349bf16e4e72c22786f0c7cda_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-339a7d780994c55fdb4194a2f99d634e_1440w.jpg">
<meta property="og:image" content="https://image.rexking6.top/img/v2-246069c89a58bdda1c512257c49e483b_1440w.jpg">
<meta property="article:published_time" content="2024-12-14T16:33:03.000Z">
<meta property="article:modified_time" content="2024-12-15T05:02:18.459Z">
<meta property="article:author" content="Run-Qing Chen">
<meta property="article:tag" content="算法">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://image.rexking6.top/img/v2-3eb192e4990f42b5522425ed5ddfe2cf_1440w.jpg">

<link rel="canonical" href="https://blog.rexking6.top/2024/12/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98%E8%B0%83%E7%A0%94-LLM-Hallucination-Survey/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>大模型的幻觉问题调研: LLM Hallucination Survey | RexKing6's Note</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="RexKing6's Note" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RexKing6's Note</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/rexking6" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.rexking6.top/2024/12/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98%E8%B0%83%E7%A0%94-LLM-Hallucination-Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Run-Qing Chen">
      <meta itemprop="description" content="覆苍天以为衾，卧大地以为庐。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RexKing6's Note">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大模型的幻觉问题调研: LLM Hallucination Survey
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-12-15 00:33:03 / 修改时间：13:02:18" itemprop="dateCreated datePublished" datetime="2024-12-15T00:33:03+08:00">2024-12-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">大模型</span></a>
                </span>
            </span>

          
            <span id="/2024/12/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98%E8%B0%83%E7%A0%94-LLM-Hallucination-Survey/" class="post-meta-item leancloud_visitors" data-flag-title="大模型的幻觉问题调研: LLM Hallucination Survey" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>12 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>转载于：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/642648601">大模型的幻觉问题调研: LLM Hallucination Survey</a>。</p>
<h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><p>Update (23.9.7)：我们撰写了面向大模型幻觉问题的全面survey，欢迎感兴趣的朋友提意见！</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.01219">Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models</a></p>
<p>Update (23.7.13)：更新了一些LLM幻觉的检测和消除工作。</p>
<p>幻觉问题是LLM的实际落地应用中大家非常关注的一个问题。推荐一个前人写的比较全面的综述，但这篇Survey较少涉及2023年以后LLM时代的幻觉问题工作。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.03629">Survey of Hallucination in Natural Language Generation</a></p>
<p>笔者也整理了一些相关的最新工作（主要是大模型相关），在如下仓库：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/HillZhang1999/llm-hallucination-survey">llm-hallucination-survey</a></p>
<h1 id="幻觉的定义"><a href="#幻觉的定义" class="headerlink" title="幻觉的定义"></a>幻觉的定义</h1><p><strong>定义</strong>：当模型生成的文本不遵循原文（Faithfulness）或者不符合事实（Factualness），我们就可以认为模型出现了幻觉的问题。</p>
<blockquote>
<p><em>the generated content that is nonsensical or unfaithful to the provided source content</em></p>
</blockquote>
<p><strong>什么是Faithfulness and Factualness：</strong></p>
<ul>
<li><strong>Faithfulness</strong>：是否遵循input content；</li>
<li><strong>Factualness</strong>：是否符合世界知识；</li>
</ul>
<blockquote>
<p><em>Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and factuality in abstractive summarization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.</em></p>
</blockquote>
<p><strong>针对不同任务，幻觉的定义也可能出现差异：</strong></p>
<ul>
<li><strong>数据源（source）不一致</strong>：<ul>
<li>例如：摘要的数据源是document，data-to-text的数据源是data table，对话的数据源是对话历史，而开放域对话的数据源可以是世界知识。</li>
</ul>
</li>
<li><strong>容忍幻觉的程度不一致</strong>：<ul>
<li>在摘要、data-to-text任务中，非常看重response的Faithfulness，因此这些任务对幻觉的容忍程度很低；</li>
<li>而像开放域对话任务中，只需要response符合事实即可，容忍程度较高；</li>
</ul>
</li>
</ul>
<p><strong>在传统任务里，幻觉大都是指的是Faithfulness：</strong></p>
<ul>
<li><strong>Intrinsic Hallucination（信息冲突）</strong>: LMs在生成回复时，与输入信息产生了冲突，例如摘要问题里，abstract和document的信息不一致。</li>
<li><strong>Extrinsic Hallucination（无中生有）:</strong> LMs在生成回复时，输出一些并没有体现在输入中的额外信息，比如邮箱地址、电话号码、住址，并且难以验证其真假。（PS: 按照此定义，Extrinsic Hallucination有可能是真的信息，只是需要外部信息源进行认证）</li>
</ul>
<p><strong>而面向LLMs，我们通常考虑的幻觉则是Factualness：</strong></p>
<ul>
<li>因为我们应用LLM的形式是open-domain Chat，而不是局限于特定任务，所以数据源可以看做任意的世界知识。LLMs如果生成了不在input source里的额外信息，但是符合事实的，这种情况也可能是对我们有帮助的。</li>
</ul>
<h1 id="幻觉的原因"><a href="#幻觉的原因" class="headerlink" title="幻觉的原因"></a>幻觉的原因</h1><h2 id="数据层面"><a href="#数据层面" class="headerlink" title="数据层面"></a>数据层面</h2><p>在数据工程层面可能出现一些问题，导致幻觉问题：</p>
<ul>
<li>训练数据收集过程中，众包/爬虫检索的数据可能包含虚假信息，从而让模型记忆了错误的知识；</li>
<li>过多的重复信息也可能导致模型的知识记忆出现bias，从而导致幻觉：</li>
</ul>
<blockquote>
<p><em>Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2021. Deduplicating training data makes language models better. arXiv preprint arXiv:2107.06499 (2021).</em></p>
</blockquote>
<p><strong>潜在的研究方向：</strong></p>
<ul>
<li>Building High-quality Training Corpus is essential.</li>
<li>Data verification/ Data filter/ Data selection.</li>
</ul>
<h2 id="模型层面"><a href="#模型层面" class="headerlink" title="模型层面"></a>模型层面</h2><p>即使有了高质量训练数据，LLMs仍然可能表现出幻觉现象。</p>
<ul>
<li><strong>模型结构</strong>：如果是较弱的backbone（比如RNN）可能导致比较严重的幻觉问题，但在LLMs时代应该不太可能存在这一问题；</li>
<li><strong>解码算法</strong>：研究表明，如果使用不确定性较高的采样算法（e.g.，top-p）会诱导LMs出现更严重的幻觉问题。甚至可以故意在解码算法中加入一些随机性，进一步让LMs胡编乱造（可以用该方法生成一些negative samples）</li>
</ul>
<blockquote>
<p><em>Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, and Bryan Catanzaro. 2022. Factuality enhanced language models for open-ended text generation. arXiv preprint arXiv:2206.04624 (2022).</em></p>
</blockquote>
<ul>
<li><strong>暴露偏差</strong>：训练和测试阶段不匹配的exposure bias问题可能导致LLMs出现幻觉，特别是生成long-form response的时候。</li>
</ul>
<blockquote>
<p><em>Chaojun Wang and Rico Sennrich. 2020. On exposure bias, hallucination and domain shift in neural machine translation. In Proceedings of the 2020 Annual Conference of the Association for Computational Linguistics. 3544–3552.</em></p>
</blockquote>
<ul>
<li><strong>参数知识：</strong>LMs在预训练阶段记忆的错误的知识，将会严重导致幻觉问题。</li>
</ul>
<blockquote>
<p><em>Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh. 2021. Entity-based knowledge conflicts in question answering. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP’21). 7052–7063.</em></p>
</blockquote>
<h1 id="幻觉的评估"><a href="#幻觉的评估" class="headerlink" title="幻觉的评估"></a>幻觉的评估</h1><p>现有的传统幻觉评估指标和人类结果的相关性往往较低，同时大都是task-specific的。</p>
<blockquote>
<p><em>Artidoro Pagnoni, Vidhisha Balachandran, and Yulia Tsvetkov. 2021. Understanding factuality in abstractive summarization with FRANK: A benchmark for factuality metrics. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT’21). 4812–4829</em></p>
</blockquote>
<h2 id="Reference-based"><a href="#Reference-based" class="headerlink" title="Reference-based"></a>Reference-based</h2><p>Reference-based的指标有两类：</p>
<ul>
<li><strong>基于Source Information和Target Reference</strong>：利用一些统计学指标，比如ROUGE、BLEU来评估输出结果和Source/Target信息的重叠度。</li>
<li><strong>基于Source Information</strong>：由于NLG任务里，Target输出往往是多种多样的，因此许多工作只基于Source信息进行幻觉的评估。比如Knowledge F1。</li>
</ul>
<p><em>基于Reference的评价指标，基本上只能评价Faithfulness，而无法评价Factualness，因此通常不适用于LLMs。</em></p>
<h2 id="Reference-Free"><a href="#Reference-Free" class="headerlink" title="Reference-Free"></a><strong>Reference-Free</strong></h2><ul>
<li><strong>基于IE</strong>：将知识限定于可以用三元组形式表示的关系和事件，基于额外的IE模型进行抽取，接着使用额外模型进行验证。<ul>
<li><strong>缺点：</strong><ul>
<li>可能存在IE模型的错误传播问题。</li>
<li>知识被限定在三元组形式。</li>
</ul>
</li>
</ul>
</li>
<li><strong>基于QA</strong>：第一步先基于LM生成的回复，使用一个QG(question generation)模型生成一系列QA pairs；第二步给定Source Information，让QA模型对上一步生成的Question进行回复；第三步则是通过对比第一步的answers和第二步的answers，计算匹配指标，衡量模型的幻觉问题；<ul>
<li><strong>缺点</strong>：<ul>
<li>同样存在QA/QG模型的错误传播问题。</li>
<li>难以评估Factualness，因为上述第二步里面，Source Information不可能包含全部的世界知识，因此对于一些问题难以生成可靠的回复。</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p><em>Esin Durmus, He He, and Mona Diab. 2020. FEQA: A question answering evaluation framework for faithfulness assessment in abstractive summarization. In Proceedings of the 58th Annual Meeting of the ACL. 5055–5070.</em></p>
</blockquote>
<ul>
<li><p><strong>基于NLI</strong>：基于NLI的方法通过NLI模型评估是否Source Information可以蕴含Generated Text，从而评估是否出现了幻觉现象。</p>
<ul>
<li><p><strong>缺点</strong>：</p>
<ul>
<li>Off-the-shelf NLI模型用于核查事实效果不是很好；</li>
</ul>
<blockquote>
<p><em>Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter. 2021. Evaluating groundedness in dialogue systems: The BEGIN benchmark. In Findings of the Association for Computational Linguistics. Association for Computational Linguistics, 1–12.</em></p>
</blockquote>
<ul>
<li><p>无法评估需要世界知识的幻觉问题：仅能依赖于Source进行核查；</p>
</li>
<li><p>都是sentence-level的，无法支撑更细粒度的幻觉检查；</p>
</li>
</ul>
<blockquote>
<p><em>Tanya Goyal and Greg Durrett. 2020. Evaluating factuality in generation with dependency-level entailment. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. 3592–3603.</em></p>
</blockquote>
<ul>
<li>幻觉问题和蕴含问题实际并不等价：<ul>
<li>例子：Putin is president. -&gt; Putin is U.S. president (可以蕴含，但是是幻觉)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>基于Factualness Classification Metric</strong>：标注/构造一批和幻觉/事实有关的数据，训练检测模型，利用该模型评估新生成文本的幻觉/事实问题。</p>
</li>
</ul>
<blockquote>
<p><em>Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2018. Wizard of Wikipedia: Knowledge-powered conversational agents. In Proceedings of the International Conference on Learning Representations.</em></p>
</blockquote>
<ul>
<li><strong>人工评估：</strong>目前为止最靠谱的，此外还可以依靠LLM打分（比如利用GPT4，但是GPT4也存在着严重的幻觉问题，即使经过retrival-augment，检索回来的信息也有可能是错误的）</li>
</ul>
<h1 id="幻觉的缓解"><a href="#幻觉的缓解" class="headerlink" title="幻觉的缓解"></a>幻觉的缓解</h1><h2 id="基于数据的工作"><a href="#基于数据的工作" class="headerlink" title="基于数据的工作"></a>基于数据的工作</h2><p><strong>构建高质量数据集</strong></p>
<ol>
<li><strong>人工标注</strong><ol>
<li><strong>训练数据</strong>：LLM上不可行，只适用于task-specific的幻觉问题</li>
<li><strong>评测数据</strong>：构建细粒度的幻觉评估benchmark用于分析幻觉的严重程度和原因</li>
</ol>
</li>
</ol>
<blockquote>
<p><em>Saadia Gabriel, Asli Celikyilmaz, Rahul Jha, Yejin Choi, and Jianfeng Gao. 2021. GO FIGURE: A meta evaluation of factuality in summarization. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Association for Computational Linguistics, 478–487.</em><br><em>Or Honovich, Leshem Choshen, Roee Aharoni, Ella Neeman, Idan Szpektor, and Omri Abend. 2021. Q2: Evaluating factual consistency in knowledge-grounded dialogues via question generation and question answering. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 7856–7870</em></p>
</blockquote>
<ol>
<li><p><strong>自动筛选</strong>：</p>
<ol>
<li><p>利用<strong>模型筛选</strong>出可能导致幻觉的数据并剔除；</p>
</li>
<li><p>预训练时给更faithful的<strong>数据加权</strong>（wiki vs. fake news），或者不使用可靠来源的数据（比如只选用经过人工审查的数据源，如wiki或者教科书，预训练）</p>
</li>
</ol>
</li>
</ol>
<h2 id="模型层面的工作"><a href="#模型层面的工作" class="headerlink" title="模型层面的工作"></a>模型层面的工作</h2><p><strong>模型结构</strong></p>
<ul>
<li>模型结构层面的工作往往focus在设计更能充分编码利用source information的方法，比如融入一些人类偏置，如GNN网络。</li>
<li>或者在解码时减少模型的<strong>生成随机性</strong>，因为diversity和Faithfulness往往是一个trade-off的关系，减少diversity/randomness可以变相提升Faithfulness/Factuality。</li>
</ul>
<blockquote>
<p><em>Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, and Bryan Catanzaro. 2022. Factuality enhanced language models for open-ended text generation. arXiv preprint arXiv:2206.04624 (2022).</em></p>
</blockquote>
<ul>
<li><strong>检索增强</strong>被证明可以显著减少幻觉问题，e.g., llama-index。</li>
</ul>
<blockquote>
<p><em>Peng, Baolin, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang et al. “Check your facts and try again: Improving large language models with external knowledge and automated feedback.”arXiv preprint arXiv:2302.12813(2023).</em></p>
</blockquote>
<p><strong>训练方式</strong></p>
<ul>
<li><strong>可控文本生成</strong>：将幻觉的程度作为一个可控的属性，利用可控文本生成技术进行控制。</li>
</ul>
<blockquote>
<p><em>Hannah Rashkin, David Reitter, Gaurav Singh Tomar, and Dipanjan Das. 2021. Increasing faithfulness in knowledgegrounded dialogue with controllable features. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. 704–718.</em><br><em>Zeqiu Wu, Michel Galley, Chris Brockett, Yizhe Zhang, Xiang Gao, Chris Quirk, Rik Koncel-Kedziorski, et al. 2021. A controllable model of grounded response generation. In Proceedings of the AAAI Conference on Artificial Intelligence. 14085–14093.</em></p>
</blockquote>
<ul>
<li><strong>提前规划骨架，再生成</strong>：sketch to content</li>
</ul>
<blockquote>
<p><em>Ratish Puduppully, Li Dong, and Mirella Lapata. 2019. Data-to-text generation with content selection and planning. In Proceedings of the AAAI Conference on Artificial Intelligence</em></p>
</blockquote>
<ul>
<li><strong>强化学习：</strong>假设是基于word的MLE训练目标，只优化唯一的reference，可能导致暴露偏差问题。现有工作将减轻幻觉的指标作为强化学习的reward函数，从而减轻幻觉现象。</li>
</ul>
<blockquote>
<p><em>Yangming Li, Kaisheng Yao, Libo Qin, Wanxiang Che, Xiaolong Li, and Ting Liu. 2020. Slot-consistent NLG for task-oriented dialogue systems with iterative rectification network. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 97–106.</em><br><em>Mohsen Mesgar, Edwin Simpson, and Iryna Gurevych. 2021. Improving factual consistency between a response and persona facts. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics. 549–562.</em></p>
</blockquote>
<ul>
<li><strong>多任务学习</strong>: 通过设计合适的额外任务，可以达到减轻幻觉的效果。</li>
<li><strong>后处理</strong>：设计一个小模型专门用于fix幻觉错误。</li>
</ul>
<blockquote>
<p><em>Sihao Chen, Fan Zhang, Kazoo Sone, and Dan Roth. 2021. Improving faithfulness in abstractive summarization with contrast candidate generation and selection. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT’21). 5935–5941.</em></p>
</blockquote>
<h1 id="可能的后续方向"><a href="#可能的后续方向" class="headerlink" title="可能的后续方向"></a>可能的后续方向</h1><ol>
<li><strong>更细粒度的幻觉评估：</strong><ol>
<li>token/phrase level instead of sentence level</li>
<li>更精细的幻觉分类体系：<ol>
<li>Intrinsic</li>
<li>Extrinsic</li>
<li>其他类别：<ol>
<li>按幻觉产生的原因分类（调用知识出错，还是缺少相应知识）</li>
<li>主观/客观幻觉</li>
<li>幻觉可能和时间（temporal）有关</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><strong>知识的定义和诱导</strong>：<ol>
<li>怎么知道模型是否具备某一类知识，只是没有调用好？</li>
<li>知识的定义：<ol>
<li>传统工作大都将wikipedia视作知识库，但它仅仅是世界知识的很小一部分</li>
<li>如果将整个互联网当做世界知识，又不可避免的会有虚假信息的问题</li>
</ol>
</li>
</ol>
</li>
<li><strong>幻觉消除：</strong><ol>
<li>检索增强：互联网/外挂知识库(llama Index)</li>
<li>强化学习（RLHF）</li>
<li>知识诱导/注入</li>
<li>直接修改LLM中错误记忆的知识：Model Editing工作，如ROME，MEMIT等</li>
</ol>
</li>
</ol>
<h1 id="LLM时代的幻觉研究"><a href="#LLM时代的幻觉研究" class="headerlink" title="LLM时代的幻觉研究"></a>LLM时代的幻觉研究</h1><p>下面针对ChatGPT时代的针对LLM的幻觉工作做简单的总结。</p>
<h2 id="幻觉评估"><a href="#幻觉评估" class="headerlink" title="幻觉评估"></a>幻觉评估</h2><h3 id="TruthfulQA"><a href="#TruthfulQA" class="headerlink" title="TruthfulQA"></a><strong>TruthfulQA</strong></h3><p>一个很重要的用于评估LLM是否能够生成符合事实的答案的QA基准，被后续的LLM工作，如GPT4采用评估。</p>
<p>包含了817个作者手写的问题，这些问题是精心设计，往往是模型或者人类都很容易回答错误的陈述。</p>
<p>作者发现：</p>
<ul>
<li>与人类相比(94%)，当前较好的LLMs(GPT3)也只能诚实地回答58%的问题而不进行编造。</li>
<li>更大的模型更容易编造回答。</li>
<li>微调后的GPT3可以有效分辨是否回答是truthful的。</li>
</ul>
<h3 id="HaluEval-benchmark"><a href="#HaluEval-benchmark" class="headerlink" title="HaluEval benchmark"></a><strong>HaluEval benchmark</strong></h3><ol>
<li><strong>Benchmark搭建</strong>：人工标注了35,000条数据，5000条chatgpt的general query（alpaca data），30000条chatgpt的任务回复（问答、摘要、知识对话）<ol>
<li>让chatgpt生成更有可能出现幻觉的文本：数据过滤，prompt工程；</li>
<li>每个任务的幻觉还有不同类型：<ol>
<li>QA： comprehension, factualness, specificity, and inference；</li>
<li>knowledge-grounded dialogue：extrinsic-soft, extrinsic-hard, and extrinsic-grouped</li>
<li>text summarization： factual, non-factual, and intrinsic</li>
</ol>
</li>
</ol>
</li>
<li><strong>幻觉评估</strong>：<ol>
<li>Chatgpt倾向于在回复中生成无法被验证的内容（幻觉），占比约11.4%</li>
<li>当前强大的LLM，如Chatgpt，都很难精准检测出文本中出现的幻觉问题</li>
<li>通过提供外部知识和增加推理步数，能够提升LLM检测幻觉的能力</li>
</ol>
</li>
</ol>
<h3 id="ChatGPT-GPT4生成不真实回复的评估、机理"><a href="#ChatGPT-GPT4生成不真实回复的评估、机理" class="headerlink" title="ChatGPT/GPT4生成不真实回复的评估、机理"></a><strong>ChatGPT/GPT4生成不真实回复的评估、机理</strong></h3><p>对LLM生成的不符合事实的错误的类型进行分类和统计：</p>
<p><img src="https://image.rexking6.top/img/v2-3eb192e4990f42b5522425ed5ddfe2cf_1440w.jpg" alt=""></p>
<p><img src="https://image.rexking6.top/img/v2-13f96fdc567007624d3a87f16426aeff_1440w.jpg" alt=""></p>
<p>定义了三个能力，可能导致幻觉的：</p>
<p><img src="https://image.rexking6.top/img/v2-ff0c8292c8c5ce7f00c7cd2727d068eb_1440w.jpg" alt=""></p>
<ol>
<li>知识记忆</li>
<li>知识调用</li>
<li>知识推理</li>
</ol>
<p>通过实验，对大模型生成可靠回复给出了一些建议：</p>
<ol>
<li>提供更多的背景知识（检索）</li>
<li>提供更细粒度的背景知识（分析）</li>
<li>把问题进行分解（CoT)</li>
</ol>
<p>早期的工作，包括了对ChatGPT幻觉现象的评估：</p>
<ul>
<li>ChatGPT有能力识别虚假信息，并能够在无法识别时回复不知道；</li>
<li>ChatGPT仍然会被TruthfulQA内的问题误导；</li>
<li>ChatGPT同样可能出现intrinstic/extrinsic hallucination的case；</li>
</ul>
<h3 id="Retrieval-augment-LLM评估"><a href="#Retrieval-augment-LLM评估" class="headerlink" title="Retrieval-augment LLM评估"></a><strong>Retrieval-augment LLM评估</strong></h3><p>Retrieval有助于显著减少LLM的幻觉现象。</p>
<p>自OSU的两个工作，主要是研究了给定retrieval reference的情况下，LLM的遵循能力。</p>
<ul>
<li>前一个工作首先定义了自动评估一个reference能否支撑generation的任务，然后研究了LLMs（prompt/finetuned）的完成这一任务的能力<ul>
<li>automatic attribution evaluation的效果都不好</li>
<li>小的finetuned模型可以超过大的zero-shot模型</li>
<li>模型容量和评估效果并不完全正相关</li>
<li>使用额外的其他任务训练，可以提升automatic attribution evaluation的能力（QA/NLI/FC）</li>
</ul>
</li>
</ul>
<p><img src="https://image.rexking6.top/img/v2-14c63a9889074680dbaeaedbefaba292_1440w.jpg" alt=""></p>
<ul>
<li>后一个工作</li>
</ul>
<p>研究了给定reference情况下对LLM生成结果的影响：</p>
<ul>
<li>使用一个5步走的框架进行knowledge elicitation<ul>
<li>parametric memory：模型内部的知识</li>
<li>counter-memeory：与模型内部知识相反的内容</li>
</ul>
</li>
</ul>
<p><img src="https://image.rexking6.top/img/v2-8ad95c909805fd32f51e509f95e8ebb3_1440w.jpg" alt=""></p>
<ul>
<li>当只有一个单一的知识源时：<ul>
<li>简单的通过entity替换的counter-memory无法诱骗模型，但是让LLM自己生成的可以</li>
</ul>
</li>
<li>当有多个知识来源时：<ul>
<li>LLM倾向于相信更流行的知识；</li>
<li>LLM对于知识的顺序很敏感，倾向于相信先出现的知识；</li>
<li>LLM相信更长的知识；</li>
<li>LLM随大流，相信占据大多数的知识</li>
</ul>
</li>
</ul>
<h3 id="LLM幻觉的滚雪球现象"><a href="#LLM幻觉的滚雪球现象" class="headerlink" title="LLM幻觉的滚雪球现象"></a><strong>LLM幻觉的滚雪球现象</strong></h3><p>本文作者认为：LLM出现幻觉现象，很多情况下并不是因为它们缺少对应的知识，而仅仅是在调用知识的过程中出错。他们发现：LLMs如果在回复一开始做出了错误的判断，那么它们随后会给出错误的解释（幻觉）。他们称这一现象为幻觉的滚雪球现象。但是，当仅给定错误的解释时，LLMs往往可以成功判断它是不正确的。这证明LLMs其实具备相应的知识，只是被早期的错误断言给误导了。</p>
<p><img src="https://image.rexking6.top/img/v2-f5fc0ce70b63a167fd8d97a4b8199b5c_1440w.jpg" alt=""></p>
<p>作者也探索了一些缓解幻觉滚雪球问题的方法：</p>
<ul>
<li>更好的Prompt（CoT）：有效，但是CoT也存在着思维链内部的幻觉滚雪球问题。</li>
<li>解码算法：作者尝试了不同的解码算法，但并没有显著效果。</li>
<li>训练策略：构造更多的CoT训练数据，以及构造允许模型自我回溯（self-correct）的训练数据。</li>
</ul>
<h3 id="LLM幻觉的原子粒度评估"><a href="#LLM幻觉的原子粒度评估" class="headerlink" title="LLM幻觉的原子粒度评估"></a><strong>LLM幻觉的原子粒度评估</strong></h3><p>定义原子事实：仅包含一个信息的短句。</p>
<p>将LLM生成的内容（本文选用的内容是人物简介）分解为多个原子事实（instructGPT分解，人类校对），评估生成事实的精确度：</p>
<p><img src="https://image.rexking6.top/img/v2-bb1701600ee6498e2916f5ccad808546_1440w.jpg" alt=""></p>
<p>人工标注常用LLMs的原子事实精确度后，发现：</p>
<ul>
<li>所有LLM都会出现较为严重幻觉问题，特别是原子粒度上；</li>
<li>检索增强的LLM（perplexity AI）能够缓解事实错误；</li>
<li>在生成和罕见实体相关的回复时，LLM更容易犯错；</li>
<li>模型在生成回复的后期，更容易出现幻觉；</li>
</ul>
<p>作者也研究了基于LLM自动评估原子事实精确度的可能性（不可能每次对新模型评估都靠人工标注）：</p>
<ul>
<li>检索增强能显著提升评估的效果；</li>
<li>更大的LLM能够更好地评估。</li>
</ul>
<p>最后，作者基于自动指标，评估了现阶段LLM的原子事实性：</p>
<p><img src="https://image.rexking6.top/img/v2-43dc369115a46e487b6d621e6638c9ac_1440w.jpg" alt=""></p>
<p>有一些有趣的发现：比如Dolly模型经常频繁提及Databricks公司，导致事实错误（因为dolly的训练语料是databricks公司员工手写的）</p>
<p>最后作者研究了自动利用LLMs修复事实错误的可能性，发现在原子粒度纠正以及提供检索信息，能显著提高纠正的效果。</p>
<p><img src="https://image.rexking6.top/img/v2-0f34e6f0cae7821ac1a7239014f7637f_1440w.jpg" alt=""></p>
<p>除了模型生成事实的精确度外，还应该考虑召回度（即内容中的原子事实信息尽可能多），否则LLMs可能走捷径，生成一些无意义的废话。</p>
<h2 id="幻觉检测-amp-修正"><a href="#幻觉检测-amp-修正" class="headerlink" title="幻觉检测&amp;修正"></a>幻觉检测&amp;修正</h2><h3 id="事实性增强的语言模型"><a href="#事实性增强的语言模型" class="headerlink" title="事实性增强的语言模型"></a><strong>事实性增强的语言模型</strong></h3><p>面向LLM的事实/幻觉问题的早期工作(2022.6)。</p>
<p>本文首先基于FEVER数据集构建一个FactualPrompt数据集，包含了符合/不符合事实的提示，用于诱导LLM生成符合/不符合事实的下文。</p>
<p>评价指标：</p>
<ul>
<li>幻觉实体率：对比生成内容和Golden Knowledge中实体的重叠率；</li>
<li>蕴含率：使用额外的NLI模型，评估生成内容有多少是被golden Knowledge蕴含的；</li>
<li>生成质量评估：除了幻觉现象外，还要确保生成的效果<ul>
<li>流畅度：平均困惑度；</li>
<li>多样性：distinct n-grams；</li>
<li>重复度</li>
</ul>
</li>
</ul>
<p>从多个维度评估LLM生成的事实问题：</p>
<ul>
<li>模型容量：更大的模型生成结果的事实性越好</li>
<li>提示类型：不符合事实的提示更可能诱导LLM生成不符合事实的内容；</li>
<li>解码算法：带有随机性的解码算法（如Top-P）显著比贪心解码生成的内容更不符合事实；<ul>
<li>基于这个发现作者还提出了一个非常简单的top-p解码算法优化，在生成的diversity和factuality中寻求trade-off：<ul>
<li>p随时间步衰减（后期生成的内容更可能不符合事实），每次生成一个新句子（通过检测是否生成了句号）重新初始化p，并且p的衰减可以定一个下界；</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>作者还提出了一种继续预训练策略来提升事实性：</p>
<ul>
<li>使用更权威的数据，如Wiki来训练；</li>
<li>给每个句子加上Wiki Document的名称：作者认为这能给句子提供额外的事实信息，比如解释句子里的代词（有点玄学）</li>
</ul>
<h3 id="基于外部知识和自动反馈提升事实性"><a href="#基于外部知识和自动反馈提升事实性" class="headerlink" title="基于外部知识和自动反馈提升事实性"></a><strong>基于外部知识和自动反馈提升事实性</strong></h3><p>通过外挂知识库和LLM自我审视，来提升LLM生成的事实性/效果：</p>
<ul>
<li>主要包含以下部分：<ul>
<li>LLM Agent</li>
<li>外部知识库：互联网、wiki百科等；</li>
<li>动作执行器：<ul>
<li>知识检索：BM-25/Dense，通过给定prompt检索知识；</li>
<li>Prompt引擎：基于用户输入/知识/历史信息/反馈信息等，构造prompt，融合信息生成新的回复；</li>
</ul>
</li>
<li>策略选择器：<ul>
<li>基于规则（是否通过utility模块）</li>
<li>可学习（T5-based）</li>
</ul>
</li>
<li>效用检验模块：<ul>
<li>打分器：用分数评估回复质量；</li>
<li>反馈器：用自然语言给出回复评估；</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>本质上，该系统是一个检索知识-&gt;生成回复-&gt;评估的反复迭代/决策的过程，能够通过外部知识库和检查模块，显著提升生成的各维度效果，包括事实性。</p>
<p><img src="https://image.rexking6.top/img/v2-efc1795288c922a06821fcbecd7e1fed_1440w.jpg" alt=""></p>
<h3 id="零资源黑盒LLM幻觉检测"><a href="#零资源黑盒LLM幻觉检测" class="headerlink" title="零资源黑盒LLM幻觉检测"></a><strong>零资源黑盒LLM幻觉检测</strong></h3><p>作者认为传统的幻觉检测方法在当今LLM时代有如下的缺陷：</p>
<ul>
<li>基于不确定度指标：这一类方法通过衡量LLM回复的熵/概率，来判断LLM对回复是否自信，越不自信越可能是编造的内容。但是该方法对闭源模型（如OpenAI）不友好。</li>
<li>基于事实验证指标：这一类方法需要外挂知识库，但是现在缺少涵盖所有世界知识的高质量知识库。</li>
</ul>
<p>作者提出了SelfCheckGPT方法，核心的假设是：如果大模型非常肯定一个事实，那么它随机采样多次生成的回复，将对该事实有着近似的陈述（self-consistency）。如果多次采样，LLM都生成不同的陈述，那么很有可能是出现了幻觉。具体地，评估多个采样陈述是否一致，可以通过：1）BERTScore；2）QA-based；3）n-gram metric进行实现。</p>
<p>ETH-Zurich也有一篇类似的工作，着重关注LLM生成回复中的自相矛盾现象，包括评估、检测和消除。</p>
<h3 id="零资源黑盒事实错误纠正"><a href="#零资源黑盒事实错误纠正" class="headerlink" title="零资源黑盒事实错误纠正"></a><strong>零资源黑盒事实错误纠正</strong></h3><p><img src="https://image.rexking6.top/img/v2-e34655e569508abce7489e042a831e2a_1440w.jpg" alt=""></p>
<p>提出了一个五步的零资源事实错误纠正流水线：</p>
<ul>
<li>Claim Answer抽取：从陈述中抽取关键信息；</li>
<li>Question Generation：针对每个关键信息，生成一个问题；</li>
<li>Question Answer：针对每个问题，将外部证据作为额外输入，进行回答；</li>
<li>QA-to-claim：将QA-pair转回陈述；</li>
<li>Correction scoring：额外打分器判断新的陈述是否合理。</li>
</ul>
<h3 id="工具增强的LLM自动纠正"><a href="#工具增强的LLM自动纠正" class="headerlink" title="工具增强的LLM自动纠正"></a><strong>工具增强的LLM自动纠正</strong></h3><p>MSRA的工作，本文允许LLM在自我检查答案正确性的过程中调用外部工具，比如知识库、搜索引擎和维基百科，从而缓解事实性和幻觉问题。</p>
<p><img src="https://image.rexking6.top/img/v2-2fed05cab24e4c188a90b23f235f80f9_1440w.jpg" alt=""></p>
<h3 id="通过推理时干预诱导LLM生成符合事实的答案"><a href="#通过推理时干预诱导LLM生成符合事实的答案" class="headerlink" title="通过推理时干预诱导LLM生成符合事实的答案"></a><strong>通过推理时干预诱导LLM生成符合事实的答案</strong></h3><p>哈佛的工作，本文中作者提出了一种推理时干预的策略（ITI）提升LLM生成答案的事实性。</p>
<p>作者假设：LLMs know more than they say，LLM内部存在着隐藏的、可解释的结构，这些结构和事实性息息相关，因此可以通过干预：</p>
<ul>
<li>作者探索了LLM的生成回复准确率（直接回答问题）和Probe准确率（用一个linear classifier基于中间状态选择回答）的关系，发现LLM很多情况下知道知识，但无法正确生成回复。</li>
</ul>
<p><img src="https://image.rexking6.top/img/v2-40cf1022364e571693210d4a654147c4_1440w.jpg" alt=""></p>
<ul>
<li>ITI方法选择和事实知识紧密相关的head，进行干预，让激活值移动到truthful相关的方向，实验表明能够有效提升回复的事实性。</li>
</ul>
<h3 id="训练小模型后处理幻觉问题"><a href="#训练小模型后处理幻觉问题" class="headerlink" title="训练小模型后处理幻觉问题"></a><strong>训练小模型后处理幻觉问题</strong></h3><p><img src="https://image.rexking6.top/img/v2-21f6ae2349bf16e4e72c22786f0c7cda_1440w.jpg" alt=""></p>
<p>Google的工作，核心思想是用LLM自动对一个正确样本生成幻觉样本，组成平行语料，训练一个T5学会降噪：</p>
<ul>
<li>根据文档、干净的陈述，利用LLM对陈述进行加噪，使其含有幻觉问题；</li>
<li>将文档和含有幻觉的文本作为输入，干净的文本作为输出，训练一个小模型用于降噪（去幻觉）</li>
<li>推理时，对给定的陈述，先使用QG模型生成一系列问题，再根据问题召回证据，将证据文档和陈述传入小模型进行幻觉的编辑和修正。</li>
</ul>
<h3 id="利用多智能体辩论显著提升LM的事实性和推理能力"><a href="#利用多智能体辩论显著提升LM的事实性和推理能力" class="headerlink" title="利用多智能体辩论显著提升LM的事实性和推理能力"></a><strong>利用多智能体辩论显著提升LM的事实性和推理能力</strong></h3><p>MIT&amp;Google，利用多个智能体（LLM）相互辩论来解决事实性问题，相当于是一种变相的self-verify。</p>
<p><img src="https://image.rexking6.top/img/v2-339a7d780994c55fdb4194a2f99d634e_1440w.jpg" alt=""></p>
<h3 id="人在回路的幻觉消除"><a href="#人在回路的幻觉消除" class="headerlink" title="人在回路的幻觉消除"></a><strong>人在回路的幻觉消除</strong></h3><p>本文提出基于人机交互，让LLM获得更好的知识-问题对齐，从而提升回复的事实性，减轻幻觉。</p>
<p><img src="https://image.rexking6.top/img/v2-246069c89a58bdda1c512257c49e483b_1440w.jpg" alt=""></p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2024\11\25\19类Agent框架对比\" rel="bookmark">19类Agent框架对比</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2024\12\14\Chain-of-Table论文解读\" rel="bookmark">Chain-of-Table论文解读</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2023\02\22\ChatGPT背后的经济账\" rel="bookmark">ChatGPT 背后的经济账</a></div>
    </li>
  </ul>

        <div class="reward-container">
  <div>一分一毛，也是心意。</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Run-Qing Chen 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="Run-Qing Chen 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Run-Qing Chen
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://blog.rexking6.top/2024/12/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98%E8%B0%83%E7%A0%94-LLM-Hallucination-Survey/" title="大模型的幻觉问题调研: LLM Hallucination Survey">https://blog.rexking6.top/2024/12/15/大模型的幻觉问题调研-LLM-Hallucination-Survey/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%AE%97%E6%B3%95/" rel="tag"># 算法</a>
              <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag"># 大模型</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/12/14/ReAcTable%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" rel="prev" title="ReAcTable论文解读">
      <i class="fa fa-chevron-left"></i> ReAcTable论文解读
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/12/15/%E4%B8%80%E6%96%87%E7%9C%8BSora%E6%8A%80%E6%9C%AF%E6%8E%A8%E6%BC%94/" rel="next" title="一文看Sora技术推演">
      一文看Sora技术推演 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

    <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0"><span class="nav-number">2.</span> <span class="nav-text">更新</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%BB%E8%A7%89%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">3.</span> <span class="nav-text">幻觉的定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%BB%E8%A7%89%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">4.</span> <span class="nav-text">幻觉的原因</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%B1%82%E9%9D%A2"><span class="nav-number">4.1.</span> <span class="nav-text">数据层面</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%B1%82%E9%9D%A2"><span class="nav-number">4.2.</span> <span class="nav-text">模型层面</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%BB%E8%A7%89%E7%9A%84%E8%AF%84%E4%BC%B0"><span class="nav-number">5.</span> <span class="nav-text">幻觉的评估</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference-based"><span class="nav-number">5.1.</span> <span class="nav-text">Reference-based</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference-Free"><span class="nav-number">5.2.</span> <span class="nav-text">Reference-Free</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%BB%E8%A7%89%E7%9A%84%E7%BC%93%E8%A7%A3"><span class="nav-number">6.</span> <span class="nav-text">幻觉的缓解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="nav-number">6.1.</span> <span class="nav-text">基于数据的工作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%B1%82%E9%9D%A2%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="nav-number">6.2.</span> <span class="nav-text">模型层面的工作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%AF%E8%83%BD%E7%9A%84%E5%90%8E%E7%BB%AD%E6%96%B9%E5%90%91"><span class="nav-number">7.</span> <span class="nav-text">可能的后续方向</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LLM%E6%97%B6%E4%BB%A3%E7%9A%84%E5%B9%BB%E8%A7%89%E7%A0%94%E7%A9%B6"><span class="nav-number">8.</span> <span class="nav-text">LLM时代的幻觉研究</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B9%BB%E8%A7%89%E8%AF%84%E4%BC%B0"><span class="nav-number">8.1.</span> <span class="nav-text">幻觉评估</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TruthfulQA"><span class="nav-number">8.1.1.</span> <span class="nav-text">TruthfulQA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HaluEval-benchmark"><span class="nav-number">8.1.2.</span> <span class="nav-text">HaluEval benchmark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ChatGPT-GPT4%E7%94%9F%E6%88%90%E4%B8%8D%E7%9C%9F%E5%AE%9E%E5%9B%9E%E5%A4%8D%E7%9A%84%E8%AF%84%E4%BC%B0%E3%80%81%E6%9C%BA%E7%90%86"><span class="nav-number">8.1.3.</span> <span class="nav-text">ChatGPT&#x2F;GPT4生成不真实回复的评估、机理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Retrieval-augment-LLM%E8%AF%84%E4%BC%B0"><span class="nav-number">8.1.4.</span> <span class="nav-text">Retrieval-augment LLM评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM%E5%B9%BB%E8%A7%89%E7%9A%84%E6%BB%9A%E9%9B%AA%E7%90%83%E7%8E%B0%E8%B1%A1"><span class="nav-number">8.1.5.</span> <span class="nav-text">LLM幻觉的滚雪球现象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM%E5%B9%BB%E8%A7%89%E7%9A%84%E5%8E%9F%E5%AD%90%E7%B2%92%E5%BA%A6%E8%AF%84%E4%BC%B0"><span class="nav-number">8.1.6.</span> <span class="nav-text">LLM幻觉的原子粒度评估</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B9%BB%E8%A7%89%E6%A3%80%E6%B5%8B-amp-%E4%BF%AE%E6%AD%A3"><span class="nav-number">8.2.</span> <span class="nav-text">幻觉检测&amp;修正</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8B%E5%AE%9E%E6%80%A7%E5%A2%9E%E5%BC%BA%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="nav-number">8.2.1.</span> <span class="nav-text">事实性增强的语言模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8F%8D%E9%A6%88%E6%8F%90%E5%8D%87%E4%BA%8B%E5%AE%9E%E6%80%A7"><span class="nav-number">8.2.2.</span> <span class="nav-text">基于外部知识和自动反馈提升事实性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%B6%E8%B5%84%E6%BA%90%E9%BB%91%E7%9B%92LLM%E5%B9%BB%E8%A7%89%E6%A3%80%E6%B5%8B"><span class="nav-number">8.2.3.</span> <span class="nav-text">零资源黑盒LLM幻觉检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%B6%E8%B5%84%E6%BA%90%E9%BB%91%E7%9B%92%E4%BA%8B%E5%AE%9E%E9%94%99%E8%AF%AF%E7%BA%A0%E6%AD%A3"><span class="nav-number">8.2.4.</span> <span class="nav-text">零资源黑盒事实错误纠正</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%A5%E5%85%B7%E5%A2%9E%E5%BC%BA%E7%9A%84LLM%E8%87%AA%E5%8A%A8%E7%BA%A0%E6%AD%A3"><span class="nav-number">8.2.5.</span> <span class="nav-text">工具增强的LLM自动纠正</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E6%8E%A8%E7%90%86%E6%97%B6%E5%B9%B2%E9%A2%84%E8%AF%B1%E5%AF%BCLLM%E7%94%9F%E6%88%90%E7%AC%A6%E5%90%88%E4%BA%8B%E5%AE%9E%E7%9A%84%E7%AD%94%E6%A1%88"><span class="nav-number">8.2.6.</span> <span class="nav-text">通过推理时干预诱导LLM生成符合事实的答案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%B0%8F%E6%A8%A1%E5%9E%8B%E5%90%8E%E5%A4%84%E7%90%86%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98"><span class="nav-number">8.2.7.</span> <span class="nav-text">训练小模型后处理幻觉问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E8%BE%A9%E8%AE%BA%E6%98%BE%E8%91%97%E6%8F%90%E5%8D%87LM%E7%9A%84%E4%BA%8B%E5%AE%9E%E6%80%A7%E5%92%8C%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B"><span class="nav-number">8.2.8.</span> <span class="nav-text">利用多智能体辩论显著提升LM的事实性和推理能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%BA%E5%9C%A8%E5%9B%9E%E8%B7%AF%E7%9A%84%E5%B9%BB%E8%A7%89%E6%B6%88%E9%99%A4"><span class="nav-number">8.2.9.</span> <span class="nav-text">人在回路的幻觉消除</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Run-Qing Chen"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Run-Qing Chen</p>
  <div class="site-description" itemprop="description">覆苍天以为衾，卧大地以为庐。</div>
</div>


   <div class="feed-link motion-element">
     <a href="/atom.xml" rel="alternate">
       <i class="fa fa-rss"></i>
       RSS
     </a>
   </div>
 
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">250</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">86</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">85</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/RexKing6" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;RexKing6" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1010026261@qq.com" title="E-Mail → mailto:1010026261@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://zhimi.vercel.app/index_zh-cn.html" title="https:&#x2F;&#x2F;zhimi.vercel.app&#x2F;index_zh-cn.html" rel="noopener" target="_blank">執迷</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://whitepuffer.github.io/" title="https:&#x2F;&#x2F;whitepuffer.github.io&#x2F;" rel="noopener" target="_blank">江斓</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://kexue.fm/" title="https:&#x2F;&#x2F;kexue.fm&#x2F;" rel="noopener" target="_blank">科学空间</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yongyuan.name/" title="https:&#x2F;&#x2F;yongyuan.name&#x2F;" rel="noopener" target="_blank">袁勇</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/abcjennifer" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;abcjennifer" rel="noopener" target="_blank">Rachel Zhang</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://dmkf.xyz/" title="http:&#x2F;&#x2F;dmkf.xyz&#x2F;" rel="noopener" target="_blank">代码咖啡</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://wuxiaolong.me/" title="http:&#x2F;&#x2F;wuxiaolong.me&#x2F;" rel="noopener" target="_blank">吴小龙同学</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.tennfy.com/" title="http:&#x2F;&#x2F;www.tennfy.com&#x2F;" rel="noopener" target="_blank">TENNFY WU</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fab fa-accessible-icon"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Run-Qing Chen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">4.3m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">65:02</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"6XDsO3aHIjDk3nV6eLJCufbl-MdYXbMMI","app_key":"YK4qOc0TpkazN6exhuqsnwmB","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
